"""
STAR-Forecastä¸»è®­ç»ƒå™¨
é›†æˆISTRç½‘ç»œã€AutoGenæ™ºèƒ½ä½“ã€Agent Lightningå®¢æˆ·ç«¯
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from typing import Dict, List, Optional, Tuple, Any
import numpy as np
from datetime import datetime
import logging
from pathlib import Path
import json
import time
import os
import sys

# ============ ä¿®å¤å¯¼å…¥è·¯å¾„ ============
# è·å–å½“å‰æ–‡ä»¶çš„ç›®å½•
current_dir = os.path.dirname(os.path.abspath(__file__))
# è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆtrainingç›®å½•çš„çˆ¶ç›®å½•ï¼‰
project_root = os.path.dirname(current_dir)
# æ·»åŠ åˆ°Pythonè·¯å¾„
sys.path.insert(0, project_root)


# ============ å®‰å…¨å¯¼å…¥å‡½æ•° ============
def safe_import(module_name, class_name=None):
    """å®‰å…¨åœ°å¯¼å…¥æ¨¡å—ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None"""
    try:
        module = __import__(module_name, fromlist=['*'])
        if class_name:
            return getattr(module, class_name)
        return module
    except (ImportError, AttributeError) as e:
        print(f"âš ï¸  å¯¼å…¥ {module_name}.{class_name} å¤±è´¥: {e}")
        return None


# ============ å°è¯•å¯¼å…¥é¡¹ç›®æ¨¡å— ============
print("ğŸ”§ æ­£åœ¨å¯¼å…¥STAR-Forecastæ¨¡å—...")

# å°è¯•å¯¼å…¥ISTRæ¨¡å‹
ISTRNetwork = safe_import('models.istr', 'ISTRNetwork')
if ISTRNetwork is None:
    # åˆ›å»ºç®€å•çš„ISTRç½‘ç»œæ›¿ä»£
    class SimpleISTRNetwork(nn.Module):
        def __init__(self, config):
            super().__init__()
            self.config = config
            hidden_dim = config.get('istr', {}).get('hidden_dim', 256)

            # ç®€å•çš„å·ç§¯ç½‘ç»œ
            self.conv1 = nn.Conv1d(7, 64, kernel_size=3, padding=1)
            self.conv2 = nn.Conv1d(64, hidden_dim, kernel_size=3, padding=1)
            self.relu = nn.ReLU()
            self.dropout = nn.Dropout(0.1)

            # è‡ªé€‚åº”å‚æ•°ï¼ˆç®€åŒ–ï¼‰
            self.adaptive_params = {
                'spectral_threshold': torch.tensor(0.5)
            }
            self.laplacian_regularizer = nn.Parameter(torch.tensor(0.1))

        def forward(self, x, return_regularization=False):
            # è½¬ç½®ä»¥é€‚åº”å·ç§¯
            x = x.transpose(1, 2)

            # å·ç§¯å±‚
            x = self.relu(self.conv1(x))
            x = self.dropout(x)
            x = self.relu(self.conv2(x))

            # è½¬ç½®å›æ¥
            x = x.transpose(1, 2)

            # æ­£åˆ™åŒ–æŸå¤±ï¼ˆç®€åŒ–ï¼‰
            reg_loss = torch.tensor(0.0)

            if return_regularization:
                return x, reg_loss
            return x

        def extract_features_for_analysis(self, x):
            """æå–ç‰¹å¾ä¾›åˆ†æ"""
            with torch.no_grad():
                features = self.forward(x)
                return {
                    'mean': features.mean().item(),
                    'std': features.std().item(),
                    'shape': features.shape
                }

        def update_adaptive_parameters(self, params):
            """æ›´æ–°è‡ªé€‚åº”å‚æ•°"""
            for key, value in params.items():
                if key in self.adaptive_params:
                    self.adaptive_params[key] = torch.tensor(value)


    ISTRNetwork = SimpleISTRNetwork
    print("  âš ï¸  ä½¿ç”¨ç®€åŒ–ç‰ˆISTRç½‘ç»œ")

# å°è¯•å¯¼å…¥MultiHeadPredictor
MultiHeadPredictor = safe_import('models.predictor', 'MultiHeadPredictor')
if MultiHeadPredictor is None:
    # åˆ›å»ºç®€å•çš„å¤šå¤´é¢„æµ‹å™¨
    class SimpleMultiHeadPredictor(nn.Module):
        def __init__(self, hidden_dim=256, pred_len=24, heads=3):
            super().__init__()
            self.heads = heads
            self.pred_len = pred_len

            # æ¯ä¸ªå¤´ä¸€ä¸ªçº¿æ€§å±‚
            self.head_layers = nn.ModuleList([
                nn.Linear(hidden_dim, pred_len) for _ in range(heads)
            ])

            # æ³¨æ„åŠ›æƒé‡
            self.attention = nn.Linear(hidden_dim, heads)

        def forward(self, x):
            batch_size = x.size(0)

            # å…¨å±€å¹³å‡æ± åŒ–
            context = x.mean(dim=1)  # [batch_size, hidden_dim]

            # è®¡ç®—æ³¨æ„åŠ›æƒé‡
            attn_weights = F.softmax(self.attention(context), dim=-1)  # [batch_size, heads]

            # æ¯ä¸ªå¤´çš„é¢„æµ‹
            head_predictions = []
            for head_layer in self.head_layers:
                pred = head_layer(context).unsqueeze(1)  # [batch_size, 1, pred_len]
                head_predictions.append(pred)

            # å †å 
            all_predictions = torch.cat(head_predictions, dim=1)  # [batch_size, heads, pred_len]

            # åŠ æƒæ±‚å’Œ
            attn_weights = attn_weights.unsqueeze(-1)  # [batch_size, heads, 1]
            final_prediction = torch.sum(all_predictions * attn_weights, dim=1)  # [batch_size, pred_len]

            return final_prediction.unsqueeze(-1)  # [batch_size, pred_len, 1]


    MultiHeadPredictor = SimpleMultiHeadPredictor
    print("  âš ï¸  ä½¿ç”¨ç®€åŒ–ç‰ˆå¤šå¤´é¢„æµ‹å™¨")

# å°è¯•å¯¼å…¥å…¶ä»–æ¨¡å—
TimeSeriesMetrics = safe_import('training.metrics', 'TimeSeriesMetrics')
if TimeSeriesMetrics is None:
    # åˆ›å»ºç®€å•çš„æ—¶åºæŒ‡æ ‡è®¡ç®—å™¨
    class SimpleTimeSeriesMetrics:
        def compute(self, predictions, targets):
            predictions = torch.tensor(predictions)
            targets = torch.tensor(targets)

            mse = F.mse_loss(predictions, targets).item()
            mae = F.l1_loss(predictions, targets).item()

            # è®¡ç®—RMSE
            rmse = torch.sqrt(torch.tensor(mse)).item()

            # è®¡ç®—MAPEï¼ˆé¿å…é™¤é›¶ï¼‰
            mask = torch.abs(targets) > 1e-8
            if torch.any(mask):
                mape = torch.mean(torch.abs((targets[mask] - predictions[mask]) / targets[mask])).item() * 100
            else:
                mape = 0.0

            return {
                'mse': mse,
                'mae': mae,
                'rmse': rmse,
                'mape': mape
            }


    TimeSeriesMetrics = SimpleTimeSeriesMetrics

# å°è¯•å¯¼å…¥å›è°ƒ
TrainingCallbacks = safe_import('training.callbacks', 'TrainingCallbacks')
if TrainingCallbacks is None:
    # åˆ›å»ºç®€å•çš„å›è°ƒ
    class SimpleTrainingCallbacks:
        def __init__(self, config):
            self.config = config

        def on_epoch_end(self, epoch, train_metrics, val_metrics):
            pass

        def on_train_end(self, test_metrics):
            pass


    TrainingCallbacks = SimpleTrainingCallbacks

# å°è¯•å¯¼å…¥é…ç½®
load_config = safe_import('utils.config', 'load_config')
if load_config is None:
    # åˆ›å»ºç®€å•çš„é…ç½®åŠ è½½å™¨
    def simple_load_config(config_path):
        import yaml
        if os.path.exists(config_path):
            with open(config_path, 'r') as f:
                return yaml.safe_load(f)
        else:
            # è¿”å›é»˜è®¤é…ç½®
            return {
                'experiment': {
                    'seed': 42,
                    'name': 'STAR-Forecast'
                },
                'hardware': {
                    'mixed_precision': False
                },
                'istr': {
                    'hidden_dim': 256
                },
                'predictor': {
                    'heads': 3
                },
                'data': {
                    'seq_len': 96,
                    'pred_len': 24
                },
                'training': {
                    'epochs': 50,
                    'learning_rate': 0.001,
                    'weight_decay': 0.0001,
                    'optimizer': {
                        'type': 'AdamW',
                        'betas': [0.9, 0.999],
                        'eps': 1e-8
                    },
                    'scheduler': {
                        'type': 'CosineAnnealingWarmRestarts',
                        'T_0': 10,
                        'T_mult': 2,
                        'eta_min': 1e-6
                    },
                    'gradient': {
                        'clip_norm': 1.0
                    },
                    'early_stopping': {
                        'patience': 10
                    },
                    'checkpoint': {
                        'save_frequency': 5
                    }
                },
                'logging': {
                    'experiment_tracking': {
                        'wandb': {
                            'enabled': False,
                            'project': 'star-forecast',
                            'entity': None
                        }
                    }
                },
                'autogen': {
                    'trigger': {
                        'check_interval': 50
                    }
                },
                'agent_lightning': {
                    'client': {
                        'base_url': 'http://localhost:8000',
                        'timeout': 30,
                        'retry_attempts': 3,
                        'fallback_enabled': True
                    },
                    'rl': {
                        'reward': {
                            'weights': {
                                'mse': 1.0,
                                'smoothness': 0.1,
                                'stability': 0.05,
                                'semantic': 0.5
                            }
                        }
                    }
                }
            }


    load_config = simple_load_config

# å°è¯•å¯¼å…¥æ—¥å¿—
setup_logger = safe_import('utils.logger', 'setup_logger')
if setup_logger is None:
    # åˆ›å»ºç®€å•çš„æ—¥å¿—è®¾ç½®
    def simple_setup_logger(name):
        logger = logging.getLogger(name)
        logger.setLevel(logging.INFO)

        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)

        return logger


    setup_logger = simple_setup_logger

print("âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥å®Œæˆ")


# ============ åˆ›å»ºç¼ºå¤±çš„ç±» ============

class AgentLightningClient:
    """Agent Lightningå®¢æˆ·ç«¯ï¼ˆç®€åŒ–ç‰ˆï¼‰"""

    def __init__(self, base_url, client_id, timeout=30, retry_attempts=3, fallback_enabled=True):
        self.base_url = base_url
        self.client_id = client_id
        self.timeout = timeout
        self.retry_attempts = retry_attempts
        self.fallback_enabled = fallback_enabled
        self.stats = {
            'requests_sent': 0,
            'responses_received': 0,
            'errors': 0
        }

    def get_decision(self, context):
        """è·å–å†³ç­–ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        self.stats['requests_sent'] += 1

        # ç®€åŒ–ï¼šè¿”å›å›ºå®šå†³ç­–
        return type('Decision', (), {
            'action': 'adjust_parameters',
            'parameters': {
                'spectral_threshold': 0.7,
                'laplacian_weight': 0.15,
                'learning_rate_multiplier': 1.0
            },
            'semantic_reward': 0.5
        })()

    def update_experience(self, state, action, reward, next_state):
        """æ›´æ–°ç»éªŒï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        pass

    def get_client_stats(self):
        """è·å–å®¢æˆ·ç«¯ç»Ÿè®¡"""
        return self.stats


class AutoGenMultiAgentSystem:
    """AutoGenå¤šæ™ºèƒ½ä½“ç³»ç³»ç»Ÿï¼ˆç®€åŒ–ç‰ˆï¼‰"""

    def __init__(self, config):
        self.config = config
        self.conversation_history = []

    def get_conversation_history(self):
        """è·å–å¯¹è¯å†å²"""
        return self.conversation_history


def create_dataloaders(config, data_path):
    """åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
    from torch.utils.data import Dataset, DataLoader

    class SimpleTimeSeriesDataset(Dataset):
        def __init__(self, data_path, seq_len, pred_len, mode='train'):
            import pandas as pd
            import numpy as np

            df = pd.read_csv(data_path)
            if 'date' in df.columns:
                data = df.drop('date', axis=1).values
            else:
                data = df.values

            # ç®€å•åˆ’åˆ†
            n = len(data)
            if mode == 'train':
                data = data[:int(n * 0.7)]
            elif mode == 'val':
                data = data[int(n * 0.7):int(n * 0.9)]
            else:  # test
                data = data[int(n * 0.9):]

            self.data = data.astype(np.float32)
            self.seq_len = seq_len
            self.pred_len = pred_len

        def __len__(self):
            return len(self.data) - self.seq_len - self.pred_len + 1

        def __getitem__(self, idx):
            x = self.data[idx:idx + self.seq_len]
            y = self.data[idx + self.seq_len:idx + self.seq_len + self.pred_len, -1:]
            return torch.FloatTensor(x), torch.FloatTensor(y)

    seq_len = config['data']['seq_len']
    pred_len = config['data']['pred_len']

    train_dataset = SimpleTimeSeriesDataset(data_path, seq_len, pred_len, 'train')
    val_dataset = SimpleTimeSeriesDataset(data_path, seq_len, pred_len, 'val')
    test_dataset = SimpleTimeSeriesDataset(data_path, seq_len, pred_len, 'test')

    batch_size = config['training']['batch_size']

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    return train_loader, val_loader, test_loader


# ============ ä¸»è®­ç»ƒå™¨ç±» ============

class STARForecastTrainer:
    """
    STAR-Forecastä¸»è®­ç»ƒå™¨

    é›†æˆï¼š
    1. ISTRç½‘ç»œï¼ˆTCN + æ‹‰æ™®æ‹‰æ–¯ï¼‰
    2. AutoGenå¤šæ™ºèƒ½ä½“å¯¹è¯
    3. Agent Lightningè§£è€¦è®­ç»ƒ
    4. å®Œæ•´çš„è®­ç»ƒå¾ªç¯å’Œè¯„ä¼°
    """

    def __init__(self, config_path: str = "./config.yaml"):
        # åŠ è½½é…ç½®
        self.config = load_config(config_path)

        # è®¾ç½®æ—¥å¿—
        self.logger = setup_logger("STAR-Forecast")

        # è®¾ç½®è®¾å¤‡
        self.device = self._setup_device()

        # è®¾ç½®éšæœºç§å­
        self._set_seed()

        # åˆå§‹åŒ–ç»„ä»¶
        self.istr_model = None
        self.predictor = None
        self.optimizer = None
        self.scheduler = None

        # æ™ºèƒ½ä½“ç³»ç»Ÿ
        self.autogen_system = None
        self.agent_client = None

        # è®­ç»ƒçŠ¶æ€
        self.current_epoch = 0
        self.global_step = 0
        self.best_val_loss = float('inf')

        # æŒ‡æ ‡è·Ÿè¸ª
        self.metrics = TimeSeriesMetrics()
        self.callbacks = TrainingCallbacks(self.config)

        # å®éªŒè·Ÿè¸ª
        self._setup_experiment_tracking()

        self.logger.info("ğŸ¯ STAR-Forecastè®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")

    def _setup_device(self):
        """è®¾ç½®è®¾å¤‡"""
        if torch.cuda.is_available():
            device = torch.device('cuda:0')
            self.logger.info(f"âœ… ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")

            # è®¾ç½®æ··åˆç²¾åº¦
            if self.config['hardware']['mixed_precision']:
                self.scaler = torch.cuda.amp.GradScaler()
                self.logger.info("âœ… å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ")
            else:
                self.scaler = None
        else:
            device = torch.device('cpu')
            self.logger.warning("âš ï¸ ä½¿ç”¨CPUè®­ç»ƒï¼Œæ€§èƒ½å¯èƒ½å—é™")
            self.scaler = None

        return device

    def _set_seed(self):
        """è®¾ç½®éšæœºç§å­"""
        seed = self.config['experiment']['seed']

        torch.manual_seed(seed)
        np.random.seed(seed)

        if torch.cuda.is_available():
            torch.cuda.manual_seed(seed)
            torch.cuda.manual_seed_all(seed)
            torch.backends.cudnn.deterministic = True
            torch.backends.cudnn.benchmark = False

        self.logger.info(f"ğŸ”§ è®¾ç½®éšæœºç§å­: {seed}")

    def _setup_experiment_tracking(self):
        """è®¾ç½®å®éªŒè·Ÿè¸ª"""
        # å°è¯•å¯¼å…¥wandbï¼Œå¦‚æœå¤±è´¥åˆ™ç¦ç”¨
        try:
            import wandb
            if self.config['logging']['experiment_tracking']['wandb']['enabled']:
                wandb.init(
                    project=self.config['logging']['experiment_tracking']['wandb']['project'],
                    entity=self.config['logging']['experiment_tracking']['wandb']['entity'],
                    config=self.config,
                    name=self.config['experiment']['name']
                )
                self.logger.info("ğŸ“Š å¯ç”¨WandBå®éªŒè·Ÿè¸ª")
                self.wandb = wandb
            else:
                self.wandb = None
        except ImportError:
            self.logger.warning("âš ï¸ æœªå®‰è£…wandbï¼Œç¦ç”¨å®éªŒè·Ÿè¸ª")
            self.wandb = None

    def build_models(self):
        """æ„å»ºæ¨¡å‹"""
        self.logger.info("ğŸ”¨ æ„å»ºæ¨¡å‹...")

        # 1. æ„å»ºISTRç½‘ç»œ
        self.istr_model = ISTRNetwork(self.config).to(self.device)

        # 2. æ„å»ºé¢„æµ‹å¤´
        self.predictor = MultiHeadPredictor(
            hidden_dim=self.config['istr']['hidden_dim'],
            pred_len=self.config['data']['pred_len'],
            heads=self.config['predictor']['heads']
        ).to(self.device)

        # 3. è®¡ç®—æ€»å‚æ•°
        total_params = sum(p.numel() for p in self.istr_model.parameters())
        trainable_params = sum(p.numel() for p in self.istr_model.parameters()
                               if p.requires_grad)

        self.logger.info(f"ğŸ“Š æ¨¡å‹ç»Ÿè®¡:")
        self.logger.info(f"   ISTRå‚æ•°: {total_params:,} (å¯è®­ç»ƒ: {trainable_params:,})")
        self.logger.info(f"   é¢„æµ‹å¤´å‚æ•°: {sum(p.numel() for p in self.predictor.parameters()):,}")

    def build_optimizer(self):
        """æ„å»ºä¼˜åŒ–å™¨"""
        self.logger.info("âš™ï¸ æ„å»ºä¼˜åŒ–å™¨...")

        # åªä¼˜åŒ–å¯è®­ç»ƒå‚æ•°
        trainable_params = []
        trainable_params.extend(
            [p for p in self.istr_model.parameters() if p.requires_grad]
        )
        trainable_params.extend(self.predictor.parameters())

        # ä¼˜åŒ–å™¨
        optimizer_config = self.config['training']['optimizer']

        if optimizer_config['type'] == 'AdamW':
            self.optimizer = torch.optim.AdamW(
                trainable_params,
                lr=self.config['training']['learning_rate'],
                betas=tuple(optimizer_config['betas']),
                eps=optimizer_config['eps'],
                weight_decay=self.config['training']['weight_decay']
            )
        else:
            self.optimizer = torch.optim.Adam(
                trainable_params,
                lr=self.config['training']['learning_rate'],
                weight_decay=self.config['training']['weight_decay']
            )

        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler_config = self.config['training']['scheduler']

        if scheduler_config['type'] == 'CosineAnnealingWarmRestarts':
            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
                self.optimizer,
                T_0=scheduler_config['T_0'],
                T_mult=scheduler_config['T_mult'],
                eta_min=scheduler_config['eta_min']
            )
        else:
            self.scheduler = None

        self.logger.info(f"âœ… ä¼˜åŒ–å™¨: {optimizer_config['type']}")
        self.logger.info(f"   åˆå§‹å­¦ä¹ ç‡: {self.config['training']['learning_rate']}")

    def initialize_agents(self):
        """åˆå§‹åŒ–æ™ºèƒ½ä½“ç³»ç³»ç»Ÿ"""
        self.logger.info("ğŸ¤– åˆå§‹åŒ–æ™ºèƒ½ä½“ç³»ç³»ç»Ÿ...")

        # 1. åˆå§‹åŒ–AutoGenç³»ç»Ÿ
        self.autogen_system = AutoGenMultiAgentSystem(self.config)

        # 2. åˆå§‹åŒ–Agent Lightningå®¢æˆ·ç«¯
        agent_config = self.config['agent_lightning']['client']

        self.agent_client = AgentLightningClient(
            base_url=agent_config['base_url'],
            client_id=f"star_forecast_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            timeout=agent_config['timeout'],
            retry_attempts=agent_config['retry_attempts'],
            fallback_enabled=agent_config['fallback_enabled']
        )

        self.logger.info("âœ… æ™ºèƒ½ä½“ç³»ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    def train_epoch(self, train_loader: DataLoader, epoch: int) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.istr_model.train()
        self.predictor.train()

        epoch_losses = []
        epoch_metrics = {'mse': [], 'mae': []}

        self.logger.info(f"ğŸ‹ï¸  Epoch {epoch + 1} è®­ç»ƒå¼€å§‹")

        for batch_idx, (x, y) in enumerate(train_loader):
            x, y = x.to(self.device), y.to(self.device)

            # è®­ç»ƒæ­¥éª¤
            loss, metrics = self.train_step(x, y, batch_idx)

            epoch_losses.append(loss)
            epoch_metrics['mse'].append(metrics['mse'])
            epoch_metrics['mae'].append(metrics['mae'])

            # æ—¥å¿—è®°å½•
            if batch_idx % 50 == 0:
                current_lr = self.optimizer.param_groups[0]['lr']

                self.logger.info(
                    f"  Batch {batch_idx}/{len(train_loader)}, "
                    f"Loss: {loss:.4f}, MSE: {metrics['mse']:.4f}, "
                    f"LR: {current_lr:.6f}"
                )

                # WandBæ—¥å¿—
                if self.wandb is not None:
                    self.wandb.log({
                        'train/loss': loss,
                        'train/mse': metrics['mse'],
                        'train/mae': metrics['mae'],
                        'train/lr': current_lr,
                        'epoch': epoch,
                        'global_step': self.global_step
                    })

            self.global_step += 1

        # è®¡ç®—epochå¹³å‡æŒ‡æ ‡
        avg_loss = np.mean(epoch_losses)
        avg_mse = np.mean(epoch_metrics['mse'])
        avg_mae = np.mean(epoch_metrics['mae'])

        return {
            'loss': avg_loss,
            'mse': avg_mse,
            'mae': avg_mae
        }

    def train_step(self, x: torch.Tensor, y: torch.Tensor, batch_idx: int) -> Tuple[float, Dict[str, float]]:
        """å•æ‰¹æ¬¡è®­ç»ƒæ­¥éª¤"""
        # æ··åˆç²¾åº¦è®­ç»ƒ
        if self.scaler is not None:
            with torch.cuda.amp.autocast():
                # ISTRç‰¹å¾æå–
                features, reg_loss = self.istr_model(x, return_regularization=True)

                # é¢„æµ‹
                predictions = self.predictor(features)

                # è®¡ç®—æŸå¤±
                mse_loss = F.mse_loss(predictions, y)
                total_loss = mse_loss + reg_loss
        else:
            # ISTRç‰¹å¾æå–
            features, reg_loss = self.istr_model(x, return_regularization=True)

            # é¢„æµ‹
            predictions = self.predictor(features)

            # è®¡ç®—æŸå¤±
            mse_loss = F.mse_loss(predictions, y)
            total_loss = mse_loss + reg_loss

        # åå‘ä¼ æ’­
        self.optimizer.zero_grad()

        if self.scaler is not None:
            self.scaler.scale(total_loss).backward()
            self.scaler.unscale_(self.optimizer)

            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(
                self.istr_model.parameters(),
                self.config['training']['gradient']['clip_norm']
            )

            self.scaler.step(self.optimizer)
            self.scaler.update()
        else:
            total_loss.backward()

            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(
                self.istr_model.parameters(),
                self.config['training']['gradient']['clip_norm']
            )

            self.optimizer.step()

        # è°ƒåº¦å™¨æ­¥è¿›
        if self.scheduler is not None:
            self.scheduler.step()

        # æ™ºèƒ½ä½“å†³ç­–ï¼ˆåœ¨ç‰¹å®šæ­¥éª¤è§¦å‘ï¼‰
        if self._should_trigger_agents(batch_idx):
            self._agent_decision_step(x, features, predictions, y, batch_idx)

        # è®¡ç®—æŒ‡æ ‡
        metrics = {
            'mse': mse_loss.item(),
            'mae': F.l1_loss(predictions, y).item(),
            'reg_loss': reg_loss.item() if isinstance(reg_loss, torch.Tensor) else 0.0
        }

        return total_loss.item(), metrics

    def _should_trigger_agents(self, batch_idx: int) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è§¦å‘æ™ºèƒ½ä½“"""
        check_interval = self.config.get('autogen', {}).get('trigger', {}).get('check_interval', 50)

        # æ¯Nä¸ªæ‰¹æ¬¡è§¦å‘ä¸€æ¬¡
        if batch_idx % check_interval == 0:
            return True

        return False

    def _agent_decision_step(self, x: torch.Tensor, features: torch.Tensor,
                             predictions: torch.Tensor, targets: torch.Tensor,
                             batch_idx: int):
        """æ™ºèƒ½ä½“å†³ç­–æ­¥éª¤"""
        self.logger.info(f"ğŸ¤– è§¦å‘æ™ºèƒ½ä½“å†³ç­– (Batch {batch_idx})")

        # 1. æå–ç‰¹å¾ä¾›åˆ†æ
        with torch.no_grad():
            feature_analysis = self.istr_model.extract_features_for_analysis(x)

            # è®¡ç®—å½“å‰æŒ‡æ ‡
            current_mse = F.mse_loss(predictions, targets).item()
            current_mae = F.l1_loss(predictions, targets).item()

        # 2. å‡†å¤‡ä¸Šä¸‹æ–‡ä¿¡æ¯
        context = {
            'features': feature_analysis,
            'metrics': {
                'mse': current_mse,
                'mae': current_mae,
                'batch_idx': batch_idx,
                'global_step': self.global_step
            },
            'current_params': {
                'spectral_threshold': self.istr_model.adaptive_params['spectral_threshold'].item(),
                'laplacian_weight': self.istr_model.laplacian_regularizer.weight.item(),
                'learning_rate': self.optimizer.param_groups[0]['lr']
            },
            'training_info': {
                'epoch': self.current_epoch,
                'total_epochs': self.config['training']['epochs'],
                'batch_idx': batch_idx
            },
            'batch_idx': batch_idx,
            'global_step': self.global_step
        }

        # 3. è°ƒç”¨Agent Lightningè·å–å†³ç­–
        try:
            decision = self.agent_client.get_decision(context)

            self.logger.info(f"âœ… æ™ºèƒ½ä½“å†³ç­–: action={decision.action}, "
                             f"params={decision.parameters}")

            # 4. åº”ç”¨å†³ç­–åˆ°æ¨¡å‹
            if decision.parameters:
                self.istr_model.update_adaptive_parameters(decision.parameters)

                # æ›´æ–°å­¦ä¹ ç‡
                if 'learning_rate_multiplier' in decision.parameters:
                    new_lr = (self.config['training']['learning_rate'] *
                              decision.parameters['learning_rate_multiplier'])

                    for param_group in self.optimizer.param_groups:
                        param_group['lr'] = new_lr

                    self.logger.info(f"ğŸ”„ è°ƒæ•´å­¦ä¹ ç‡: {new_lr:.6f}")

            # 5. å‡†å¤‡å¼ºåŒ–å­¦ä¹ çŠ¶æ€å’Œå¥–åŠ±
            state = self._prepare_rl_state(features)
            reward = self._calculate_reward(predictions, targets, decision)

            # 6. å¼‚æ­¥æ›´æ–°æ™ºèƒ½ä½“ç»éªŒï¼ˆä¸é˜»å¡è®­ç»ƒï¼‰
            next_state = state  # ç®€åŒ–ï¼šå‡è®¾çŠ¶æ€ä¸å˜
            self.agent_client.update_experience(
                state=state,
                action=decision.action,
                reward=reward,
                next_state=next_state
            )

            # 7. è®°å½•å†³ç­–
            if self.wandb is not None:
                self.wandb.log({
                    'agent/action': decision.action,
                    'agent/reward': reward,
                    'agent/semantic_reward': decision.semantic_reward,
                    'agent/spectral_threshold': decision.parameters.get('spectral_threshold', 0),
                    'agent/laplacian_weight': decision.parameters.get('laplacian_weight', 0),
                    'epoch': self.current_epoch,
                    'global_step': self.global_step
                })

        except Exception as e:
            self.logger.error(f"âŒ æ™ºèƒ½ä½“å†³ç­–å¤±è´¥: {e}")

    def _prepare_rl_state(self, features: torch.Tensor) -> List[float]:
        """å‡†å¤‡å¼ºåŒ–å­¦ä¹ çŠ¶æ€"""
        with torch.no_grad():
            # æå–ç‰¹å¾ç»Ÿè®¡
            state = []

            # å‡å€¼
            state.append(features.mean().item())

            # æ ‡å‡†å·®
            state.append(features.std().item())

            # è‡ªé€‚åº”å‚æ•°
            state.append(self.istr_model.adaptive_params['spectral_threshold'].item())
            state.append(self.istr_model.laplacian_regularizer.weight.item())

        return state

    def _calculate_reward(self, predictions: torch.Tensor,
                          targets: torch.Tensor,
                          decision: Any) -> float:
        """è®¡ç®—å¥–åŠ±"""
        # 1. é¢„æµ‹è¯¯å·®å¥–åŠ±
        mse = F.mse_loss(predictions, targets).item()
        error_reward = -mse * self.config['agent_lightning']['rl']['reward']['weights']['mse']

        # 2. å¹³æ»‘æ€§å¥–åŠ±
        if predictions.shape[1] > 1:
            smoothness = torch.mean(
                torch.abs(predictions[:, 1:] - predictions[:, :-1])
            ).item()
            smoothness_reward = -smoothness * self.config['agent_lightning']['rl']['reward']['weights']['smoothness']
        else:
            smoothness_reward = 0.0

        # 3. ç¨³å®šæ€§å¥–åŠ±
        stability = torch.std(predictions).item()
        stability_reward = -stability * self.config['agent_lightning']['rl']['reward']['weights']['stability']

        # 4. è¯­ä¹‰å¥–åŠ±ï¼ˆæ¥è‡ªæ™ºèƒ½ä½“å¯¹è¯ï¼‰
        semantic_reward = decision.semantic_reward * self.config['agent_lightning']['rl']['reward']['weights'][
            'semantic']

        # æ€»å¥–åŠ±
        total_reward = (
                error_reward +
                smoothness_reward +
                stability_reward +
                semantic_reward
        )

        return total_reward

    def validate(self, val_loader: DataLoader) -> Dict[str, float]:
        """éªŒè¯æ¨¡å‹"""
        self.istr_model.eval()
        self.predictor.eval()

        val_losses = []
        all_predictions = []
        all_targets = []

        with torch.no_grad():
            for x, y in val_loader:
                x, y = x.to(self.device), y.to(self.device)

                # å‰å‘ä¼ æ’­
                features = self.istr_model(x)
                predictions = self.predictor(features)

                # è®¡ç®—æŸå¤±
                loss = F.mse_loss(predictions, y)
                val_losses.append(loss.item())

                # ä¿å­˜é¢„æµ‹ç»“æœ
                all_predictions.append(predictions.cpu().numpy())
                all_targets.append(y.cpu().numpy())

        # è®¡ç®—æŒ‡æ ‡
        val_loss = np.mean(val_losses)
        all_predictions = np.concatenate(all_predictions, axis=0)
        all_targets = np.concatenate(all_targets, axis=0)

        metrics = self.metrics.compute(all_predictions, all_targets)
        metrics['loss'] = val_loss

        return metrics

    def test(self, test_loader: DataLoader) -> Dict[str, float]:
        """æµ‹è¯•æ¨¡å‹"""
        return self.validate(test_loader)  # ä¸éªŒè¯é€»è¾‘ç›¸åŒ

    def train(self, data_path: str = "./data/ETTh1.csv"):
        """ä¸»è®­ç»ƒå¾ªç¯"""
        self.logger.info("ğŸš€ STAR-Forecastè®­ç»ƒå¼€å§‹")
        self.logger.info("=" * 60)

        # 1. æ„å»ºæ¨¡å‹
        self.build_models()

        # 2. æ„å»ºä¼˜åŒ–å™¨
        self.build_optimizer()

        # 3. åˆå§‹åŒ–æ™ºèƒ½ä½“
        self.initialize_agents()

        # 4. åŠ è½½æ•°æ®
        self.logger.info("ğŸ“Š åŠ è½½æ•°æ®...")
        train_loader, val_loader, test_loader = create_dataloaders(
            self.config, data_path
        )

        # 5. è®­ç»ƒå¾ªç¯
        best_model_path = None
        patience_counter = 0

        for epoch in range(self.config['training']['epochs']):
            self.current_epoch = epoch

            # è®­ç»ƒ
            train_metrics = self.train_epoch(train_loader, epoch)

            # éªŒè¯
            val_metrics = self.validate(val_loader)

            # è®°å½•æŒ‡æ ‡
            self._log_epoch_metrics(epoch, train_metrics, val_metrics)

            # æ—©åœæ£€æŸ¥
            if val_metrics['loss'] < self.best_val_loss:
                self.best_val_loss = val_metrics['loss']
                patience_counter = 0

                # ä¿å­˜æœ€ä½³æ¨¡å‹
                best_model_path = self._save_checkpoint(epoch, is_best=True)
                self.logger.info(f"âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: {best_model_path}")
            else:
                patience_counter += 1

            # æ£€æŸ¥æ—©åœ
            if patience_counter >= self.config['training']['early_stopping']['patience']:
                self.logger.info(f"ğŸ›‘ æ—©åœè§¦å‘ï¼Œåœæ­¢è®­ç»ƒ")
                break

            # ä¿å­˜å¸¸è§„æ£€æŸ¥ç‚¹
            if epoch % self.config['training']['checkpoint']['save_frequency'] == 0:
                self._save_checkpoint(epoch, is_best=False)

        # 6. æœ€ç»ˆæµ‹è¯•
        self.logger.info("ğŸ§ª æœ€ç»ˆæµ‹è¯•...")

        # åŠ è½½æœ€ä½³æ¨¡å‹
        if best_model_path:
            self._load_checkpoint(best_model_path)

        test_metrics = self.test(test_loader)

        # è®°å½•æµ‹è¯•ç»“æœ
        self._log_test_metrics(test_metrics)

        # 7. ä¿å­˜æœ€ç»ˆç»“æœ
        self._save_final_results(test_metrics)

        self.logger.info("ğŸ‰ è®­ç»ƒå®Œæˆï¼")

        return test_metrics

    def _log_epoch_metrics(self, epoch: int, train_metrics: Dict[str, float],
                           val_metrics: Dict[str, float]):
        """è®°å½•epochæŒ‡æ ‡"""
        self.logger.info(f"\nğŸ“Š Epoch {epoch + 1} ç»“æœ:")
        self.logger.info(f"   è®­ç»ƒ - Loss: {train_metrics['loss']:.4f}, "
                         f"MSE: {train_metrics['mse']:.4f}, "
                         f"MAE: {train_metrics['mae']:.4f}")
        self.logger.info(f"   éªŒè¯ - Loss: {val_metrics['loss']:.4f}, "
                         f"MSE: {val_metrics['mse']:.4f}, "
                         f"MAE: {val_metrics['mae']:.4f}")

        # WandBæ—¥å¿—
        if self.wandb is not None:
            self.wandb.log({
                'epoch/train_loss': train_metrics['loss'],
                'epoch/train_mse': train_metrics['mse'],
                'epoch/train_mae': train_metrics['mae'],
                'epoch/val_loss': val_metrics['loss'],
                'epoch/val_mse': val_metrics['mse'],
                'epoch/val_mae': val_metrics['mae'],
                'epoch': epoch
            })

    def _log_test_metrics(self, test_metrics: Dict[str, float]):
        """è®°å½•æµ‹è¯•æŒ‡æ ‡"""
        self.logger.info("\n" + "=" * 60)
        self.logger.info("ğŸ¯ æœ€ç»ˆæµ‹è¯•ç»“æœ")
        self.logger.info("=" * 60)

        for metric_name, metric_value in test_metrics.items():
            self.logger.info(f"   {metric_name.upper()}: {metric_value:.6f}")

        # WandBæ—¥å¿—
        if self.wandb is not None:
            for metric_name, metric_value in test_metrics.items():
                self.wandb.log({f'test/{metric_name}': metric_value})

    def _save_checkpoint(self, epoch: int, is_best: bool = False) -> str:
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint_dir = Path("./checkpoints")
        checkpoint_dir.mkdir(exist_ok=True)

        if is_best:
            filename = f"best_model_epoch{epoch + 1}.pth"
        else:
            filename = f"checkpoint_epoch{epoch + 1}.pth"

        checkpoint_path = checkpoint_dir / filename

        checkpoint = {
            'epoch': epoch,
            'global_step': self.global_step,
            'istr_state_dict': self.istr_model.state_dict(),
            'predictor_state_dict': self.predictor.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,
            'best_val_loss': self.best_val_loss,
            'config': self.config
        }

        torch.save(checkpoint, checkpoint_path)

        return str(checkpoint_path)

    def _load_checkpoint(self, checkpoint_path: str):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        checkpoint = torch.load(checkpoint_path, map_location=self.device)

        self.istr_model.load_state_dict(checkpoint['istr_state_dict'])
        self.predictor.load_state_dict(checkpoint['predictor_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

        if self.scheduler and checkpoint['scheduler_state_dict']:
            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])

        self.current_epoch = checkpoint['epoch']
        self.global_step = checkpoint['global_step']
        self.best_val_loss = checkpoint['best_val_loss']

        self.logger.info(f"âœ… åŠ è½½æ£€æŸ¥ç‚¹: {checkpoint_path}")

    def _save_final_results(self, test_metrics: Dict[str, float]):
        """ä¿å­˜æœ€ç»ˆç»“æœ"""
        results_dir = Path("./results")
        results_dir.mkdir(exist_ok=True)

        # è·å–å®¢æˆ·ç«¯ç»Ÿè®¡
        client_stats = self.agent_client.get_client_stats()

        # è·å–AutoGenå†å²
        autogen_history = self.autogen_system.get_conversation_history()

        # æ„å»ºç»“æœ
        results = {
            'experiment': self.config['experiment'],
            'test_metrics': test_metrics,
            'best_val_loss': self.best_val_loss,
            'total_epochs': self.current_epoch + 1,
            'agent_stats': client_stats,
            'autogen_conversations': len(autogen_history),
            'timestamp': datetime.now().isoformat()
        }

        # ä¿å­˜ä¸ºJSON
        results_path = results_dir / "final_results.json"
        with open(results_path, 'w') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        self.logger.info(f"ğŸ’¾ ç»“æœä¿å­˜åˆ°: {results_path}")

        # ä¿å­˜ä¸ºCSVï¼ˆä¾¿äºåˆ†æï¼‰
        csv_path = results_dir / "results.csv"
        with open(csv_path, 'w') as f:
            f.write("metric,value\n")
            for metric, value in test_metrics.items():
                f.write(f"{metric},{value}\n")

        return results_path


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="STAR-Forecastè®­ç»ƒ")
    parser.add_argument("--config", type=str, default="./config.yaml",
                        help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--data", type=str, default="./data/ETTh1.csv",
                        help="æ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--epochs", type=int, default=None,
                        help="è®­ç»ƒè½®æ•°ï¼ˆè¦†ç›–é…ç½®ï¼‰")

    args = parser.parse_args()

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = STARForecastTrainer(args.config)

    # è¦†ç›–é…ç½®ï¼ˆå¦‚æœæä¾›äº†å‚æ•°ï¼‰
    if args.epochs:
        trainer.config['training']['epochs'] = args.epochs

    # å¼€å§‹è®­ç»ƒ
    try:
        results = trainer.train(args.data)

        print("\n" + "=" * 60)
        print("ğŸ‰ è®­ç»ƒå®Œæˆï¼æœ€ç»ˆç»“æœ:")
        print("=" * 60)

        for metric, value in results.items():
            print(f"{metric.upper()}: {value:.6f}")

    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()