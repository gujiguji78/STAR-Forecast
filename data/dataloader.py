"""
æ•°æ®åŠ è½½æ¨¡å— - STAR-Forecast
æä¾›æ—¶é—´åºåˆ—æ•°æ®åŠ è½½å™¨
"""

import torch
import numpy as np
from torch.utils.data import Dataset, DataLoader
from typing import Tuple, List, Optional, Dict, Any
import pandas as pd
from sklearn.preprocessing import StandardScaler


class TimeSeriesDataset(Dataset):
    """æ—¶é—´åºåˆ—æ•°æ®é›†"""

    def __init__(self, data: np.ndarray, seq_len: int, pred_len: int,
                 label_len: int = 0, stride: int = 1):
        """
        åˆå§‹åŒ–æ—¶é—´åºåˆ—æ•°æ®é›†

        å‚æ•°:
            data: æ—¶é—´åºåˆ—æ•°æ®ï¼Œå½¢çŠ¶ä¸º (seq_length, feature_dim)
            seq_len: è¾“å…¥åºåˆ—é•¿åº¦
            pred_len: é¢„æµ‹åºåˆ—é•¿åº¦
            label_len: æ ‡ç­¾åºåˆ—é•¿åº¦ï¼ˆç”¨äºdecoderï¼‰
            stride: æ»‘åŠ¨çª—å£æ­¥é•¿
        """
        self.data = data
        self.seq_len = seq_len
        self.pred_len = pred_len
        self.label_len = label_len
        self.stride = stride
        self.total_len = seq_len + pred_len

        # è®¡ç®—æ ·æœ¬æ•°é‡
        self.n_samples = (len(data) - self.total_len) // stride + 1

    def __len__(self) -> int:
        """è¿”å›æ•°æ®é›†å¤§å°"""
        return self.n_samples

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
        """è·å–å•ä¸ªæ ·æœ¬"""
        start_idx = idx * self.stride
        end_idx = start_idx + self.total_len

        # è·å–åºåˆ—
        sequence = self.data[start_idx:end_idx]

        # åˆ†å‰²è¾“å…¥å’Œè¾“å‡º
        seq_x = sequence[:self.seq_len]  # è¾“å…¥åºåˆ—
        seq_y = sequence[self.seq_len - self.label_len:self.total_len]  # è¾“å‡ºåºåˆ—

        # è½¬æ¢ä¸ºå¼ é‡
        seq_x = torch.FloatTensor(seq_x)
        seq_y = torch.FloatTensor(seq_y)

        return seq_x, seq_y


class TimeSeriesDataLoader:
    """æ—¶é—´åºåˆ—æ•°æ®åŠ è½½å™¨"""

    def __init__(self, data_path: str, seq_len: int = 96, pred_len: int = 24,
                 label_len: int = 48, batch_size: int = 32, scale: bool = True,
                 features: str = 'M', target: str = 'OT', timeenc: int = 0,
                 freq: str = 'h', train_split: float = 0.7, val_split: float = 0.2,
                 shuffle: bool = True, stride: int = 1):
        """
        åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨

        å‚æ•°:
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
            seq_len: è¾“å…¥åºåˆ—é•¿åº¦
            pred_len: é¢„æµ‹åºåˆ—é•¿åº¦
            label_len: æ ‡ç­¾åºåˆ—é•¿åº¦
            batch_size: æ‰¹æ¬¡å¤§å°
            scale: æ˜¯å¦æ ‡å‡†åŒ–
            features: ç‰¹å¾ç±»å‹ ('M': å¤šå˜é‡, 'S': å•å˜é‡, 'MS': å¤šå¯¹å•)
            target: ç›®æ ‡åˆ—å
            timeenc: æ—¶é—´ç¼–ç æ–¹å¼
            freq: æ•°æ®é¢‘ç‡
            train_split: è®­ç»ƒé›†æ¯”ä¾‹
            val_split: éªŒè¯é›†æ¯”ä¾‹
            shuffle: æ˜¯å¦æ‰“ä¹±æ•°æ®
            stride: æ»‘åŠ¨çª—å£æ­¥é•¿
        """
        self.data_path = data_path
        self.seq_len = seq_len
        self.pred_len = pred_len
        self.label_len = label_len
        self.batch_size = batch_size
        self.scale = scale
        self.features = features
        self.target = target
        self.timeenc = timeenc
        self.freq = freq
        self.train_split = train_split
        self.val_split = val_split
        self.shuffle = shuffle
        self.stride = stride

        # åŠ è½½æ•°æ®
        self.raw_data = self._load_data()

        # å¤„ç†æ•°æ®
        self.processed_data = self._process_data()

        # åˆ›å»ºæ•°æ®é›†
        self.train_dataset = None
        self.val_dataset = None
        self.test_dataset = None

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        self.train_loader = None
        self.val_loader = None
        self.test_loader = None

        # æ ‡å‡†åŒ–å™¨
        self.scaler = StandardScaler() if scale else None

        # åˆå§‹åŒ–
        self._prepare_datasets()

    def _load_data(self) -> pd.DataFrame:
        """åŠ è½½æ•°æ®"""
        if self.data_path.endswith('.csv'):
            df = pd.read_csv(self.data_path)
        elif self.data_path.endswith('.pkl'):
            df = pd.read_pickle(self.data_path)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æ ¼å¼: {self.data_path}")

        return df

    def _process_data(self) -> np.ndarray:
        """å¤„ç†æ•°æ®"""
        df = self.raw_data

        # é€‰æ‹©ç‰¹å¾
        if self.features == 'M' or self.features == 'MS':
            # å¤šå˜é‡é¢„æµ‹
            data_cols = [col for col in df.columns if col != 'date']
            data = df[data_cols].values
        elif self.features == 'S':
            # å•å˜é‡é¢„æµ‹
            if self.target not in df.columns:
                raise ValueError(f"ç›®æ ‡åˆ— {self.target} ä¸å­˜åœ¨äºæ•°æ®ä¸­")
            data = df[[self.target]].values
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ç‰¹å¾ç±»å‹: {self.features}")

        return data.astype(np.float32)

    def _prepare_datasets(self):
        """å‡†å¤‡æ•°æ®é›†"""
        data = self.processed_data

        # æ ‡å‡†åŒ–
        if self.scale:
            train_size = int(len(data) * self.train_split)
            train_data = data[:train_size]
            self.scaler.fit(train_data)
            data = self.scaler.transform(data)

        # åˆ’åˆ†æ•°æ®é›†
        n = len(data)
        train_end = int(n * self.train_split)
        val_end = train_end + int(n * self.val_split)

        train_data = data[:train_end]
        val_data = data[train_end:val_end]
        test_data = data[val_end:]

        # åˆ›å»ºæ•°æ®é›†
        self.train_dataset = TimeSeriesDataset(
            train_data, self.seq_len, self.pred_len, self.label_len, self.stride
        )
        self.val_dataset = TimeSeriesDataset(
            val_data, self.seq_len, self.pred_len, self.label_len, self.stride
        )
        self.test_dataset = TimeSeriesDataset(
            test_data, self.seq_len, self.pred_len, self.label_len, self.stride
        )

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        self.train_loader = DataLoader(
            self.train_dataset,
            batch_size=self.batch_size,
            shuffle=self.shuffle,
            num_workers=0,  # Windowsä¸‹è®¾ç½®ä¸º0é¿å…é—®é¢˜
            pin_memory=True
        )

        self.val_loader = DataLoader(
            self.val_dataset,
            batch_size=self.batch_size,
            shuffle=False,
            num_workers=0,
            pin_memory=True
        )

        self.test_loader = DataLoader(
            self.test_dataset,
            batch_size=self.batch_size,
            shuffle=False,
            num_workers=0,
            pin_memory=True
        )

    def get_train_loader(self) -> DataLoader:
        """è·å–è®­ç»ƒæ•°æ®åŠ è½½å™¨"""
        return self.train_loader

    def get_val_loader(self) -> DataLoader:
        """è·å–éªŒè¯æ•°æ®åŠ è½½å™¨"""
        return self.val_loader

    def get_test_loader(self) -> DataLoader:
        """è·å–æµ‹è¯•æ•°æ®åŠ è½½å™¨"""
        return self.test_loader

    def inverse_transform(self, data: np.ndarray) -> np.ndarray:
        """åæ ‡å‡†åŒ–"""
        if self.scaler and self.scale:
            return self.scaler.inverse_transform(data)
        return data

    def get_data_info(self) -> Dict[str, Any]:
        """è·å–æ•°æ®ä¿¡æ¯"""
        return {
            'original_shape': self.raw_data.shape,
            'processed_shape': self.processed_data.shape,
            'n_features': self.processed_data.shape[1],
            'train_samples': len(self.train_dataset) if self.train_dataset else 0,
            'val_samples': len(self.val_dataset) if self.val_dataset else 0,
            'test_samples': len(self.test_dataset) if self.test_dataset else 0,
            'feature_names': list(self.raw_data.columns),
            'target_column': self.target
        }

    def print_info(self):
        """æ‰“å°æ•°æ®ä¿¡æ¯"""
        info = self.get_data_info()

        print("ğŸ“Š æ•°æ®ä¿¡æ¯:")
        print(f"   åŸå§‹æ•°æ®å½¢çŠ¶: {info['original_shape']}")
        print(f"   å¤„ç†æ•°æ®å½¢çŠ¶: {info['processed_shape']}")
        print(f"   ç‰¹å¾æ•°é‡: {info['n_features']}")
        print(f"   è®­ç»ƒæ ·æœ¬æ•°: {info['train_samples']}")
        print(f"   éªŒè¯æ ·æœ¬æ•°: {info['val_samples']}")
        print(f"   æµ‹è¯•æ ·æœ¬æ•°: {info['test_samples']}")
        print(f"   ç‰¹å¾åˆ—: {info['feature_names']}")
        print(f"   ç›®æ ‡åˆ—: {info['target_column']}")


class BatchDataLoader:
    """æ‰¹é‡æ•°æ®åŠ è½½å™¨ï¼ˆç”¨äºå·²ç»åˆ†å‰²å¥½çš„æ•°æ®ï¼‰"""

    def __init__(self, train_data: np.ndarray, val_data: np.ndarray,
                 test_data: np.ndarray, batch_size: int = 32,
                 seq_len: int = 96, pred_len: int = 24, label_len: int = 48):
        """
        åˆå§‹åŒ–æ‰¹é‡æ•°æ®åŠ è½½å™¨

        å‚æ•°:
            train_data: è®­ç»ƒæ•°æ®
            val_data: éªŒè¯æ•°æ®
            test_data: æµ‹è¯•æ•°æ®
            batch_size: æ‰¹æ¬¡å¤§å°
            seq_len: è¾“å…¥åºåˆ—é•¿åº¦
            pred_len: é¢„æµ‹åºåˆ—é•¿åº¦
            label_len: æ ‡ç­¾åºåˆ—é•¿åº¦
        """
        self.batch_size = batch_size
        self.seq_len = seq_len
        self.pred_len = pred_len
        self.label_len = label_len

        # åˆ›å»ºæ•°æ®é›†
        self.train_dataset = TimeSeriesDataset(
            train_data, seq_len, pred_len, label_len
        )
        self.val_dataset = TimeSeriesDataset(
            val_data, seq_len, pred_len, label_len
        )
        self.test_dataset = TimeSeriesDataset(
            test_data, seq_len, pred_len, label_len
        )

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        self.train_loader = DataLoader(
            self.train_dataset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=0
        )

        self.val_loader = DataLoader(
            self.val_dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=0
        )

        self.test_loader = DataLoader(
            self.test_dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=0
        )

    def get_train_loader(self) -> DataLoader:
        """è·å–è®­ç»ƒæ•°æ®åŠ è½½å™¨"""
        return self.train_loader

    def get_val_loader(self) -> DataLoader:
        """è·å–éªŒè¯æ•°æ®åŠ è½½å™¨"""
        return self.val_loader

    def get_test_loader(self) -> DataLoader:
        """è·å–æµ‹è¯•æ•°æ®åŠ è½½å™¨"""
        return self.test_loader