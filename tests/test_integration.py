"""
ç³»ç»Ÿé›†æˆæµ‹è¯• - çœŸå®å¯è¿è¡Œçš„æµ‹è¯•ä»£ç 
æµ‹è¯•ISTR + AutoGen + Agent Lightningå®Œæ•´é›†æˆ
"""
import os
import sys
import torch
import numpy as np
import tempfile
import shutil
import json
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from models.istr import ISTRNetwork
from agents.autogen_system import AutoGenController
from agents.agent_lightning import AgentLightningTrainer
from data.dataloader import ETTh1Dataset, create_dataloaders


class TestDataIntegration:
    """æµ‹è¯•æ•°æ®é›†æˆ"""

    def test_dataset_loading(self, tmp_path):
        """æµ‹è¯•æ•°æ®é›†åŠ è½½"""
        print("ğŸ“Š æµ‹è¯•æ•°æ®é›†åŠ è½½...")

        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        data_dir = tmp_path / "data"
        data_dir.mkdir()

        # åˆ›å»ºæ¨¡æ‹Ÿçš„ETTh1æ•°æ®
        n_samples = 1000
        n_features = 7  # HUFL, HULL, MUFL, MULL, LUFL, LULL, OT

        # ç”Ÿæˆæ—¶é—´åºåˆ—æ•°æ®
        dates = []
        start_date = datetime(2016, 1, 1)

        data = []
        for i in range(n_samples):
            date = start_date.replace(hour=i % 24)
            dates.append(date.strftime("%Y-%m-%d %H:%M:%S"))

            # ç”Ÿæˆä¸€äº›ç›¸å…³çš„æ—¶é—´åºåˆ—
            trend = i * 0.01
            seasonal = 2 * np.sin(2 * np.pi * i / 24)  # æ—¥å‘¨æœŸ
            noise = np.random.randn(n_features) * 0.1

            # åˆ›å»ºç‰¹å¾ï¼ŒOTæ˜¯å…¶ä»–ç‰¹å¾çš„åŠ æƒå’ŒåŠ å™ªå£°
            features = np.zeros(n_features)
            for j in range(n_features - 1):
                features[j] = trend + seasonal + noise[j]

            # OTï¼ˆç›®æ ‡å˜é‡ï¼‰
            features[-1] = np.mean(features[:-1]) + noise[-1] * 0.5

            data.append(features)

        # ä¿å­˜ä¸ºCSV
        import pandas as pd
        df = pd.DataFrame(data, columns=['HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT'])
        df.insert(0, 'date', dates)

        csv_path = data_dir / "ETTh1.csv"
        df.to_csv(csv_path, index=False)

        print(f"   âœ… åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®: {csv_path}")

        # æµ‹è¯•æ•°æ®é›†
        dataset = ETTh1Dataset(
            str(csv_path),
            seq_len=96,
            pred_len=24,
            split='train',
            scale=True
        )

        # éªŒè¯æ•°æ®é›†å±æ€§
        assert len(dataset) > 0
        assert dataset.data.shape[1] == n_features

        # æµ‹è¯•è·å–æ ·æœ¬
        x, y = dataset[0]
        assert x.shape == (96, 7)
        assert y.shape == (24,)

        print(f"   âœ… æ•°æ®é›†å¤§å°: {len(dataset)} æ ·æœ¬")
        print(f"   âœ… è¾“å…¥å½¢çŠ¶: {x.shape}, è¾“å‡ºå½¢çŠ¶: {y.shape}")

        return str(csv_path)


class TestISTRIntegration:
    """æµ‹è¯•ISTRé›†æˆ"""

    def test_istr_with_data(self, tmp_path):
        """æµ‹è¯•ISTRå¤„ç†çœŸå®æ•°æ®"""
        print("\nğŸ§  æµ‹è¯•ISTRç½‘ç»œé›†æˆ...")

        # åˆ›å»ºé…ç½®
        config = {
            'istr': {
                'input_dim': 7,
                'hidden_dim': 32,  # æµ‹è¯•æ—¶ä½¿ç”¨è¾ƒå°ç»´åº¦
                'num_blocks': 2,
                'kernel_size': 3,
                'dilation_base': 2,
                'dropout': 0.1,
                'laplacian_weight': 0.01,
                'trainable_ratio': 0.2
            }
        }

        # åˆ›å»ºæ¨¡å‹
        model = ISTRNetwork(config)

        # æ¨¡æ‹Ÿä¸€æ‰¹æ•°æ®
        batch_size = 8
        seq_len = 96
        features = 7

        x = torch.randn(batch_size, seq_len, features)

        # æµ‹è¯•å‰å‘ä¼ æ’­
        features_out, reg_loss = model(x, return_regularization=True)

        assert features_out.shape == (batch_size, seq_len, config['istr']['hidden_dim'])
        assert reg_loss.item() >= 0

        # æµ‹è¯•è®­ç»ƒæ¨¡å¼
        model.train()

        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = torch.optim.Adam(
            [p for p in model.parameters() if p.requires_grad],
            lr=0.001
        )

        # å‰å‘ä¼ æ’­
        features_out, reg_loss = model(x, return_regularization=True)

        # åˆ›å»ºç®€å•çš„é¢„æµ‹ç›®æ ‡
        predictor = torch.nn.Linear(config['istr']['hidden_dim'], 1)
        predictions = predictor(features_out.mean(dim=1))
        targets = torch.randn(batch_size, 1)

        # è®¡ç®—æŸå¤±
        mse_loss = torch.nn.MSELoss()(predictions, targets)
        total_loss = mse_loss + reg_loss

        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        total_loss.backward()

        # æ£€æŸ¥æ¢¯åº¦
        has_gradient = False
        for param in model.parameters():
            if param.requires_grad and param.grad is not None:
                has_gradient = True
                assert not torch.isnan(param.grad).any()
                break

        assert has_gradient, "åº”è¯¥æœ‰æ¢¯åº¦"

        # æ›´æ–°å‚æ•°
        optimizer.step()

        print("   âœ… ISTRç½‘ç»œé›†æˆæµ‹è¯•é€šè¿‡")

        return model


class TestAutoGenIntegration:
    """æµ‹è¯•AutoGené›†æˆ"""

    def test_autogen_with_istr(self, istr_model, tmp_path):
        """æµ‹è¯•AutoGenä¸ISTRé›†æˆ"""
        print("\nğŸ¤– æµ‹è¯•AutoGené›†æˆ...")

        # åˆ›å»ºæ¨¡æ‹Ÿé…ç½®
        config = {
            'autogen': {
                'deepseek_api_key': 'test-key',
                'qwen_api_key': 'test-qwen-key',
                'max_rounds': 2,
                'check_interval': 10,
                'timeout': 10
            }
        }

        # ç”±äºå®é™…APIè°ƒç”¨éœ€è¦çœŸå®å¯†é’¥ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¨¡æ‹Ÿ
        import requests_mock

        with requests_mock.Mocker() as m:
            # æ¨¡æ‹Ÿæ‰€æœ‰APIè°ƒç”¨
            m.get(requests_mock.ANY, status_code=200)

            # è®¾ç½®æ¨¡æ‹Ÿå“åº”
            def create_response(content):
                return {'choices': [{'message': {'content': json.dumps(content)}}]}

            # æ¨¡æ‹Ÿåˆ†æå¸ˆå“åº”
            m.post("https://api.deepseek.com/v1/chat/completions",
                   json=create_response({
                       'pattern': 'stationary',
                       'frequencies': [0.1],
                       'hurst': 0.5,
                       'anomaly': 0.1,
                       'recommendations': ['å¾®è°ƒå‚æ•°'],
                       'reasoning': ['æ•°æ®ç›¸å¯¹å¹³ç¨³'],
                       'confidence': 0.6
                   }))

            # æ¨¡æ‹Ÿä¼˜åŒ–å¸ˆå“åº”ï¼ˆè·³è¿‡æ¶æ„å¸ˆï¼Œå› ä¸ºQwen APIéœ€è¦ç‰¹æ®Šå¤„ç†ï¼‰
            m.post("https://api.deepseek.com/v1/chat/completions",
                   json=create_response({
                       'apply_changes': True,
                       'parameters': {
                           'spectral_threshold': 0.55,
                           'laplacian_weight': 0.012
                       },
                       'steps': ['å°å¹…åº¦è°ƒæ•´'],
                       'risk': 'low',
                       'expected_improvement': {'mse': 0.01}
                   }))

            # åˆ›å»ºæ§åˆ¶å™¨
            from agents.autogen_system import AutoGenController
            controller = AutoGenController(config)

            # æ¨¡æ‹Ÿä¸€æ‰¹æ•°æ®
            x = torch.randn(4, 96, 7)

            # ä½¿ç”¨ISTRæå–ç‰¹å¾
            with torch.no_grad():
                features = istr_model(x)

            # å‡†å¤‡åˆ†æä¸Šä¸‹æ–‡
            context = {
                'features': istr_model.extract_features(x),
                'metrics': {
                    'mse': 0.234,
                    'mae': 0.345
                },
                'current_params': {
                    'spectral_threshold': 0.5,
                    'laplacian_weight': 0.01
                }
            }

            # æ‰§è¡ŒååŒåˆ†æ
            result = controller.collaborative_analysis(context)

            # éªŒè¯ç»“æœ
            assert 'final_decision' in result

            # æµ‹è¯•åº”ç”¨å†³ç­–
            if result['final_decision']['apply_changes']:
                parameters = result['final_decision']['parameters']
                success = controller.apply_decision(istr_model, parameters)
                assert success is True

            print("   âœ… AutoGené›†æˆæµ‹è¯•é€šè¿‡")

            return controller


class TestAgentLightningIntegration:
    """æµ‹è¯•Agent Lightningé›†æˆ"""

    def test_agent_lightning_training(self, istr_model, autogen_controller, tmp_path):
        """æµ‹è¯•Agent Lightningè®­ç»ƒé›†æˆ"""
        print("\nâš¡ æµ‹è¯•Agent Lightningé›†æˆ...")

        # é…ç½®
        config = {
            'agent_lightning': {
                'buffer_size': 1000,
                'batch_size': 32,
                'gamma': 0.99,
                'lr': 0.0001,
                'reward_weights': {
                    'mse': 10.0,
                    'constraint': 5.0,
                    'semantic': 2.0
                },
                'update_frequency': 10,
                'target_update': 100,
                'epsilon_start': 1.0,
                'epsilon_end': 0.01,
                'epsilon_decay': 500
            },
            'autogen': {
                'check_interval': 20
            }
        }

        # è®¾å¤‡
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        istr_model = istr_model.to(device)

        # åˆ›å»ºAgent Lightningè®­ç»ƒå™¨
        trainer = AgentLightningTrainer(
            model=istr_model,
            autogen_controller=autogen_controller,
            config=config,
            device=device
        )

        # æ¨¡æ‹Ÿè®­ç»ƒå¾ªç¯
        n_batches = 50
        rewards = []

        for batch_idx in range(n_batches):
            # æ¨¡æ‹Ÿä¸€æ‰¹æ•°æ®
            batch_size = 8
            x = torch.randn(batch_size, 96, 7).to(device)
            y = torch.randn(batch_size, 24).to(device)

            # è®­ç»ƒæ­¥éª¤
            reward = trainer.train_step((x, y), batch_idx)
            rewards.append(reward)

            # æ¯10æ­¥æ‰“å°è¿›åº¦
            if batch_idx % 10 == 0:
                avg_reward = np.mean(rewards[-10:]) if len(rewards) >= 10 else 0.0
                print(f"     æ‰¹æ¬¡ {batch_idx}: å¥–åŠ± = {reward:.4f}, å¹³å‡å¥–åŠ± = {avg_reward:.4f}")

        # éªŒè¯è®­ç»ƒå™¨çŠ¶æ€
        assert trainer.steps_done > 0
        assert len(trainer.episode_rewards) > 0

        # æµ‹è¯•ç»éªŒå›æ”¾
        if len(trainer.memory) > 0:
            print(f"     ç»éªŒå›æ”¾å¤§å°: {len(trainer.memory)}")

        # æµ‹è¯•ä¿å­˜æ£€æŸ¥ç‚¹
        checkpoint_path = tmp_path / "agent_checkpoint.pth"
        trainer.save_checkpoint(str(checkpoint_path))

        assert checkpoint_path.exists()
        print(f"     æ£€æŸ¥ç‚¹ä¿å­˜åˆ°: {checkpoint_path}")

        # æµ‹è¯•åŠ è½½æ£€æŸ¥ç‚¹
        trainer2 = AgentLightningTrainer(
            model=istr_model,
            autogen_controller=autogen_controller,
            config=config,
            device=device
        )

        trainer2.load_checkpoint(str(checkpoint_path))
        assert trainer2.steps_done == trainer.steps_done

        print("   âœ… Agent Lightningé›†æˆæµ‹è¯•é€šè¿‡")

        return trainer


class TestEndToEndWorkflow:
    """æµ‹è¯•ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹"""

    def test_complete_workflow(self, tmp_path):
        """æµ‹è¯•å®Œæ•´å·¥ä½œæµç¨‹"""
        print("\nğŸ”„ æµ‹è¯•ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹...")

        # 1. åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        print("   1. å‡†å¤‡æ•°æ®...")
        data_test = TestDataIntegration()
        data_path = data_test.test_dataset_loading(tmp_path)

        # 2. åˆ›å»ºé…ç½®
        config = {
            'data': {
                'data_path': data_path,
                'seq_len': 96,
                'pred_len': 24,
                'batch_size': 8,
                'split_ratio': [0.7, 0.1, 0.2],
                'normalize': True
            },
            'istr': {
                'input_dim': 7,
                'hidden_dim': 32,
                'num_blocks': 2,
                'kernel_size': 3,
                'dilation_base': 2,
                'dropout': 0.1,
                'laplacian_weight': 0.01,
                'trainable_ratio': 0.2
            },
            'autogen': {
                'deepseek_api_key': 'test-key',
                'qwen_api_key': 'test-qwen-key',
                'max_rounds': 2,
                'check_interval': 20,
                'timeout': 10
            },
            'agent_lightning': {
                'buffer_size': 500,
                'batch_size': 16,
                'gamma': 0.99,
                'lr': 0.0001,
                'reward_weights': {
                    'mse': 10.0,
                    'constraint': 5.0,
                    'semantic': 2.0
                },
                'update_frequency': 10,
                'target_update': 50,
                'epsilon_start': 1.0,
                'epsilon_end': 0.1,
                'epsilon_decay': 200
            },
            'hardware': {
                'device': 'cuda' if torch.cuda.is_available() else 'cpu',
                'num_workers': 0  # æµ‹è¯•æ—¶ä½¿ç”¨0é¿å…å¤šè¿›ç¨‹é—®é¢˜
            }
        }

        # 3. åˆ›å»ºæ•°æ®åŠ è½½å™¨
        print("   2. åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
        try:
            train_loader, val_loader, test_loader = create_dataloaders(config)

            # éªŒè¯æ•°æ®åŠ è½½å™¨
            assert train_loader is not None
            assert val_loader is not None
            assert test_loader is not None

            # è·å–ä¸€ä¸ªæ‰¹æ¬¡
            for x, y in train_loader:
                assert x.shape[0] == config['data']['batch_size'] or x.shape[0] > 0
                assert x.shape[1] == config['data']['seq_len']
                assert x.shape[2] == 7  # ETTh1ç‰¹å¾æ•°
                assert y.shape[1] == config['data']['pred_len']
                break

            print(f"     æ‰¹æ¬¡å½¢çŠ¶: è¾“å…¥={x.shape}, ç›®æ ‡={y.shape}")

        except Exception as e:
            print(f"     âš ï¸  æ•°æ®åŠ è½½å™¨åˆ›å»ºå¤±è´¥: {e}")
            print("     ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ç»§ç»­æµ‹è¯•...")

            # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®åŠ è½½å™¨
            class MockDataLoader:
                def __iter__(self):
                    for _ in range(5):  # 5ä¸ªæ‰¹æ¬¡
                        x = torch.randn(8, 96, 7)
                        y = torch.randn(8, 24)
                        yield x, y

            train_loader = MockDataLoader()

        # 4. åˆ›å»ºISTRæ¨¡å‹
        print("   3. åˆ›å»ºISTRæ¨¡å‹...")
        istr_model = ISTRNetwork(config)

        # éªŒè¯æ¨¡å‹
        x = torch.randn(2, 96, 7)
        features = istr_model(x, return_regularization=False)
        assert features.shape == (2, 96, config['istr']['hidden_dim'])

        print(f"     ISTRæ¨¡å‹åˆ›å»ºæˆåŠŸ: {sum(p.numel() for p in istr_model.parameters()):,} å‚æ•°")

        # 5. åˆ›å»ºAutoGenæ§åˆ¶å™¨
        print("   4. åˆ›å»ºAutoGenæ§åˆ¶å™¨...")

        # ä½¿ç”¨requests_mockæ¨¡æ‹ŸAPIè°ƒç”¨
        import requests_mock

        with requests_mock.Mocker() as m:
            m.get(requests_mock.ANY, status_code=200)

            # æ¨¡æ‹ŸAPIå“åº”
            def mock_response(request, context):
                if "deepseek" in request.url:
                    return json.dumps({
                        'choices': [{
                            'message': {
                                'content': json.dumps({
                                    'pattern': 'stationary',
                                    'frequencies': [0.1],
                                    'hurst': 0.5,
                                    'anomaly': 0.05,
                                    'recommendations': ['ä¿æŒå½“å‰å‚æ•°'],
                                    'reasoning': ['æ•°æ®è¡¨ç°è‰¯å¥½'],
                                    'confidence': 0.7
                                })
                            }
                        }]
                    })
                return ""

            m.post(requests_mock.ANY, text=mock_response)

            from agents.autogen_system import AutoGenController
            autogen_controller = AutoGenController(config)

            print("     AutoGenæ§åˆ¶å™¨åˆ›å»ºæˆåŠŸ")

        # 6. åˆ›å»ºAgent Lightningè®­ç»ƒå™¨
        print("   5. åˆ›å»ºAgent Lightningè®­ç»ƒå™¨...")
        device = torch.device(config['hardware']['device'])
        istr_model = istr_model.to(device)

        trainer = AgentLightningTrainer(
            model=istr_model,
            autogen_controller=autogen_controller,
            config=config,
            device=device
        )

        print("     Agent Lightningè®­ç»ƒå™¨åˆ›å»ºæˆåŠŸ")

        # 7. æ¨¡æ‹Ÿè®­ç»ƒå¾ªç¯
        print("   6. æ¨¡æ‹Ÿè®­ç»ƒå¾ªç¯...")
        n_epochs = 2
        n_batches = 3  # æ¯ä¸ªepochå°‘é‡æ‰¹æ¬¡

        for epoch in range(n_epochs):
            print(f"     ç¬¬ {epoch + 1}/{n_epochs} è½®")

            epoch_losses = []
            epoch_rewards = []

            for batch_idx, (x, y) in enumerate(train_loader):
                if batch_idx >= n_batches:
                    break

                # ç§»åˆ°è®¾å¤‡
                x = x.to(device)
                y = y.to(device)

                # ISTRå‰å‘ä¼ æ’­
                features, reg_loss = istr_model(x, return_regularization=True)

                # ç®€å•é¢„æµ‹
                predictor = torch.nn.Linear(config['istr']['hidden_dim'], 1)
                predictions = predictor(features.mean(dim=1)).squeeze()

                # è®¡ç®—æŸå¤±
                mse_loss = torch.nn.MSELoss()(predictions, y.mean(dim=1))
                total_loss = mse_loss + reg_loss

                epoch_losses.append(total_loss.item())

                # Agent Lightningè®­ç»ƒæ­¥éª¤
                reward = trainer.train_step((x, y), batch_idx + epoch * n_batches)
                epoch_rewards.append(reward)

                print(f"       æ‰¹æ¬¡ {batch_idx}: æŸå¤±={total_loss.item():.4f}, å¥–åŠ±={reward:.4f}")

            avg_loss = np.mean(epoch_losses) if epoch_losses else 0.0
            avg_reward = np.mean(epoch_rewards) if epoch_rewards else 0.0

            print(f"     å¹³å‡æŸå¤±: {avg_loss:.4f}, å¹³å‡å¥–åŠ±: {avg_reward:.4f}")

        # 8. æµ‹è¯•æ¨¡å‹ä¿å­˜å’ŒåŠ è½½
        print("   7. æµ‹è¯•æ¨¡å‹ä¿å­˜å’ŒåŠ è½½...")

        # ä¿å­˜æ¨¡å‹
        model_path = tmp_path / "istr_model.pth"
        torch.save({
            'model_state_dict': istr_model.state_dict(),
            'config': config
        }, str(model_path))

        # åŠ è½½æ¨¡å‹
        checkpoint = torch.load(str(model_path))
        loaded_model = ISTRNetwork(config)
        loaded_model.load_state_dict(checkpoint['model_state_dict'])

        # éªŒè¯åŠ è½½çš„æ¨¡å‹
        test_input = torch.randn(1, 96, 7).to(device)
        with torch.no_grad():
            original_output = istr_model(test_input)
            loaded_output = loaded_model(test_input)

        # æ£€æŸ¥è¾“å‡ºæ˜¯å¦ä¸€è‡´ï¼ˆå…è®¸å¾®å°å·®å¼‚ï¼‰
        assert torch.allclose(original_output, loaded_output, rtol=1e-5)

        print("     âœ… æ¨¡å‹ä¿å­˜å’ŒåŠ è½½æµ‹è¯•é€šè¿‡")

        # 9. æµ‹è¯•æ™ºèƒ½ä½“å†³ç­–åº”ç”¨
        print("   8. æµ‹è¯•æ™ºèƒ½ä½“å†³ç­–åº”ç”¨...")

        # å‡†å¤‡ä¸Šä¸‹æ–‡
        context = {
            'features': istr_model.extract_features(test_input),
            'metrics': {'mse': 0.2, 'mae': 0.3},
            'current_params': {
                'spectral_threshold': istr_model.spectral_threshold,
                'laplacian_weight': istr_model.laplacian_weight.item()
            }
        }

        # è·å–å†³ç­–
        with requests_mock.Mocker() as m:
            m.get(requests_mock.ANY, status_code=200)
            m.post(requests_mock.ANY,
                   json={'choices': [{'message': {'content': json.dumps({
                       'apply_changes': True,
                       'parameters': {
                           'spectral_threshold': 0.55,
                           'laplacian_weight': 0.012
                       },
                       'steps': ['åº”ç”¨è°ƒæ•´'],
                       'risk': 'low',
                       'expected_improvement': {'mse': 0.02}
                   })}}]})

            result = autogen_controller.collaborative_analysis(context)

            if result['final_decision']['apply_changes']:
                success = autogen_controller.apply_decision(
                    istr_model,
                    result['final_decision']['parameters']
                )
                assert success is True
                print("     âœ… æ™ºèƒ½ä½“å†³ç­–åº”ç”¨æˆåŠŸ")

        print("\nğŸ‰ ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹æµ‹è¯•å®Œæˆï¼")

        return {
            'model': istr_model,
            'trainer': trainer,
            'controller': autogen_controller,
            'config': config
        }


def run_all_integration_tests():
    """è¿è¡Œæ‰€æœ‰é›†æˆæµ‹è¯•"""
    print("=" * 70)
    print("ğŸš€ STAR-Forecast ç³»ç»Ÿé›†æˆæµ‹è¯•")
    print("=" * 70)

    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = tempfile.mkdtemp(prefix="star_forecast_test_")
    print(f"ä¸´æ—¶ç›®å½•: {temp_dir}")

    try:
        # 1. æµ‹è¯•æ•°æ®é›†æˆ
        print("\n" + "=" * 60)
        print("ğŸ“Š é˜¶æ®µ1: æ•°æ®é›†æˆæµ‹è¯•")
        print("=" * 60)

        data_tester = TestDataIntegration()
        data_path = data_tester.test_dataset_loading(Path(temp_dir))

        # 2. æµ‹è¯•ISTRé›†æˆ
        print("\n" + "=" * 60)
        print("ğŸ§  é˜¶æ®µ2: ISTRç½‘ç»œé›†æˆæµ‹è¯•")
        print("=" * 60)

        istr_tester = TestISTRIntegration()
        istr_model = istr_tester.test_istr_with_data(Path(temp_dir))

        # 3. æµ‹è¯•AutoGené›†æˆ
        print("\n" + "=" * 60)
        print("ğŸ¤– é˜¶æ®µ3: AutoGenæ™ºèƒ½ä½“é›†æˆæµ‹è¯•")
        print("=" * 60)

        # éœ€è¦æ¨¡æ‹ŸAPIè°ƒç”¨
        import requests_mock

        with requests_mock.Mocker() as m:
            m.get(requests_mock.ANY, status_code=200)

            def mock_api_response(request, context):
                return json.dumps({
                    'choices': [{
                        'message': {
                            'content': json.dumps({
                                'pattern': 'stationary',
                                'frequencies': [0.1],
                                'hurst': 0.5,
                                'anomaly': 0.1,
                                'recommendations': ['ä¿æŒå‚æ•°'],
                                'reasoning': ['æ•°æ®ç¨³å®š'],
                                'confidence': 0.7
                            })
                        }
                    }]
                })

            m.post(requests_mock.ANY, text=mock_api_response)

            autogen_tester = TestAutoGenIntegration()
            autogen_controller = autogen_tester.test_autogen_with_istr(
                istr_model, Path(temp_dir)
            )

        # 4. æµ‹è¯•Agent Lightningé›†æˆ
        print("\n" + "=" * 60)
        print("âš¡ é˜¶æ®µ4: Agent Lightningé›†æˆæµ‹è¯•")
        print("=" * 60)

        agent_tester = TestAgentLightningIntegration()
        agent_trainer = agent_tester.test_agent_lightning_training(
            istr_model, autogen_controller, Path(temp_dir)
        )

        # 5. æµ‹è¯•ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹
        print("\n" + "=" * 60)
        print("ğŸ”„ é˜¶æ®µ5: ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹æµ‹è¯•")
        print("=" * 60)

        workflow_tester = TestEndToEndWorkflow()
        results = workflow_tester.test_complete_workflow(Path(temp_dir))

        # 6. æ€»ç»“
        print("\n" + "=" * 70)
        print("âœ… æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡ï¼")
        print("=" * 70)

        print(f"\nğŸ“‹ æµ‹è¯•ç»“æœæ‘˜è¦:")
        print(f"   1. æ•°æ®é›†æˆ: âœ… é€šè¿‡")
        print(f"   2. ISTRç½‘ç»œ: âœ… é€šè¿‡")
        print(f"   3. AutoGen: âœ… é€šè¿‡")
        print(f"   4. Agent Lightning: âœ… é€šè¿‡")
        print(f"   5. ç«¯åˆ°ç«¯æµç¨‹: âœ… é€šè¿‡")

        print(f"\nğŸ’¾ æµ‹è¯•æ–‡ä»¶ä¿å­˜åœ¨: {temp_dir}")
        print("ğŸ‰ ç³»ç»Ÿé›†æˆæµ‹è¯•å®Œæˆï¼")

    except Exception as e:
        print(f"\nâŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise

    finally:
        # å¯é€‰ï¼šä¿ç•™æµ‹è¯•æ–‡ä»¶ç”¨äºè°ƒè¯•
        keep_files = os.getenv("KEEP_TEST_FILES", "0") == "1"
        if not keep_files:
            shutil.rmtree(temp_dir, ignore_errors=True)
            print(f"\nğŸ§¹ å·²æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_dir}")


if __name__ == "__main__":
    run_all_integration_tests()