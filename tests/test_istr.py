"""
ISTRç½‘ç»œå•å…ƒæµ‹è¯• - çœŸå®å¯è¿è¡Œçš„æµ‹è¯•ä»£ç 
æµ‹è¯•TCN + æ‹‰æ™®æ‹‰æ–¯æ­£åˆ™åŒ–çš„å®Œæ•´åŠŸèƒ½
"""
import torch
import torch.nn as nn
import numpy as np
import pytest
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from models.istr import ISTRNetwork, TemporalBlock, SpectralGate


class TestTemporalBlock:
    """æµ‹è¯•TCNåŸºç¡€å—"""

    def test_initialization(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        block = TemporalBlock(
            n_inputs=64,
            n_outputs=64,
            kernel_size=3,
            stride=1,
            dilation=1,
            dropout=0.1
        )

        assert hasattr(block, 'conv1')
        assert hasattr(block, 'conv2')
        assert hasattr(block, 'bn1')
        assert hasattr(block, 'bn2')
        assert block.conv1.in_channels == 64
        assert block.conv1.out_channels == 64

    def test_forward_pass(self):
        """æµ‹è¯•å‰å‘ä¼ æ’­"""
        block = TemporalBlock(64, 64, 3, 1, 1, 0.1)

        # æ¨¡æ‹Ÿè¾“å…¥: [batch=2, channels=64, seq_len=96]
        x = torch.randn(2, 64, 96)

        # å‰å‘ä¼ æ’­
        output = block(x)

        # éªŒè¯è¾“å‡ºå½¢çŠ¶
        assert output.shape == (2, 64, 96)

        # éªŒè¯æ®‹å·®è¿æ¥
        assert not torch.isnan(output).any()
        assert not torch.isinf(output).any()

    def test_residual_connection(self):
        """æµ‹è¯•æ®‹å·®è¿æ¥"""
        # è¾“å…¥è¾“å‡ºç»´åº¦ä¸åŒ
        block = TemporalBlock(32, 64, 3, 1, 1, 0.1)
        x = torch.randn(2, 32, 96)
        output = block(x)

        assert output.shape == (2, 64, 96)
        assert block.downsample is not None  # åº”è¯¥æœ‰ä¸‹é‡‡æ ·å±‚

    def test_causal_dilation(self):
        """æµ‹è¯•å› æœè†¨èƒ€å·ç§¯"""
        # è†¨èƒ€ç‡ä¸º2
        block = TemporalBlock(64, 64, 3, 1, 2, 0.1)

        # è®¡ç®—æœŸæœ›çš„padding
        expected_padding = (3 - 1) * 2  # (kernel_size - 1) * dilation
        actual_padding = block.conv1.padding[0]

        assert actual_padding == expected_padding


class TestSpectralGate:
    """æµ‹è¯•è°±é—¨æ§æœºåˆ¶"""

    def test_initialization(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        gate = SpectralGate(hidden_dim=64, threshold=0.5)

        assert gate.hidden_dim == 64
        assert gate.threshold == 0.5
        assert hasattr(gate, 'freq_proj')
        assert hasattr(gate, 'time_proj')
        assert hasattr(gate, 'gate_net')

    def test_forward_pass(self):
        """æµ‹è¯•å‰å‘ä¼ æ’­"""
        gate = SpectralGate(64, 0.5)

        # æ¨¡æ‹Ÿè¾“å…¥: [batch=2, seq_len=96, hidden=64]
        x = torch.randn(2, 96, 64)

        output = gate(x)

        # éªŒè¯è¾“å‡ºå½¢çŠ¶
        assert output.shape == (2, 96, 64)

        # éªŒè¯é—¨æ§å€¼åœ¨[0,1]èŒƒå›´å†…
        x_fft = torch.fft.rfft(x, dim=1)
        x_fft_mag = torch.abs(x_fft)
        freq_features = torch.mean(x_fft_mag, dim=1)

        # é—¨æ§åº”è¯¥æ˜¯åŸºäºç‰¹å¾çš„
        assert not torch.isnan(output).any()
        assert not torch.isinf(output).any()

        # éªŒè¯é—¨æ§æ•ˆæœï¼ˆåº”è¯¥æ”¹å˜è¾“å…¥å€¼ï¼‰
        if gate.threshold > 0:
            assert not torch.allclose(output, x, rtol=1e-5)


class TestISTRNetwork:
    """æµ‹è¯•å®Œæ•´ISTRç½‘ç»œ"""

    @pytest.fixture
    def config(self):
        """æµ‹è¯•é…ç½®"""
        return {
            'istr': {
                'input_dim': 7,  # ETTh1ç‰¹å¾æ•°
                'hidden_dim': 64,  # éšè—ç»´åº¦
                'num_blocks': 2,  # æµ‹è¯•æ—¶ä½¿ç”¨è¾ƒå°‘å—
                'kernel_size': 3,
                'dilation_base': 2,
                'dropout': 0.1,
                'laplacian_weight': 0.01,
                'trainable_ratio': 0.1  # æµ‹è¯•æ—¶è®­ç»ƒæ›´å¤šå‚æ•°
            }
        }

    @pytest.fixture
    def sample_input(self):
        """æµ‹è¯•è¾“å…¥"""
        # æ¨¡æ‹ŸETTh1æ•°æ®: [batch=4, seq_len=96, features=7]
        return torch.randn(4, 96, 7)

    def test_initialization(self, config):
        """æµ‹è¯•ç½‘ç»œåˆå§‹åŒ–"""
        model = ISTRNetwork(config)

        assert hasattr(model, 'input_proj')
        assert hasattr(model, 'tcn_layers')
        assert hasattr(model, 'spectral_gate')
        assert hasattr(model, 'output_norm')
        assert hasattr(model, 'laplacian_weight')

        # éªŒè¯å±‚æ•°
        assert len(model.tcn_layers) == config['istr']['num_blocks']

        # éªŒè¯å‚æ•°å†»ç»“
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        expected_trainable = int(total_params * config['istr']['trainable_ratio'])

        # å…è®¸ä¸€äº›è¯¯å·®
        assert abs(trainable_params - expected_trainable) / total_params < 0.05

    def test_forward_pass(self, config, sample_input):
        """æµ‹è¯•å‰å‘ä¼ æ’­"""
        model = ISTRNetwork(config)

        # åŸºç¡€å‰å‘ä¼ æ’­
        features = model(sample_input, return_regularization=False)

        # éªŒè¯è¾“å‡ºå½¢çŠ¶
        batch_size, seq_len, _ = sample_input.shape
        hidden_dim = config['istr']['hidden_dim']
        assert features.shape == (batch_size, seq_len, hidden_dim)

    def test_forward_with_regularization(self, config, sample_input):
        """æµ‹è¯•å¸¦æ­£åˆ™åŒ–çš„å‰å‘ä¼ æ’­"""
        model = ISTRNetwork(config)

        # å¸¦æ­£åˆ™åŒ–çš„å‰å‘ä¼ æ’­
        features, reg_loss = model(sample_input, return_regularization=True)

        # éªŒè¯è¾“å‡º
        assert features.shape[0] == sample_input.shape[0]
        assert isinstance(reg_loss, torch.Tensor)
        assert reg_loss.item() >= 0  # æ­£åˆ™åŒ–æŸå¤±åº”ä¸ºéè´Ÿ

        # æµ‹è¯•è®­ç»ƒæ¨¡å¼
        model.train()
        features_train, reg_loss_train = model(sample_input, return_regularization=True)
        assert reg_loss_train.item() >= 0

    def test_extract_features(self, config, sample_input):
        """æµ‹è¯•ç‰¹å¾æå–"""
        model = ISTRNetwork(config)

        features = model.extract_features(sample_input)

        # éªŒè¯ç‰¹å¾å­—å…¸ç»“æ„
        assert isinstance(features, dict)
        assert 'shape' in features
        assert 'statistics' in features
        assert 'frequency' in features

        # éªŒè¯å½¢çŠ¶ä¿¡æ¯
        assert features['shape'] == list(sample_input.shape)

        # éªŒè¯ç»Ÿè®¡ä¿¡æ¯
        stats = features['statistics']
        assert 'mean' in stats
        assert 'std' in stats
        assert 'autocorr' in stats

        # å‡å€¼å’Œæ ‡å‡†å·®åº”ä¸ºåˆ—è¡¨
        assert isinstance(stats['mean'], list)
        assert len(stats['mean']) == sample_input.shape[-1]

    def test_update_parameters(self, config, sample_input):
        """æµ‹è¯•å‚æ•°æ›´æ–°"""
        model = ISTRNetwork(config)

        # è·å–åˆå§‹å‚æ•°
        initial_threshold = model.spectral_threshold
        initial_weight = model.laplacian_weight.item()

        # æ›´æ–°å‚æ•°
        model.update_parameters(
            spectral_threshold=0.7,
            laplacian_weight=0.02
        )

        # éªŒè¯å‚æ•°å·²æ›´æ–°
        assert model.spectral_threshold == 0.7
        assert abs(model.laplacian_weight.item() - 0.02) < 1e-6

        # éªŒè¯è®¡æ•°å™¨
        assert model.adaptation_count.item() == 1

    def test_gradient_flow(self, config, sample_input):
        """æµ‹è¯•æ¢¯åº¦æµ"""
        model = ISTRNetwork(config)

        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = torch.optim.Adam(
            [p for p in model.parameters() if p.requires_grad],
            lr=0.001
        )

        # å‰å‘ä¼ æ’­
        features, reg_loss = model(sample_input, return_regularization=True)

        # åˆ›å»ºç®€å•çš„é¢„æµ‹å¤´
        predictor = nn.Linear(config['istr']['hidden_dim'], 1)

        # é¢„æµ‹ç›®æ ‡ï¼ˆç®€åŒ–ï¼‰
        predictions = predictor(features.mean(dim=1))  # [batch, 1]
        dummy_target = torch.randn(predictions.shape)

        # è®¡ç®—æŸå¤±
        mse_loss = nn.MSELoss()(predictions, dummy_target)
        total_loss = mse_loss + reg_loss

        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        total_loss.backward()

        # æ£€æŸ¥æ¢¯åº¦
        has_gradient = False
        for name, param in model.named_parameters():
            if param.requires_grad and param.grad is not None:
                has_gradient = True
                assert not torch.isnan(param.grad).any()
                assert not torch.isinf(param.grad).any()

        assert has_gradient, "è‡³å°‘æœ‰ä¸€äº›å‚æ•°åº”è¯¥æœ‰æ¢¯åº¦"

        # ä¼˜åŒ–æ­¥éª¤
        optimizer.step()

    def test_mixed_precision(self, config, sample_input):
        """æµ‹è¯•æ··åˆç²¾åº¦è®­ç»ƒ"""
        if not torch.cuda.is_available():
            pytest.skip("CUDAä¸å¯ç”¨ï¼Œè·³è¿‡æ··åˆç²¾åº¦æµ‹è¯•")

        from torch.cuda.amp import autocast, GradScaler

        model = ISTRNetwork(config).cuda()
        scaler = GradScaler()

        # åˆ›å»ºå¯è®­ç»ƒå‚æ•°ä¼˜åŒ–å™¨
        trainable_params = [p for p in model.parameters() if p.requires_grad]
        optimizer = torch.optim.Adam(trainable_params, lr=0.001)

        # å°†è¾“å…¥ç§»åˆ°GPU
        x = sample_input.cuda()

        # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
        with autocast():
            features, reg_loss = model(x, return_regularization=True)

            # ç®€å•çš„æŸå¤±è®¡ç®—
            loss = features.mean() + reg_loss

        # æ··åˆç²¾åº¦åå‘ä¼ æ’­
        optimizer.zero_grad()
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        # éªŒè¯ç»“æœ
        assert not torch.isnan(features).any()
        assert not torch.isinf(features).any()

    def test_batch_variation(self, config):
        """æµ‹è¯•ä¸åŒæ‰¹é‡å¤§å°çš„å¤„ç†"""
        model = ISTRNetwork(config)

        # æµ‹è¯•ä¸åŒæ‰¹é‡å¤§å°
        batch_sizes = [1, 2, 8, 16]

        for batch_size in batch_sizes:
            x = torch.randn(batch_size, 96, 7)
            features = model(x, return_regularization=False)

            assert features.shape == (batch_size, 96, config['istr']['hidden_dim'])

    def test_sequence_length_variation(self, config):
        """æµ‹è¯•ä¸åŒåºåˆ—é•¿åº¦çš„å¤„ç†"""
        model = ISTRNetwork(config)

        seq_lengths = [32, 64, 96, 128]

        for seq_len in seq_lengths:
            x = torch.randn(4, seq_len, 7)
            features = model(x, return_regularization=False)

            assert features.shape == (4, seq_len, config['istr']['hidden_dim'])


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸ§ª å¼€å§‹ISTRç½‘ç»œæµ‹è¯•...")

    # åˆ›å»ºæµ‹è¯•é…ç½®
    config = {
        'istr': {
            'input_dim': 7,
            'hidden_dim': 64,
            'num_blocks': 2,
            'kernel_size': 3,
            'dilation_base': 2,
            'dropout': 0.1,
            'laplacian_weight': 0.01,
            'trainable_ratio': 0.1
        }
    }

    # è¿è¡ŒTemporalBlockæµ‹è¯•
    print("1. æµ‹è¯•TemporalBlock...")
    block_tester = TestTemporalBlock()

    block_tester.test_initialization()
    print("   âœ… TemporalBlockåˆå§‹åŒ–æµ‹è¯•é€šè¿‡")

    block_tester.test_forward_pass()
    print("   âœ… TemporalBlockå‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡")

    block_tester.test_residual_connection()
    print("   âœ… TemporalBlockæ®‹å·®è¿æ¥æµ‹è¯•é€šè¿‡")

    # è¿è¡ŒSpectralGateæµ‹è¯•
    print("2. æµ‹è¯•SpectralGate...")
    gate_tester = TestSpectralGate()

    gate_tester.test_initialization()
    print("   âœ… SpectralGateåˆå§‹åŒ–æµ‹è¯•é€šè¿‡")

    gate_tester.test_forward_pass()
    print("   âœ… SpectralGateå‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡")

    # è¿è¡ŒISTRNetworkæµ‹è¯•
    print("3. æµ‹è¯•ISTRNetwork...")
    istr_tester = TestISTRNetwork()

    sample_input = torch.randn(4, 96, 7)

    # æµ‹è¯•åˆå§‹åŒ–
    model = istr_tester.test_initialization(config)
    print("   âœ… ISTRNetworkåˆå§‹åŒ–æµ‹è¯•é€šè¿‡")

    # æµ‹è¯•å‰å‘ä¼ æ’­
    features = istr_tester.test_forward_pass(config, sample_input)
    print("   âœ… ISTRNetworkå‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡")

    # æµ‹è¯•ç‰¹å¾æå–
    features_dict = istr_tester.test_extract_features(config, sample_input)
    print("   âœ… ISTRNetworkç‰¹å¾æå–æµ‹è¯•é€šè¿‡")

    # æµ‹è¯•å‚æ•°æ›´æ–°
    istr_tester.test_update_parameters(config, sample_input)
    print("   âœ… ISTRNetworkå‚æ•°æ›´æ–°æµ‹è¯•é€šè¿‡")

    # æµ‹è¯•æ¢¯åº¦æµ
    istr_tester.test_gradient_flow(config, sample_input)
    print("   âœ… ISTRNetworkæ¢¯åº¦æµæµ‹è¯•é€šè¿‡")

    # æµ‹è¯•æ‰¹é‡å˜åŒ–
    istr_tester.test_batch_variation(config)
    print("   âœ… ISTRNetworkæ‰¹é‡å˜åŒ–æµ‹è¯•é€šè¿‡")

    # æµ‹è¯•åºåˆ—é•¿åº¦å˜åŒ–
    istr_tester.test_sequence_length_variation(config)
    print("   âœ… ISTRNetworkåºåˆ—é•¿åº¦å˜åŒ–æµ‹è¯•é€šè¿‡")

    print("\nğŸ‰ æ‰€æœ‰ISTRç½‘ç»œæµ‹è¯•é€šè¿‡ï¼")


if __name__ == "__main__":
    run_all_tests()