"""
STAR-Forecast Webç•Œé¢
ä½¿ç”¨Streamlitæ„å»ºäº¤äº’å¼å¯è§†åŒ–ç•Œé¢
"""
import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import torch
import yaml
import json
from datetime import datetime, timedelta
from pathlib import Path
import sys
import asyncio
from typing import Dict, List, Optional, Any
import logging

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from models.istr import ISTRNetwork
from models.predictor import create_predictor
from data.dataloader import ETTh1Dataset, create_dataloaders
from client.api_client import AgentLightningClient
from agents.autogen_system import AutoGenMultiAgentSystem

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="STAR-Forecast",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class STARForecastUI:
    """STAR-Forecast Webç•Œé¢"""

    def __init__(self):
        self.config = self.load_config()
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        # åˆå§‹åŒ–çŠ¶æ€
        self.model = None
        self.predictor = None
        self.dataset = None
        self.agent_client = None
        self.autogen_system = None

        # ä¼šè¯çŠ¶æ€
        if 'predictions' not in st.session_state:
            st.session_state.predictions = []
        if 'agent_decisions' not in st.session_state:
            st.session_state.agent_decisions = []
        if 'training_history' not in st.session_state:
            st.session_state.training_history = []
        if 'selected_sample' not in st.session_state:
            st.session_state.selected_sample = 0

    def load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®"""
        config_path = Path("./config.yaml")
        if not config_path.exists():
            st.error("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: config.yaml")
            return {}

        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)

        return config

    def setup_sidebar(self):
        """è®¾ç½®ä¾§è¾¹æ """
        with st.sidebar:
            st.title("âš™ï¸ æ§åˆ¶é¢æ¿")

            # æ¨¡å‹åŠ è½½éƒ¨åˆ†
            st.header("ğŸ“¦ æ¨¡å‹ç®¡ç†")

            col1, col2 = st.columns(2)
            with col1:
                if st.button("åŠ è½½æ¨¡å‹", use_container_width=True):
                    self.load_models()

            with col2:
                if st.button("é‡æ–°åŠ è½½æ•°æ®", use_container_width=True):
                    self.load_data()

            # æ•°æ®é€‰æ‹©
            st.header("ğŸ“Š æ•°æ®é€‰æ‹©")

            if self.dataset:
                sample_idx = st.slider(
                    "é€‰æ‹©æ ·æœ¬ç´¢å¼•",
                    0,
                    len(self.dataset) - 1,
                    st.session_state.selected_sample,
                    key="sample_slider"
                )
                st.session_state.selected_sample = sample_idx

                # æ˜¾ç¤ºæ ·æœ¬ä¿¡æ¯
                st.info(f"æ ·æœ¬ {sample_idx}/{len(self.dataset) - 1}")

            # é¢„æµ‹è®¾ç½®
            st.header("ğŸ”® é¢„æµ‹è®¾ç½®")

            self.num_predictions = st.slider(
                "é¢„æµ‹æ­¥æ•°",
                1,
                48,
                self.config['data']['pred_len'],
                key="pred_len_slider"
            )

            self.batch_size = st.slider(
                "æ‰¹å¤„ç†å¤§å°",
                1,
                64,
                16,
                key="batch_size_slider"
            )

            # æ™ºèƒ½ä½“è®¾ç½®
            st.header("ğŸ¤– æ™ºèƒ½ä½“æ§åˆ¶")

            self.agent_enabled = st.checkbox("å¯ç”¨æ™ºèƒ½ä½“", value=True)

            if self.agent_enabled:
                self.agent_check_interval = st.slider(
                    "æ™ºèƒ½ä½“æ£€æŸ¥é—´éš”",
                    10,
                    1000,
                    self.config['autogen']['trigger']['check_interval'],
                    step=10
                )

            # æ“ä½œæŒ‰é’®
            st.header("ğŸš€ æ“ä½œ")

            col1, col2 = st.columns(2)
            with col1:
                if st.button("è¿è¡Œé¢„æµ‹", type="primary", use_container_width=True):
                    self.run_prediction()

            with col2:
                if st.button("è°ƒç”¨æ™ºèƒ½ä½“", type="secondary", use_container_width=True):
                    self.call_agent()

            if st.button("é‡ç½®æ‰€æœ‰", type="secondary", use_container_width=True):
                st.session_state.predictions = []
                st.session_state.agent_decisions = []
                st.rerun()

            # ä¿¡æ¯æ˜¾ç¤º
            st.header("ğŸ“ˆ çŠ¶æ€ä¿¡æ¯")

            if self.model:
                st.success("âœ… æ¨¡å‹å·²åŠ è½½")
            else:
                st.warning("âš ï¸ æ¨¡å‹æœªåŠ è½½")

            if self.dataset:
                st.success("âœ… æ•°æ®å·²åŠ è½½")
            else:
                st.warning("âš ï¸ æ•°æ®æœªåŠ è½½")

    def load_models(self):
        """åŠ è½½æ¨¡å‹"""
        with st.spinner("åŠ è½½æ¨¡å‹ä¸­..."):
            try:
                # åŠ è½½æ£€æŸ¥ç‚¹
                checkpoint_dir = Path("./checkpoints")
                checkpoints = list(checkpoint_dir.glob("*.pth"))

                if not checkpoints:
                    st.error("æœªæ‰¾åˆ°æ¨¡å‹æ£€æŸ¥ç‚¹")
                    return

                # é€‰æ‹©æœ€æ–°æ£€æŸ¥ç‚¹
                latest_checkpoint = max(checkpoints, key=lambda x: x.stat().st_mtime)
                checkpoint = torch.load(latest_checkpoint, map_location=self.device)

                # åˆ›å»ºæ¨¡å‹
                self.model = ISTRNetwork(self.config).to(self.device)
                self.predictor = create_predictor(self.config).to(self.device)

                # åŠ è½½æƒé‡
                self.model.load_state_dict(checkpoint['istr_state_dict'])
                self.predictor.load_state_dict(checkpoint['predictor_state_dict'])

                # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
                self.model.eval()
                self.predictor.eval()

                st.success(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {latest_checkpoint.name}")

            except Exception as e:
                st.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

    def load_data(self):
        """åŠ è½½æ•°æ®"""
        with st.spinner("åŠ è½½æ•°æ®ä¸­..."):
            try:
                data_path = self.config['data']['data_path']

                if not Path(data_path).exists():
                    st.error(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
                    return

                # åˆ›å»ºæ•°æ®é›†
                self.dataset = ETTh1Dataset(
                    data_path,
                    seq_len=self.config['data']['seq_len'],
                    pred_len=self.config['data']['pred_len'],
                    split='test',
                    scale=True
                )

                st.success(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(self.dataset)} ä¸ªæ ·æœ¬")

            except Exception as e:
                st.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")

    def initialize_agents(self):
        """åˆå§‹åŒ–æ™ºèƒ½ä½“"""
        if not self.agent_client:
            try:
                self.agent_client = AgentLightningClient(
                    base_url=self.config['agent_lightning']['client']['base_url'],
                    client_id=f"web_ui_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    timeout=self.config['agent_lightning']['client']['timeout']
                )
                st.success("âœ… Agent Lightningå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                st.warning(f"âš ï¸ Agent Lightningå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")

        if not self.autogen_system:
            try:
                self.autogen_system = AutoGenMultiAgentSystem(self.config)
                st.success("âœ… AutoGenç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                st.warning(f"âš ï¸ AutoGenç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")

    def run_prediction(self):
        """è¿è¡Œé¢„æµ‹"""
        if not self.model or not self.dataset:
            st.error("è¯·å…ˆåŠ è½½æ¨¡å‹å’Œæ•°æ®")
            return

        with st.spinner("è¿è¡Œé¢„æµ‹ä¸­..."):
            try:
                # è·å–æ ·æœ¬
                sample_idx = st.session_state.selected_sample
                x, y_true = self.dataset[sample_idx]

                # è½¬æ¢ä¸ºæ‰¹é‡
                x = x.unsqueeze(0).to(self.device)
                y_true = y_true.unsqueeze(0).to(self.device)

                # è¿è¡Œé¢„æµ‹
                with torch.no_grad():
                    # ISTRç‰¹å¾æå–
                    features = self.model(x)

                    # é¢„æµ‹
                    y_pred = self.predictor(features)

                    # æå–ç‰¹å¾ä¾›åˆ†æ
                    feature_analysis = self.model.extract_features_for_analysis(x)

                # è½¬æ¢ä¸ºnumpy
                x_np = x.squeeze().cpu().numpy()
                y_true_np = y_true.squeeze().cpu().numpy()
                y_pred_np = y_pred.squeeze().cpu().numpy()

                # åæ ‡å‡†åŒ–ï¼ˆå¦‚æœæ•°æ®æœ‰æ ‡å‡†åŒ–ï¼‰
                if hasattr(self.dataset, 'scaler'):
                    # æ„å»ºå®Œæ•´åºåˆ—ï¼ˆåªå–OTç‰¹å¾ï¼‰
                    full_actual = np.concatenate([x_np[:, -1], y_true_np])
                    full_pred = np.concatenate([x_np[:, -1], y_pred_np])

                    # åæ ‡å‡†åŒ–
                    full_actual = self.dataset.inverse_transform(full_actual)
                    full_pred = self.dataset.inverse_transform(full_pred)

                    actual = full_actual
                    predicted = full_pred[-len(y_pred_np):]
                else:
                    actual = np.concatenate([x_np[:, -1], y_true_np])
                    predicted = y_pred_np

                # è®¡ç®—æŒ‡æ ‡
                metrics = self.calculate_metrics(actual[-len(predicted):], predicted)

                # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
                prediction_result = {
                    'sample_idx': sample_idx,
                    'actual': actual,
                    'predicted': predicted,
                    'metrics': metrics,
                    'feature_analysis': feature_analysis,
                    'timestamp': datetime.now()
                }

                st.session_state.predictions.append(prediction_result)

                st.success(f"âœ… é¢„æµ‹å®Œæˆ - MSE: {metrics['mse']:.4f}")

            except Exception as e:
                st.error(f"âŒ é¢„æµ‹å¤±è´¥: {e}")

    def call_agent(self):
        """è°ƒç”¨æ™ºèƒ½ä½“"""
        if not self.agent_enabled:
            st.warning("æ™ºèƒ½ä½“åŠŸèƒ½å·²ç¦ç”¨")
            return

        if not self.agent_client or len(st.session_state.predictions) == 0:
            st.error("è¯·å…ˆåˆå§‹åŒ–æ™ºèƒ½ä½“å¹¶è¿è¡Œé¢„æµ‹")
            return

        with st.spinner("æ™ºèƒ½ä½“åˆ†æä¸­..."):
            try:
                # è·å–æœ€æ–°çš„é¢„æµ‹ç»“æœ
                latest_pred = st.session_state.predictions[-1]

                # å‡†å¤‡ä¸Šä¸‹æ–‡
                context = {
                    'features': latest_pred['feature_analysis'],
                    'metrics': latest_pred['metrics'],
                    'current_params': {
                        'spectral_threshold': 0.5,
                        'laplacian_weight': 0.01
                    },
                    'training_info': {
                        'sample_idx': latest_pred['sample_idx'],
                        'timestamp': latest_pred['timestamp'].isoformat()
                    }
                }

                # è°ƒç”¨æ™ºèƒ½ä½“
                decision = self.agent_client.get_decision(context)

                # ä¿å­˜å†³ç­–
                decision_record = {
                    'context': context,
                    'decision': decision,
                    'timestamp': datetime.now()
                }

                st.session_state.agent_decisions.append(decision_record)

                # æ˜¾ç¤ºå†³ç­–ç»“æœ
                st.success("âœ… æ™ºèƒ½ä½“åˆ†æå®Œæˆ")

                # æ˜¾ç¤ºå†³ç­–è¯¦æƒ…
                with st.expander("æŸ¥çœ‹æ™ºèƒ½ä½“å†³ç­–è¯¦æƒ…"):
                    st.json(decision)

            except Exception as e:
                st.error(f"âŒ æ™ºèƒ½ä½“è°ƒç”¨å¤±è´¥: {e}")

    def calculate_metrics(self, actual: np.ndarray, predicted: np.ndarray) -> Dict[str, float]:
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
        # ç¡®ä¿é•¿åº¦ä¸€è‡´
        min_len = min(len(actual), len(predicted))
        actual = actual[:min_len]
        predicted = predicted[:min_len]

        # è®¡ç®—æŒ‡æ ‡
        mse = np.mean((actual - predicted) ** 2)
        mae = np.mean(np.abs(actual - predicted))
        rmse = np.sqrt(mse)

        # MAPEï¼ˆé¿å…é™¤ä»¥0ï¼‰
        epsilon = 1e-8
        mape = np.mean(np.abs((actual - predicted) / (actual + epsilon))) * 100

        # RÂ²åˆ†æ•°
        ss_res = np.sum((actual - predicted) ** 2)
        ss_tot = np.sum((actual - np.mean(actual)) ** 2)
        r2 = 1 - (ss_res / (ss_tot + epsilon))

        # æ–¹å‘å‡†ç¡®æ€§
        if len(actual) > 1:
            actual_dir = np.sign(actual[1:] - actual[:-1])
            pred_dir = np.sign(predicted[1:] - predicted[:-1])
            dir_acc = np.mean(actual_dir == pred_dir) * 100
        else:
            dir_acc = 0.0

        return {
            'mse': float(mse),
            'mae': float(mae),
            'rmse': float(rmse),
            'mape': float(mape),
            'r2': float(r2),
            'direction_accuracy': float(dir_acc)
        }

    def create_prediction_plot(self, actual: np.ndarray, predicted: np.ndarray,
                               title: str = "é¢„æµ‹ç»“æœ") -> go.Figure:
        """åˆ›å»ºé¢„æµ‹ç»“æœå›¾"""
        fig = make_subplots(
            rows=2, cols=1,
            subplot_titles=(f"{title}", "é¢„æµ‹è¯¯å·®"),
            vertical_spacing=0.15
        )

        # æ—¶é—´è½´
        time_actual = list(range(len(actual)))
        time_pred = list(range(len(actual) - len(predicted), len(actual)))

        # ç¬¬ä¸€å¼ å›¾ï¼šå®é™… vs é¢„æµ‹
        fig.add_trace(
            go.Scatter(
                x=time_actual,
                y=actual,
                mode='lines',
                name='å®é™…å€¼',
                line=dict(color='#1f77b4', width=2)
            ),
            row=1, col=1
        )

        fig.add_trace(
            go.Scatter(
                x=time_pred,
                y=predicted,
                mode='lines+markers',
                name='é¢„æµ‹å€¼',
                line=dict(color='#ff7f0e', width=2, dash='dash')
            ),
            row=1, col=1
        )

        # æ·»åŠ é¢„æµ‹åŒºé—´é˜´å½±
        if len(predicted) > 0:
            # ç®€å•ç½®ä¿¡åŒºé—´ï¼ˆåŸºäºå†å²è¯¯å·®ï¼‰
            error_std = np.std(actual[-len(predicted):] - predicted)
            upper_bound = predicted + 1.96 * error_std
            lower_bound = predicted - 1.96 * error_std

            fig.add_trace(
                go.Scatter(
                    x=time_pred + time_pred[::-1],
                    y=np.concatenate([upper_bound, lower_bound[::-1]]),
                    fill='toself',
                    fillcolor='rgba(255, 127, 14, 0.2)',
                    line=dict(color='rgba(255, 255, 255, 0)'),
                    name='95% ç½®ä¿¡åŒºé—´',
                    showlegend=True
                ),
                row=1, col=1
            )

        # ç¬¬äºŒå¼ å›¾ï¼šè¯¯å·®
        error = actual[-len(predicted):] - predicted
        fig.add_trace(
            go.Scatter(
                x=time_pred,
                y=error,
                mode='lines',
                name='è¯¯å·®',
                line=dict(color='#2ca02c', width=2)
            ),
            row=2, col=1
        )

        # æ·»åŠ é›¶çº¿
        fig.add_hline(y=0, line_dash="dot", line_color="gray", row=2, col=1)

        # æ›´æ–°å¸ƒå±€
        fig.update_layout(
            height=600,
            showlegend=True,
            template="plotly_white",
            hovermode="x unified"
        )

        fig.update_xaxes(title_text="æ—¶é—´æ­¥", row=2, col=1)
        fig.update_yaxes(title_text="æ•°å€¼", row=1, col=1)
        fig.update_yaxes(title_text="è¯¯å·®", row=2, col=1)

        return fig

    def create_metrics_dashboard(self, metrics: Dict[str, float]) -> go.Figure:
        """åˆ›å»ºæŒ‡æ ‡ä»ªè¡¨ç›˜"""
        fig = go.Figure()

        # å‡†å¤‡æ•°æ®
        metric_names = list(metrics.keys())
        metric_values = list(metrics.values())

        # åˆ›å»ºæ¡å½¢å›¾
        fig.add_trace(go.Bar(
            x=metric_names,
            y=metric_values,
            text=[f'{v:.4f}' for v in metric_values],
            textposition='auto',
            marker_color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']
        ))

        # æ›´æ–°å¸ƒå±€
        fig.update_layout(
            title="è¯„ä¼°æŒ‡æ ‡",
            template="plotly_white",
            height=400,
            showlegend=False
        )

        fig.update_yaxes(title_text="æŒ‡æ ‡å€¼")

        return fig

    def create_feature_analysis_plot(self, features: Dict[str, Any]) -> go.Figure:
        """åˆ›å»ºç‰¹å¾åˆ†æå›¾"""
        if not features or 'statistics' not in features:
            return go.Figure()

        stats = features['statistics']

        # åˆ›å»ºå­å›¾
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=("ç»Ÿè®¡ç‰¹å¾", "è‡ªç›¸å…³", "é¢‘åŸŸç‰¹å¾", "è‡ªé€‚åº”å‚æ•°"),
            vertical_spacing=0.15,
            horizontal_spacing=0.1
        )

        # 1. ç»Ÿè®¡ç‰¹å¾
        if 'mean' in stats and 'std' in stats:
            mean_vals = stats['mean']
            std_vals = stats['std']

            fig.add_trace(
                go.Bar(
                    x=[f'ç‰¹å¾{i}' for i in range(len(mean_vals))],
                    y=mean_vals,
                    error_y=dict(type='data', array=std_vals, visible=True),
                    name='å‡å€¼Â±æ ‡å‡†å·®'
                ),
                row=1, col=1
            )

        # 2. è‡ªç›¸å…³
        if 'autocorrelation' in stats:
            autocorr = stats['autocorrelation']
            fig.add_trace(
                go.Scatter(
                    x=list(range(len(autocorr))),
                    y=autocorr,
                    mode='lines+markers',
                    name='è‡ªç›¸å…³'
                ),
                row=1, col=2
            )

        # 3. é¢‘åŸŸç‰¹å¾
        if 'frequency' in features:
            freq_features = features['frequency']
            if 'dominant_frequency' in freq_features:
                fig.add_trace(
                    go.Indicator(
                        mode="gauge+number",
                        value=freq_features['dominant_frequency'],
                        title={'text': "ä¸»å¯¼é¢‘ç‡"},
                        domain={'row': 0, 'column': 0},
                        gauge={'axis': {'range': [0, 50]}}
                    ),
                    row=2, col=1
                )

        # 4. è‡ªé€‚åº”å‚æ•°
        if 'adaptive_parameters' in features:
            adaptive_params = features['adaptive_parameters']

            param_names = list(adaptive_params.keys())
            param_values = list(adaptive_params.values())

            fig.add_trace(
                go.Bar(
                    x=param_names,
                    y=param_values,
                    name='è‡ªé€‚åº”å‚æ•°'
                ),
                row=2, col=2
            )

        # æ›´æ–°å¸ƒå±€
        fig.update_layout(
            height=600,
            showlegend=False,
            template="plotly_white"
        )

        return fig

    def display_prediction_results(self):
        """æ˜¾ç¤ºé¢„æµ‹ç»“æœ"""
        if not st.session_state.predictions:
            return

        st.header("ğŸ“Š é¢„æµ‹ç»“æœ")

        # æ˜¾ç¤ºæœ€è¿‘çš„é¢„æµ‹
        latest_pred = st.session_state.predictions[-1]

        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("MSE", f"{latest_pred['metrics']['mse']:.4f}")
        with col2:
            st.metric("MAE", f"{latest_pred['metrics']['mae']:.4f}")
        with col3:
            st.metric("RÂ²", f"{latest_pred['metrics']['r2']:.4f}")

        # æ˜¾ç¤ºé¢„æµ‹å›¾
        st.subheader("é¢„æµ‹å¯è§†åŒ–")

        fig = self.create_prediction_plot(
            latest_pred['actual'],
            latest_pred['predicted'],
            f"æ ·æœ¬ {latest_pred['sample_idx']} é¢„æµ‹ç»“æœ"
        )

        st.plotly_chart(fig, use_container_width=True)

        # æ˜¾ç¤ºæŒ‡æ ‡ä»ªè¡¨ç›˜
        st.subheader("è¯„ä¼°æŒ‡æ ‡")

        metrics_fig = self.create_metrics_dashboard(latest_pred['metrics'])
        st.plotly_chart(metrics_fig, use_container_width=True)

        # æ˜¾ç¤ºç‰¹å¾åˆ†æ
        if 'feature_analysis' in latest_pred:
            st.subheader("ç‰¹å¾åˆ†æ")

            feature_fig = self.create_feature_analysis_plot(latest_pred['feature_analysis'])
            st.plotly_chart(feature_fig, use_container_width=True)

        # æ˜¾ç¤ºå†å²é¢„æµ‹
        if len(st.session_state.predictions) > 1:
            st.subheader("å†å²é¢„æµ‹è®°å½•")

            history_df = pd.DataFrame([
                {
                    'æ ·æœ¬ç´¢å¼•': p['sample_idx'],
                    'MSE': p['metrics']['mse'],
                    'MAE': p['metrics']['mae'],
                    'RÂ²': p['metrics']['r2'],
                    'æ—¶é—´': p['timestamp'].strftime('%H:%M:%S')
                }
                for p in st.session_state.predictions[-10:]  # æ˜¾ç¤ºæœ€è¿‘10æ¡
            ])

            st.dataframe(history_df, use_container_width=True)

    def display_agent_decisions(self):
        """æ˜¾ç¤ºæ™ºèƒ½ä½“å†³ç­–"""
        if not st.session_state.agent_decisions:
            return

        st.header("ğŸ¤– æ™ºèƒ½ä½“å†³ç­–")

        # æ˜¾ç¤ºæœ€è¿‘çš„å†³ç­–
        latest_decision = st.session_state.agent_decisions[-1]
        decision = latest_decision['decision']

        # å†³ç­–æ¦‚è§ˆ
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("åŠ¨ä½œ", decision.get('action', 'N/A'))
        with col2:
            st.metric("è¯­ä¹‰å¥–åŠ±", f"{decision.get('semantic_reward', 0):.3f}")
        with col3:
            if decision.get('fallback', False):
                st.warning("å¤‡ç”¨å†³ç­–")
            else:
                st.success("æ™ºèƒ½ä½“å†³ç­–")

        # æ˜¾ç¤ºå‚æ•°è°ƒæ•´
        if 'parameters' in decision and decision['parameters']:
            st.subheader("å‚æ•°è°ƒæ•´å»ºè®®")

            params = decision['parameters']
            param_df = pd.DataFrame({
                'å‚æ•°': list(params.keys()),
                'å»ºè®®å€¼': list(params.values())
            })

            st.dataframe(param_df, use_container_width=True)

        # æ˜¾ç¤ºAutoGenå¯¹è¯æ‘˜è¦
        if 'autogen_conversation' in decision:
            conversation = decision['autogen_conversation']

            with st.expander("AutoGenå¯¹è¯è¯¦æƒ…"):
                st.write(f"å¯¹è¯ID: {conversation.get('conversation_id', 'N/A')}")
                st.write(f"å…±è¯†ç¨‹åº¦: {conversation.get('consensus_level', 0):.2%}")

                if 'summary' in conversation:
                    st.write("å¯¹è¯æ‘˜è¦:")
                    st.write(conversation['summary'])

        # æ˜¾ç¤ºå†å²å†³ç­–
        if len(st.session_state.agent_decisions) > 1:
            st.subheader("å†å²å†³ç­–è®°å½•")

            decision_history = []
            for i, d in enumerate(st.session_state.agent_decisions[-5:]):  # æ˜¾ç¤ºæœ€è¿‘5æ¡
                decision_data = d['decision']
                decision_history.append({
                    'åºå·': i + 1,
                    'åŠ¨ä½œ': decision_data.get('action', 'N/A'),
                    'å‚æ•°æ•°é‡': len(decision_data.get('parameters', {})),
                    'å¥–åŠ±': f"{decision_data.get('semantic_reward', 0):.3f}",
                    'æ—¶é—´': d['timestamp'].strftime('%H:%M:%S')
                })

            history_df = pd.DataFrame(decision_history)
            st.dataframe(history_df, use_container_width=True)

    def display_model_info(self):
        """æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯"""
        if not self.model:
            return

        st.header("ğŸ§  æ¨¡å‹ä¿¡æ¯")

        # è®¡ç®—æ¨¡å‹å‚æ•°
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)

        col1, col2 = st.columns(2)

        with col1:
            st.metric("æ€»å‚æ•°", f"{total_params:,}")
        with col2:
            st.metric("å¯è®­ç»ƒå‚æ•°", f"{trainable_params:,}")

        # æ˜¾ç¤ºæ¶æ„ä¿¡æ¯
        with st.expander("æŸ¥çœ‹æ¶æ„è¯¦æƒ…"):
            # ISTRç½‘ç»œä¿¡æ¯
            st.subheader("ISTRç½‘ç»œ")

            if hasattr(self.model, 'config'):
                istr_config = self.model.config['istr']

                info_df = pd.DataFrame({
                    'å‚æ•°': ['è¾“å…¥ç»´åº¦', 'éšè—ç»´åº¦', 'TCNå—æ•°', 'è°±é—¨æ§', 'æ‹‰æ™®æ‹‰æ–¯æ­£åˆ™åŒ–'],
                    'å€¼': [
                        istr_config['input_dim'],
                        istr_config['hidden_dim'],
                        len(istr_config['tcn']['kernel_sizes']),
                        'å¯ç”¨' if istr_config['spectral_gate']['enabled'] else 'ç¦ç”¨',
                        'å¯ç”¨' if istr_config['laplacian']['enabled'] else 'ç¦ç”¨'
                    ]
                })

                st.dataframe(info_df, use_container_width=True)

        # æ˜¾ç¤ºè®­ç»ƒçŠ¶æ€
        if hasattr(self.model, 'adaptation_count'):
            st.subheader("è‡ªé€‚åº”çŠ¶æ€")
            st.write(f"å‚æ•°è°ƒæ•´æ¬¡æ•°: {self.model.adaptation_count.item()}")

            if hasattr(self.model, 'adaptive_params'):
                adaptive_df = pd.DataFrame({
                    'å‚æ•°': list(self.model.adaptive_params.keys()),
                    'å½“å‰å€¼': [p.item() for p in self.model.adaptive_params.values()]
                })

                st.dataframe(adaptive_df, use_container_width=True)

    def display_data_info(self):
        """æ˜¾ç¤ºæ•°æ®ä¿¡æ¯"""
        if not self.dataset:
            return

        st.header("ğŸ“ˆ æ•°æ®ä¿¡æ¯")

        # è·å–æ•°æ®ç»Ÿè®¡
        try:
            data_path = self.config['data']['data_path']
            df = pd.read_csv(data_path)

            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric("æ€»æ ·æœ¬æ•°", f"{len(df):,}")
            with col2:
                st.metric("ç‰¹å¾æ•°é‡", f"{len(df.columns) - 1}")  # å‡å»æ—¥æœŸåˆ—
            with col3:
                st.metric("æ•°æ®èŒƒå›´", f"{df.iloc[0, 0]} åˆ° {df.iloc[-1, 0]}")

            # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
            with st.expander("æŸ¥çœ‹æ•°æ®é¢„è§ˆ"):
                st.dataframe(df.head(10), use_container_width=True)

            # æ˜¾ç¤ºç‰¹å¾ç»Ÿè®¡
            st.subheader("ç‰¹å¾ç»Ÿè®¡")

            numeric_cols = df.select_dtypes(include=[np.number]).columns
            stats_df = df[numeric_cols].describe().T

            st.dataframe(stats_df, use_container_width=True)

        except Exception as e:
            st.error(f"æ•°æ®ä¿¡æ¯åŠ è½½å¤±è´¥: {e}")

    def display_training_monitor(self):
        """æ˜¾ç¤ºè®­ç»ƒç›‘æ§"""
        st.header("ğŸ‹ï¸ è®­ç»ƒç›‘æ§")

        # è®­ç»ƒçŠ¶æ€æŒ‡ç¤ºå™¨
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("é¢„æµ‹æ¬¡æ•°", len(st.session_state.predictions))
        with col2:
            st.metric("æ™ºèƒ½ä½“å†³ç­–", len(st.session_state.agent_decisions))
        with col3:
            if st.session_state.predictions:
                latest_mse = st.session_state.predictions[-1]['metrics']['mse']
                st.metric("æœ€æ–°MSE", f"{latest_mse:.4f}")

        # è®­ç»ƒå†å²å›¾è¡¨
        if len(st.session_state.predictions) > 1:
            st.subheader("è®­ç»ƒå†å²")

            # æå–å†å²æŒ‡æ ‡
            history = st.session_state.predictions
            epochs = list(range(len(history)))
            mse_values = [h['metrics']['mse'] for h in history]
            mae_values = [h['metrics']['mae'] for h in history]

            # åˆ›å»ºå›¾è¡¨
            fig = go.Figure()

            fig.add_trace(go.Scatter(
                x=epochs,
                y=mse_values,
                mode='lines+markers',
                name='MSE',
                line=dict(color='#1f77b4', width=2)
            ))

            fig.add_trace(go.Scatter(
                x=epochs,
                y=mae_values,
                mode='lines+markers',
                name='MAE',
                line=dict(color='#ff7f0e', width=2)
            ))

            fig.update_layout(
                title="è®­ç»ƒæŒ‡æ ‡å˜åŒ–",
                xaxis_title="é¢„æµ‹æ¬¡æ•°",
                yaxis_title="æŒ‡æ ‡å€¼",
                template="plotly_white",
                height=400
            )

            st.plotly_chart(fig, use_container_width=True)

    def run(self):
        """è¿è¡ŒWebç•Œé¢"""
        # é¡µé¢æ ‡é¢˜
        st.title("ğŸš€ STAR-Forecast: ç¥ç»-ç¬¦å·-å¼ºåŒ–ä¸‰é‡ååŒæ—¶åºé¢„æµ‹")
        st.markdown("---")

        # åˆå§‹åŒ–æ™ºèƒ½ä½“
        self.initialize_agents()

        # ä¾§è¾¹æ 
        self.setup_sidebar()

        # ä¸»å†…å®¹åŒºåŸŸ
        tab1, tab2, tab3, tab4 = st.tabs([
            "ğŸ“Š é¢„æµ‹ç»“æœ",
            "ğŸ¤– æ™ºèƒ½ä½“åˆ†æ",
            "ğŸ§  æ¨¡å‹ä¿¡æ¯",
            "ğŸ“ˆ æ•°æ®ç›‘æ§"
        ])

        with tab1:
            self.display_prediction_results()

        with tab2:
            self.display_agent_decisions()

        with tab3:
            self.display_model_info()

        with tab4:
            self.display_data_info()
            st.markdown("---")
            self.display_training_monitor()

        # é¡µè„š
        st.markdown("---")
        st.markdown(
            """
            <div style='text-align: center'>
                <p><b>STAR-Forecast</b> Â© 2024 æ¢å¾·éš† - ç¡•å£«è®ºæ–‡å®ç°</p>
                <p>ç¥ç»-ç¬¦å·-å¼ºåŒ–ä¸‰é‡ååŒè‡ªé€‚åº”æ—¶åºé¢„æµ‹æ¡†æ¶</p>
            </div>
            """,
            unsafe_allow_html=True
        )


def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºUIå®ä¾‹
    ui = STARForecastUI()

    # è¿è¡ŒUI
    ui.run()


if __name__ == "__main__":
    main()