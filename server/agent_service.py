"""
Agent LightningæœåŠ¡ç«¯ - å®Œæ•´çš„å¾®æœåŠ¡å®ç°
æä¾›REST APIæ¥å£ï¼Œå®Œå…¨è§£è€¦è®­ç»ƒå’Œæ‰§è¡Œ
"""
from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
from typing import Dict, List, Optional, Any, Union
import asyncio
import uuid
import json
from datetime import datetime
import logging
from pathlib import Path
import threading
import queue
import time
from dataclasses import dataclass, asdict
from enum import Enum
import numpy as np

import torch
import torch.nn as nn
import torch.nn.functional as F

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from .schemas import *
from ..models.istr import ISTRNetwork
from ..agents.autogen_system import AutoGenMultiAgentSystem

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPIåº”ç”¨
app = FastAPI(
    title="Agent Lightning Service",
    version="2.0.0",
    description="è®­ç»ƒ-æ‰§è¡Œå®Œå…¨è§£è€¦çš„å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“æœåŠ¡",
    docs_url="/api/docs",
    redoc_url="/api/redoc"
)

# CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ==================== æ•°æ®ç»“æ„å®šä¹‰ ====================
class TaskStatus(str, Enum):
    """ä»»åŠ¡çŠ¶æ€"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


@dataclass
class AgentState:
    """æ™ºèƒ½ä½“çŠ¶æ€"""
    agent_id: str
    policy_net: Any
    target_net: Any
    optimizer: Any
    memory: Any  # ç»éªŒå›æ”¾ç¼“å†²åŒº
    epsilon: float
    steps_done: int
    episode_rewards: List[float]
    created_at: datetime
    last_updated: datetime


@dataclass
class TrainingTask:
    """è®­ç»ƒä»»åŠ¡"""
    task_id: str
    client_id: str
    model_config: Dict[str, Any]
    training_config: Dict[str, Any]
    data_path: Optional[str]
    callback_url: Optional[str]
    status: TaskStatus
    progress: float = 0.0
    metrics: Dict[str, Any] = None
    error: Optional[str] = None
    created_at: datetime = None
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None

    def __post_init__(self):
        if self.metrics is None:
            self.metrics = {}
        if self.created_at is None:
            self.created_at = datetime.now()


# ==================== æ ¸å¿ƒæœåŠ¡ç±» ====================
class AgentLightningService:
    """Agent Lightningæ ¸å¿ƒæœåŠ¡"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.device = torch.device(
            'cuda:0' if torch.cuda.is_available() else 'cpu'
        )

        # å®¢æˆ·ç«¯ç®¡ç†
        self.client_sessions: Dict[str, Dict[str, Any]] = {}

        # ä»»åŠ¡ç®¡ç†
        self.training_tasks: Dict[str, TrainingTask] = {}
        self.training_queue = queue.PriorityQueue()
        self.task_results: Dict[str, Any] = {}

        # æ¨¡å‹ç¼“å­˜
        self.model_cache: Dict[str, Any] = {}

        # æ™ºèƒ½ä½“æ± 
        self.agent_pool: Dict[str, AgentState] = {}

        # AutoGenç³»ç»Ÿ
        self.autogen_system = AutoGenMultiAgentSystem(config)

        # è®­ç»ƒå·¥ä½œçº¿ç¨‹
        self.workers: Dict[int, Dict[str, Any]] = {}
        self._start_workers()

        # ç›‘æ§æŒ‡æ ‡
        self.metrics = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'active_clients': 0,
            'pending_tasks': 0,
            'completed_tasks': 0
        }

        logger.info("âœ… Agent LightningæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   è®¾å¤‡: {self.device}")
        logger.info(f"   æœ€å¤§å·¥ä½œçº¿ç¨‹: {self.config['agent_lightning']['service']['workers']}")

    def _start_workers(self):
        """å¯åŠ¨è®­ç»ƒå·¥ä½œçº¿ç¨‹"""
        num_workers = self.config['agent_lightning']['service']['workers']

        for i in range(num_workers):
            worker = threading.Thread(
                target=self._training_worker,
                args=(i,),
                daemon=True,
                name=f"TrainingWorker-{i}"
            )
            worker.start()

            self.workers[i] = {
                'thread': worker,
                'busy': False,
                'current_task': None,
                'tasks_processed': 0
            }

            logger.info(f"   å¯åŠ¨å·¥ä½œçº¿ç¨‹ {i}")

    def _training_worker(self, worker_id: int):
        """è®­ç»ƒå·¥ä½œçº¿ç¨‹ä¸»å¾ªç¯"""
        logger.info(f"ğŸ‘· å·¥ä½œçº¿ç¨‹ {worker_id} å¯åŠ¨")

        while True:
            try:
                # è·å–ä»»åŠ¡ï¼ˆé˜»å¡ï¼‰
                priority, task_id = self.training_queue.get()

                self.workers[worker_id]['busy'] = True
                self.workers[worker_id]['current_task'] = task_id

                task = self.training_tasks.get(task_id)
                if not task:
                    logger.error(f"ä»»åŠ¡ {task_id} ä¸å­˜åœ¨")
                    continue

                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                task.status = TaskStatus.RUNNING
                task.started_at = datetime.now()

                logger.info(f"ğŸ”§ å·¥ä½œçº¿ç¨‹ {worker_id} å¼€å§‹å¤„ç†ä»»åŠ¡ {task_id}")

                try:
                    # æ‰§è¡Œè®­ç»ƒ
                    result = self._execute_training_task(task)

                    # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                    task.status = TaskStatus.COMPLETED
                    task.progress = 1.0
                    task.metrics = result.get('metrics', {})
                    task.completed_at = datetime.now()

                    # å­˜å‚¨ç»“æœ
                    self.task_results[task_id] = result

                    # å›è°ƒé€šçŸ¥
                    if task.callback_url:
                        self._notify_callback(task, result)

                    logger.info(f"âœ… ä»»åŠ¡ {task_id} å®Œæˆ")

                except Exception as e:
                    logger.error(f"âŒ ä»»åŠ¡ {task_id} å¤±è´¥: {e}")

                    task.status = TaskStatus.FAILED
                    task.error = str(e)
                    task.completed_at = datetime.now()

                finally:
                    self.workers[worker_id]['busy'] = False
                    self.workers[worker_id]['current_task'] = None
                    self.workers[worker_id]['tasks_processed'] += 1
                    self.training_queue.task_done()

            except Exception as e:
                logger.error(f"å·¥ä½œçº¿ç¨‹ {worker_id} é”™è¯¯: {e}")
                time.sleep(1)  # é¿å…å¿«é€Ÿå¤±è´¥å¾ªç¯

    def _execute_training_task(self, task: TrainingTask) -> Dict[str, Any]:
        """æ‰§è¡Œè®­ç»ƒä»»åŠ¡"""
        logger.info(f"æ‰§è¡Œè®­ç»ƒä»»åŠ¡ {task.task_id} for client {task.client_id}")

        # è¿™é‡Œåº”è¯¥æ˜¯å®Œæ•´çš„è®­ç»ƒé€»è¾‘
        # ç®€åŒ–å®ç°ï¼šæ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
        start_time = time.time()

        # æ¨¡æ‹Ÿè®­ç»ƒè¿›åº¦
        for i in range(1, 101):
            time.sleep(0.1)  # æ¨¡æ‹Ÿè®­ç»ƒæ—¶é—´
            task.progress = i / 100

            # æ¯10%è®°å½•ä¸€æ¬¡
            if i % 10 == 0:
                logger.info(f"ä»»åŠ¡ {task.task_id} è¿›åº¦: {i}%")

        # æ¨¡æ‹Ÿè®­ç»ƒç»“æœ
        result = {
            'task_id': task.task_id,
            'client_id': task.client_id,
            'duration': time.time() - start_time,
            'metrics': {
                'final_loss': 0.1234,
                'accuracy': 0.8765,
                'training_time': 10.5
            },
            'model_path': f"./models/{task.task_id}.pth",
            'artifacts': ['model', 'logs', 'metrics']
        }

        return result

    def _notify_callback(self, task: TrainingTask, result: Dict[str, Any]):
        """å›è°ƒé€šçŸ¥å®¢æˆ·ç«¯"""
        import requests

        try:
            requests.post(
                task.callback_url,
                json={
                    'task_id': task.task_id,
                    'status': 'completed',
                    'result': result
                },
                timeout=5
            )
            logger.info(f"âœ… å›è°ƒé€šçŸ¥æˆåŠŸ: {task.callback_url}")
        except Exception as e:
            logger.warning(f"âš ï¸ å›è°ƒé€šçŸ¥å¤±è´¥: {e}")

    # ==================== å…¬å…±APIæ–¹æ³• ====================

    async def submit_training(self, request: TrainingRequest) -> str:
        """æäº¤è®­ç»ƒä»»åŠ¡"""
        task_id = str(uuid.uuid4())

        task = TrainingTask(
            task_id=task_id,
            client_id=request.client_id,
            model_config=request.model_config,
            training_config=request.training_config,
            data_path=request.data_path,
            callback_url=request.callback_url,
            status=TaskStatus.PENDING
        )

        # è®¡ç®—ä¼˜å…ˆçº§ï¼ˆåŸºäºå®¢æˆ·ç«¯ä¼˜å…ˆçº§æˆ–ä»»åŠ¡ç±»å‹ï¼‰
        priority = self._calculate_task_priority(request)

        # å­˜å‚¨ä»»åŠ¡
        self.training_tasks[task_id] = task

        # åŠ å…¥é˜Ÿåˆ—
        self.training_queue.put((priority, task_id))

        self.metrics['pending_tasks'] += 1
        logger.info(f"ğŸ“¥ æäº¤è®­ç»ƒä»»åŠ¡ {task_id}, ä¼˜å…ˆçº§: {priority}")

        return task_id

    async def get_agent_decision(self, request: AgentDecisionRequest) -> Dict[str, Any]:
        """è·å–æ™ºèƒ½ä½“å†³ç­–"""
        self.metrics['total_requests'] += 1

        try:
            # æ£€æŸ¥å®¢æˆ·ç«¯ä¼šè¯
            if request.client_id not in self.client_sessions:
                await self._create_client_session(request.client_id)

            session = self.client_sessions[request.client_id]
            agent_state = session['agent_state']

            # å‡†å¤‡çŠ¶æ€
            state_tensor = self._prepare_state_tensor(request.context)

            # ä½¿ç”¨æ™ºèƒ½ä½“é€‰æ‹©åŠ¨ä½œ
            action = await self._select_action_async(agent_state, state_tensor)

            # è°ƒç”¨AutoGenè¿›è¡ŒååŒåˆ†æ
            autogen_context = self._prepare_autogen_context(request.context)
            conversation_result = self.autogen_system.initiate_conversation(autogen_context)

            # ä»å…±è¯†ä¸­æå–å‚æ•°
            parameters = {}
            if conversation_result.consensus and 'parameters' in conversation_result.consensus:
                parameters = conversation_result.consensus['parameters']

            # è®¡ç®—è¯­ä¹‰å¥–åŠ±
            semantic_reward = self._calculate_semantic_reward(conversation_result)

            # æ„å»ºå“åº”
            response = {
                'decision_id': str(uuid.uuid4()),
                'action': int(action),
                'parameters': parameters,
                'semantic_reward': semantic_reward,
                'autogen_conversation': {
                    'conversation_id': conversation_result.conversation_id,
                    'consensus_level': conversation_result.consensus.get('agreement_level', 0)
                    if conversation_result.consensus else 0,
                    'summary': conversation_result.summary
                },
                'agent_state': {
                    'epsilon': agent_state.epsilon,
                    'steps_done': agent_state.steps_done,
                    'episode_rewards': agent_state.episode_rewards[-10:]  # æœ€è¿‘10æ¬¡å¥–åŠ±
                },
                'timestamp': datetime.now().isoformat()
            }

            self.metrics['successful_requests'] += 1
            logger.info(f"ğŸ¤– æ™ºèƒ½ä½“å†³ç­–ç”Ÿæˆ: {action}, å‚æ•°: {parameters}")

            return response

        except Exception as e:
            self.metrics['failed_requests'] += 1
            logger.error(f"âŒ æ™ºèƒ½ä½“å†³ç­–å¤±è´¥: {e}")

            # è¿”å›å¤‡ç”¨å†³ç­–
            return await self._get_fallback_decision(request)

    async def update_agent_experience(self, request: ExperienceUpdateRequest) -> Dict[str, Any]:
        """æ›´æ–°æ™ºèƒ½ä½“ç»éªŒ"""
        if request.client_id not in self.client_sessions:
            raise HTTPException(status_code=404, detail="Client session not found")

        session = self.client_sessions[request.client_id]
        agent_state = session['agent_state']

        # å­˜å‚¨ç»éªŒ
        agent_state.memory.push(
            request.state,
            request.action,
            request.reward,
            request.next_state,
            request.done
        )

        # æ›´æ–°æ™ºèƒ½ä½“ï¼ˆå¼‚æ­¥ï¼‰
        if len(agent_state.memory) > session['config']['batch_size']:
            await self._optimize_agent_async(agent_state)

        # æ›´æ–°æ¢ç´¢ç‡
        agent_state.epsilon = self._update_epsilon(agent_state.steps_done)
        agent_state.steps_done += 1

        # è®°å½•å¥–åŠ±
        agent_state.episode_rewards.append(request.reward)
        if len(agent_state.episode_rewards) > 1000:  # é™åˆ¶é•¿åº¦
            agent_state.episode_rewards = agent_state.episode_rewards[-1000:]

        agent_state.last_updated = datetime.now()

        return {
            'status': 'updated',
            'epsilon': agent_state.epsilon,
            'steps_done': agent_state.steps_done,
            'memory_size': len(agent_state.memory),
            'avg_recent_reward': np.mean(agent_state.episode_rewards[-100:])
            if agent_state.episode_rewards else 0
        }

    # ==================== æ™ºèƒ½ä½“æ ¸å¿ƒæ–¹æ³• ====================

    async def _create_client_session(self, client_id: str):
        """åˆ›å»ºå®¢æˆ·ç«¯ä¼šè¯"""
        logger.info(f"åˆ›å»ºå®¢æˆ·ç«¯ä¼šè¯: {client_id}")

        # åˆ›å»ºDQNç½‘ç»œ
        state_dim = self.config['agent_lightning']['rl']['state_dim']
        action_dim = self.config['agent_lightning']['rl']['action_dim']
        hidden_dim = self.config['agent_lightning']['rl']['hidden_dim']

        policy_net = DQNNetwork(state_dim, action_dim, hidden_dim).to(self.device)
        target_net = DQNNetwork(state_dim, action_dim, hidden_dim).to(self.device)
        target_net.load_state_dict(policy_net.state_dict())

        # ä¼˜åŒ–å™¨
        optimizer = torch.optim.Adam(
            policy_net.parameters(),
            lr=self.config['agent_lightning']['rl']['dqn']['lr']
        )

        # ç»éªŒå›æ”¾ç¼“å†²åŒº
        memory = ReplayBuffer(
            self.config['agent_lightning']['rl']['dqn']['buffer_size']
        )

        # åˆ›å»ºæ™ºèƒ½ä½“çŠ¶æ€
        agent_state = AgentState(
            agent_id=f"agent_{client_id}",
            policy_net=policy_net,
            target_net=target_net,
            optimizer=optimizer,
            memory=memory,
            epsilon=self.config['agent_lightning']['rl']['exploration']['epsilon_start'],
            steps_done=0,
            episode_rewards=[],
            created_at=datetime.now(),
            last_updated=datetime.now()
        )

        # å­˜å‚¨ä¼šè¯
        self.client_sessions[client_id] = {
            'agent_state': agent_state,
            'config': self.config['agent_lightning'],
            'created_at': datetime.now(),
            'last_active': datetime.now()
        }

        # æ·»åŠ åˆ°æ™ºèƒ½ä½“æ± 
        self.agent_pool[f"agent_{client_id}"] = agent_state

        self.metrics['active_clients'] += 1
        logger.info(f"âœ… å®¢æˆ·ç«¯ä¼šè¯åˆ›å»ºå®Œæˆ: {client_id}")

    async def _select_action_async(self, agent_state: AgentState, state: np.ndarray) -> int:
        """å¼‚æ­¥é€‰æ‹©åŠ¨ä½œ"""
        loop = asyncio.get_event_loop()

        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œè®¡ç®—å¯†é›†å‹æ“ä½œ
        action = await loop.run_in_executor(
            None,
            self._select_action,
            agent_state, state
        )

        return action

    def _select_action(self, agent_state: AgentState, state: np.ndarray) -> int:
        """é€‰æ‹©åŠ¨ä½œï¼ˆÎµ-greedyï¼‰"""
        # æ›´æ–°æ¢ç´¢ç‡
        agent_state.epsilon = self._update_epsilon(agent_state.steps_done)

        if np.random.random() > agent_state.epsilon:
            with torch.no_grad():
                state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)
                q_values = agent_state.policy_net(state_tensor)
                action = q_values.max(1)[1].item()
        else:
            # æ¢ç´¢ï¼šéšæœºåŠ¨ä½œ
            action = np.random.randint(0, self.config['agent_lightning']['rl']['action_dim'])

            # æ·»åŠ å™ªå£°
            noise_std = self.config['agent_lightning']['rl']['exploration']['noise_std']
            if noise_std > 0:
                action = action + np.random.normal(0, noise_std)
                action = np.clip(action, 0, self.config['agent_lightning']['rl']['action_dim'] - 1)
                action = int(action)

        return action

    async def _optimize_agent_async(self, agent_state: AgentState):
        """å¼‚æ­¥ä¼˜åŒ–æ™ºèƒ½ä½“"""
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(None, self._optimize_agent, agent_state)

    def _optimize_agent(self, agent_state: AgentState):
        """ä¼˜åŒ–æ™ºèƒ½ä½“ç½‘ç»œ"""
        if len(agent_state.memory) < agent_state.memory.batch_size:
            return

        # é‡‡æ ·æ‰¹æ¬¡
        transitions = agent_state.memory.sample(agent_state.memory.batch_size)
        batch = Transition(*zip(*transitions))

        # è½¬æ¢ä¸ºå¼ é‡
        state_batch = torch.FloatTensor(batch.state).to(self.device)
        action_batch = torch.LongTensor(batch.action).unsqueeze(1).to(self.device)
        reward_batch = torch.FloatTensor(batch.reward).to(self.device)
        next_state_batch = torch.FloatTensor(batch.next_state).to(self.device)
        done_batch = torch.FloatTensor(batch.done).to(self.device)

        # è®¡ç®—å½“å‰Qå€¼
        current_q = agent_state.policy_net(state_batch).gather(1, action_batch)

        # è®¡ç®—ç›®æ ‡Qå€¼ï¼ˆDouble DQNï¼‰
        next_actions = agent_state.policy_net(next_state_batch).max(1)[1].unsqueeze(1)
        next_q = agent_state.target_net(next_state_batch).gather(1, next_actions).detach()

        expected_q = reward_batch.unsqueeze(1) + (
                self.config['agent_lightning']['rl']['dqn']['gamma'] * next_q * (1 - done_batch.unsqueeze(1))
        )

        # è®¡ç®—æŸå¤±
        loss = F.mse_loss(current_q, expected_q)

        # ä¼˜åŒ–
        agent_state.optimizer.zero_grad()
        loss.backward()

        # æ¢¯åº¦è£å‰ª
        torch.nn.utils.clip_grad_norm_(
            agent_state.policy_net.parameters(),
            self.config['agent_lightning']['rl']['training']['gradient_clip']
        )

        agent_state.optimizer.step()

        # æ›´æ–°ç›®æ ‡ç½‘ç»œ
        if agent_state.steps_done % self.config['agent_lightning']['rl']['dqn']['target_update'] == 0:
            agent_state.target_net.load_state_dict(agent_state.policy_net.state_dict())

        logger.debug(f"æ™ºèƒ½ä½“ä¼˜åŒ–: æŸå¤±={loss.item():.4f}, æ­¥æ•°={agent_state.steps_done}")

    def _update_epsilon(self, steps_done: int) -> float:
        """æ›´æ–°æ¢ç´¢ç‡"""
        epsilon_start = self.config['agent_lightning']['rl']['exploration']['epsilon_start']
        epsilon_end = self.config['agent_lightning']['rl']['exploration']['epsilon_end']
        epsilon_decay = self.config['agent_lightning']['rl']['exploration']['epsilon_decay']

        epsilon = epsilon_end + (epsilon_start - epsilon_end) * \
                  np.exp(-1. * steps_done / epsilon_decay)

        return max(epsilon_end, epsilon)

    # ==================== è¾…åŠ©æ–¹æ³• ====================

    def _prepare_state_tensor(self, context: Dict[str, Any]) -> np.ndarray:
        """å‡†å¤‡çŠ¶æ€å¼ é‡"""
        # ä»ä¸Šä¸‹æ–‡ä¸­æå–ç‰¹å¾
        features = context.get('features', {})
        metrics = context.get('metrics', {})

        # æ„å»ºçŠ¶æ€å‘é‡
        state_parts = []

        # æ·»åŠ ç»Ÿè®¡ç‰¹å¾
        if 'statistics' in features:
            stats = features['statistics']
            state_parts.extend([
                stats.get('mean', 0),
                stats.get('std', 1),
                stats.get('skewness', 0),
                stats.get('kurtosis', 0)
            ])

        # æ·»åŠ æ€§èƒ½æŒ‡æ ‡
        state_parts.extend([
            metrics.get('mse', 0),
            metrics.get('mae', 0),
            metrics.get('val_loss', 0)
        ])

        # æ·»åŠ å½“å‰å‚æ•°
        current_params = context.get('current_params', {})
        state_parts.extend([
            current_params.get('spectral_threshold', 0.5),
            current_params.get('laplacian_weight', 0.01)
        ])

        # ç¡®ä¿çŠ¶æ€ç»´åº¦ä¸€è‡´
        state_dim = self.config['agent_lightning']['rl']['state_dim']
        state = np.zeros(state_dim)

        # å¡«å……çŠ¶æ€å‘é‡
        valid_len = min(len(state_parts), state_dim)
        state[:valid_len] = state_parts[:valid_len]

        # å½’ä¸€åŒ–
        state = (state - state.mean()) / (state.std() + 1e-8)

        return state

    def _prepare_autogen_context(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡AutoGenä¸Šä¸‹æ–‡"""
        return {
            'features': context.get('features', {}),
            'metrics': context.get('metrics', {}),
            'current_params': context.get('current_params', {}),
            'training_info': context.get('training_info', {}),
            'step': context.get('batch_idx', 0),
            'batch_idx': context.get('batch_idx', 0),
            'global_step': context.get('global_step', 0)
        }

    def _calculate_semantic_reward(self, conversation_result) -> float:
        """è®¡ç®—è¯­ä¹‰å¥–åŠ±"""
        if not conversation_result.consensus:
            return -0.1  # æ²¡æœ‰å…±è¯†çš„æƒ©ç½š

        consensus_level = conversation_result.consensus.get('agreement_level', 0)

        # åŸºäºå…±è¯†ç¨‹åº¦çš„å¥–åŠ±
        reward = consensus_level * 0.5

        # æ·»åŠ å‚æ•°åˆç†æ€§çš„å¥–åŠ±
        parameters = conversation_result.consensus.get('parameters', {})
        if parameters:
            # æ£€æŸ¥å‚æ•°èŒƒå›´
            valid_params = 0
            if 'spectral_threshold' in parameters:
                if 0.1 <= parameters['spectral_threshold'] <= 0.9:
                    valid_params += 1

            if 'laplacian_weight' in parameters:
                if 0.001 <= parameters['laplacian_weight'] <= 0.1:
                    valid_params += 1

            reward += valid_params * 0.1

        return min(1.0, max(-1.0, reward))

    def _calculate_task_priority(self, request: TrainingRequest) -> int:
        """è®¡ç®—ä»»åŠ¡ä¼˜å…ˆçº§"""
        # ç®€å•å®ç°ï¼šåŸºäºå®¢æˆ·ç«¯IDçš„å“ˆå¸Œ
        priority = hash(request.client_id) % 100

        # é«˜ä¼˜å…ˆçº§ä»»åŠ¡ï¼šæ¨¡å‹åˆå§‹åŒ–æˆ–å…³é”®è®­ç»ƒ
        if request.model_config.get('type') == 'init':
            priority += 100

        return -priority  # æ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼ˆPythonä¼˜å…ˆé˜Ÿåˆ—ï¼‰

    async def _get_fallback_decision(self, request: AgentDecisionRequest) -> Dict[str, Any]:
        """è·å–å¤‡ç”¨å†³ç­–ï¼ˆå½“ä¸»ç³»ç»Ÿå¤±è´¥æ—¶ï¼‰"""
        logger.warning(f"ä½¿ç”¨å¤‡ç”¨å†³ç­– for client {request.client_id}")

        # ç®€å•å¯å‘å¼è§„åˆ™
        metrics = request.context.get('metrics', {})
        mse = metrics.get('mse', 0)

        if mse > 0.3:
            action = 4  # æ¿€è¿›è°ƒæ•´
            parameters = {
                'spectral_threshold': 0.7,
                'laplacian_weight': 0.03,
                'learning_rate_multiplier': 1.5
            }
        elif mse > 0.1:
            action = 2  # é€‚åº¦è°ƒæ•´
            parameters = {
                'spectral_threshold': 0.6,
                'laplacian_weight': 0.02,
                'learning_rate_multiplier': 1.2
            }
        else:
            action = 0  # ä¿æŒ
            parameters = {
                'spectral_threshold': 0.5,
                'laplacian_weight': 0.01,
                'learning_rate_multiplier': 1.0
            }

        return {
            'decision_id': str(uuid.uuid4()),
            'action': action,
            'parameters': parameters,
            'semantic_reward': 0.0,
            'fallback': True,
            'timestamp': datetime.now().isoformat()
        }

    # ==================== æœåŠ¡çŠ¶æ€æ–¹æ³• ====================

    def get_service_status(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡çŠ¶æ€"""
        return {
            'status': 'healthy',
            'version': '2.0.0',
            'timestamp': datetime.now().isoformat(),
            'metrics': self.metrics,
            'workers': [
                {
                    'id': worker_id,
                    'busy': worker_info['busy'],
                    'current_task': worker_info['current_task'],
                    'tasks_processed': worker_info['tasks_processed']
                }
                for worker_id, worker_info in self.workers.items()
            ],
            'active_clients': len(self.client_sessions),
            'pending_tasks': self.training_queue.qsize(),
            'total_tasks': len(self.training_tasks)
        }

    def cleanup_inactive_sessions(self, timeout_hours: int = 24):
        """æ¸…ç†ä¸æ´»è·ƒçš„ä¼šè¯"""
        cutoff_time = datetime.now() - timedelta(hours=timeout_hours)

        inactive_clients = []
        for client_id, session in self.client_sessions.items():
            if session['last_active'] < cutoff_time:
                inactive_clients.append(client_id)

        for client_id in inactive_clients:
            del self.client_sessions[client_id]
            logger.info(f"æ¸…ç†ä¸æ´»è·ƒå®¢æˆ·ç«¯: {client_id}")

        self.metrics['active_clients'] = len(self.client_sessions)
        return len(inactive_clients)


# ==================== ç¥ç»ç½‘ç»œå®šä¹‰ ====================
class DQNNetwork(nn.Module):
    """DQNç½‘ç»œ"""

    def __init__(self, state_dim: int, action_dim: int, hidden_dim: int = 128):
        super().__init__()

        self.network = nn.Sequential(
            nn.Linear(state_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, action_dim)
        )

        self._init_weights()

    def _init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for layer in self.network:
            if isinstance(layer, nn.Linear):
                nn.init.xavier_uniform_(layer.weight)
                nn.init.zeros_(layer.bias)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.network(x)


class ReplayBuffer:
    """ç»éªŒå›æ”¾ç¼“å†²åŒº"""

    def __init__(self, capacity: int):
        self.buffer = []
        self.capacity = capacity
        self.position = 0
        self.batch_size = 32  # é»˜è®¤æ‰¹æ¬¡å¤§å°

    def push(self, state, action, reward, next_state, done):
        """ä¿å­˜ç»éªŒ"""
        if len(self.buffer) < self.capacity:
            self.buffer.append(None)

        self.buffer[self.position] = (state, action, reward, next_state, done)
        self.position = (self.position + 1) % self.capacity

    def sample(self, batch_size: int):
        """éšæœºé‡‡æ ·"""
        self.batch_size = batch_size

        if len(self.buffer) < batch_size:
            return []

        indices = np.random.choice(len(self.buffer), batch_size, replace=False)
        return [self.buffer[i] for i in indices]

    def __len__(self):
        return len(self.buffer)


Transition = namedtuple('Transition',
                        ('state', 'action', 'reward', 'next_state', 'done'))

# ==================== APIè·¯ç”± ====================

# å…¨å±€æœåŠ¡å®ä¾‹
service_instance = None


def get_service():
    """è·å–æœåŠ¡å®ä¾‹"""
    global service_instance
    if service_instance is None:
        # åŠ è½½é…ç½®
        import yaml
        with open("./config.yaml", "r") as f:
            config = yaml.safe_load(f)

        service_instance = AgentLightningService(config)

    return service_instance


@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨äº‹ä»¶"""
    logger.info("ğŸš€ Agent LightningæœåŠ¡å¯åŠ¨")
    get_service()  # åˆå§‹åŒ–æœåŠ¡


@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­äº‹ä»¶"""
    logger.info("ğŸ›‘ Agent LightningæœåŠ¡å…³é—­")


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "service": "Agent Lightning",
        "version": "2.0.0",
        "status": "running",
        "docs": "/api/docs"
    }


@app.get("/api/v1/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    service = get_service()
    status = service.get_service_status()

    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        **status
    }


@app.post("/api/v1/training/submit")
async def submit_training(request: TrainingRequest):
    """æäº¤è®­ç»ƒä»»åŠ¡"""
    service = get_service()

    try:
        task_id = await service.submit_training(request)

        return JSONResponse(
            status_code=202,  # Accepted
            content={
                "task_id": task_id,
                "status": "submitted",
                "message": "è®­ç»ƒä»»åŠ¡å·²æäº¤",
                "timestamp": datetime.now().isoformat()
            }
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/training/status/{task_id}")
async def get_training_status(task_id: str):
    """è·å–è®­ç»ƒçŠ¶æ€"""
    service = get_service()

    task = service.training_tasks.get(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="Task not found")

    return {
        "task_id": task_id,
        "status": task.status,
        "progress": task.progress,
        "metrics": task.metrics,
        "error": task.error,
        "created_at": task.created_at.isoformat() if task.created_at else None,
        "started_at": task.started_at.isoformat() if task.started_at else None,
        "completed_at": task.completed_at.isoformat() if task.completed_at else None
    }


@app.post("/api/v1/agent/decision")
async def get_agent_decision(request: AgentDecisionRequest):
    """è·å–æ™ºèƒ½ä½“å†³ç­–"""
    service = get_service()

    try:
        decision = await service.get_agent_decision(request)

        return decision
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/v1/agent/update")
async def update_agent_experience(request: ExperienceUpdateRequest):
    """æ›´æ–°æ™ºèƒ½ä½“ç»éªŒ"""
    service = get_service()

    try:
        result = await service.update_agent_experience(request)
        return result
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/agent/stats/{client_id}")
async def get_agent_stats(client_id: str):
    """è·å–æ™ºèƒ½ä½“ç»Ÿè®¡ä¿¡æ¯"""
    service = get_service()

    if client_id not in service.client_sessions:
        raise HTTPException(status_code=404, detail="Client not found")

    session = service.client_sessions[client_id]
    agent_state = session['agent_state']

    return {
        "client_id": client_id,
        "agent_id": agent_state.agent_id,
        "epsilon": agent_state.epsilon,
        "steps_done": agent_state.steps_done,
        "memory_size": len(agent_state.memory),
        "episode_rewards": {
            "recent_10": agent_state.episode_rewards[-10:] if agent_state.episode_rewards else [],
            "average": np.mean(agent_state.episode_rewards[-100:]) if agent_state.episode_rewards else 0,
            "std": np.std(agent_state.episode_rewards[-100:]) if agent_state.episode_rewards else 0
        },
        "created_at": agent_state.created_at.isoformat(),
        "last_updated": agent_state.last_updated.isoformat()
    }


@app.get("/api/v1/service/metrics")
async def get_service_metrics():
    """è·å–æœåŠ¡æŒ‡æ ‡"""
    service = get_service()

    return service.get_service_status()


@app.post("/api/v1/service/cleanup")
async def cleanup_sessions(timeout_hours: int = 24):
    """æ¸…ç†ä¸æ´»è·ƒä¼šè¯"""
    service = get_service()

    cleaned = service.cleanup_inactive_sessions(timeout_hours)

    return {
        "cleaned_sessions": cleaned,
        "remaining_sessions": len(service.client_sessions),
        "timestamp": datetime.now().isoformat()
    }


if __name__ == "__main__":
    import uvicorn

    # åŠ è½½é…ç½®
    import yaml

    with open("./config.yaml", "r") as f:
        config = yaml.safe_load(f)

    service_config = config['agent_lightning']['service']

    uvicorn.run(
        app,
        host=service_config['host'],
        port=service_config['port'],
        workers=service_config['workers'],
        timeout=service_config['timeout']
    )