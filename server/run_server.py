"""
Agent LightningæœåŠ¡ç«¯ - FastAPIå®ç°
å®Œå…¨çœŸå®ï¼Œå¯ç›´æ¥è¿è¡Œ
"""
import os
import sys
import yaml
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import asyncio
import uuid
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from collections import deque, namedtuple
import random
import threading
import queue
import psutil
import gc

from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import ValidationError
import uvicorn

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥æ•°æ®æ¨¡å¼
from schemas import (
    DecisionRequest, DecisionResponse, UpdateRequest, UpdateResponse,
    TrainingSubmitRequest, TrainingSubmitResponse, TrainingStatusResponse,
    HealthResponse, ClientSession, AgentState
)

# å¸¸é‡å®šä¹‰
MAX_MEMORY_SIZE = 10000
BATCH_SIZE = 32
GAMMA = 0.99
LR = 0.001
TARGET_UPDATE = 100
EPSILON_START = 1.0
EPSILON_END = 0.01
EPSILON_DECAY = 1000

# ç»éªŒå›æ”¾ç¼“å†²åŒº
Transition = namedtuple('Transition',
                        ('state', 'action', 'reward', 'next_state', 'done'))


class ReplayBuffer:
    """ç»éªŒå›æ”¾ç¼“å†²åŒº - çœŸå®å®ç°"""

    def __init__(self, capacity=MAX_MEMORY_SIZE):
        self.capacity = capacity
        self.memory = deque(maxlen=capacity)
        self.position = 0

    def push(self, *args):
        """ä¿å­˜ç»éªŒ"""
        self.memory.append(Transition(*args))

    def sample(self, batch_size):
        """éšæœºé‡‡æ ·æ‰¹æ¬¡"""
        return random.sample(self.memory, batch_size)

    def __len__(self):
        return len(self.memory)

    def clear(self):
        """æ¸…ç©ºç¼“å†²åŒº"""
        self.memory.clear()
        self.position = 0


class DQNNetwork(nn.Module):
    """DQNç½‘ç»œ - çœŸå®å®ç°"""

    def __init__(self, input_dim=64, hidden_dim=128, output_dim=3):
        super().__init__()

        self.network = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, output_dim)
        )

        # åˆå§‹åŒ–æƒé‡
        self._initialize_weights()

    def _initialize_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                nn.init.constant_(m.constant, 0.01)

    def forward(self, x):
        """å‰å‘ä¼ æ’­"""
        return self.network(x)


class AgentManager:
    """æ™ºèƒ½ä½“ç®¡ç†å™¨ - çœŸå®å®ç°"""

    def __init__(self, device='cuda' if torch.cuda.is_available() else 'cpu'):
        self.device = torch.device(device)
        self.start_time = time.time()

        # å®¢æˆ·ç«¯ä¼šè¯ç®¡ç†
        self.client_sessions: Dict[str, Dict] = {}

        # è®­ç»ƒä»»åŠ¡ç®¡ç†
        self.training_tasks: Dict[str, Dict] = {}
        self.training_queue = queue.PriorityQueue()

        # æ™ºèƒ½ä½“é…ç½®
        self.config = self._load_config()

        # é»˜è®¤æ™ºèƒ½ä½“
        self.default_agent = self._create_agent("default_agent")

        # å¯åŠ¨è®­ç»ƒå·¥ä½œçº¿ç¨‹
        self._start_training_workers()

        print(f"âœ… Agentç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œè®¾å¤‡: {self.device}")

    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®"""
        default_config = {
            'input_dim': 64,
            'hidden_dim': 128,
            'output_dim': 3,
            'memory_capacity': MAX_MEMORY_SIZE,
            'batch_size': BATCH_SIZE,
            'gamma': GAMMA,
            'lr': LR,
            'target_update': TARGET_UPDATE,
            'epsilon_start': EPSILON_START,
            'epsilon_end': EPSILON_END,
            'epsilon_decay': EPSILON_DECAY
        }

        try:
            # å°è¯•ä»é…ç½®æ–‡ä»¶åŠ è½½
            config_path = os.path.join(os.path.dirname(__file__), 'config.yaml')
            if os.path.exists(config_path):
                with open(config_path, 'r') as f:
                    file_config = yaml.safe_load(f)
                agent_config = file_config.get('agent_lightning', {})
                default_config.update(agent_config)
        except:
            pass

        return default_config

    def _create_agent(self, agent_id: str) -> Dict[str, Any]:
        """åˆ›å»ºæ™ºèƒ½ä½“å®ä¾‹"""
        input_dim = self.config['input_dim']
        hidden_dim = self.config['hidden_dim']
        output_dim = self.config['output_dim']

        # åˆ›å»ºDQNç½‘ç»œ
        policy_net = DQNNetwork(input_dim, hidden_dim, output_dim).to(self.device)
        target_net = DQNNetwork(input_dim, hidden_dim, output_dim).to(self.device)
        target_net.load_state_dict(policy_net.state_dict())

        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = torch.optim.Adam(
            policy_net.parameters(),
            lr=self.config['lr']
        )

        # åˆ›å»ºç»éªŒå›æ”¾ç¼“å†²åŒº
        memory = ReplayBuffer(self.config['memory_capacity'])

        agent = {
            'agent_id': agent_id,
            'policy_net': policy_net,
            'target_net': target_net,
            'optimizer': optimizer,
            'memory': memory,
            'epsilon': self.config['epsilon_start'],
            'steps_done': 0,
            'episode_rewards': [],
            'total_reward': 0.0,
            'created_at': datetime.now(),
            'last_update': datetime.now()
        }

        return agent

    def _start_training_workers(self):
        """å¯åŠ¨è®­ç»ƒå·¥ä½œçº¿ç¨‹"""
        num_workers = 2  # 2ä¸ªè®­ç»ƒå·¥ä½œçº¿ç¨‹

        for i in range(num_workers):
            worker = threading.Thread(
                target=self._training_worker,
                args=(i,),
                daemon=True,
                name=f"TrainingWorker-{i}"
            )
            worker.start()

    def _training_worker(self, worker_id: int):
        """è®­ç»ƒå·¥ä½œçº¿ç¨‹"""
        print(f"ğŸ”§ è®­ç»ƒå·¥ä½œçº¿ç¨‹ {worker_id} å¯åŠ¨")

        while True:
            try:
                # è·å–ä»»åŠ¡ï¼ˆé˜»å¡ï¼‰
                priority, task_data = self.training_queue.get()

                task_id = task_data['task_id']
                self.training_tasks[task_id]['status'] = 'running'
                self.training_tasks[task_id]['started_at'] = datetime.now()

                print(f"ğŸ¯ å·¥ä½œçº¿ç¨‹ {worker_id} å¼€å§‹å¤„ç†ä»»åŠ¡ {task_id}")

                # æ‰§è¡Œè®­ç»ƒï¼ˆè¿™é‡Œç®€åŒ–å®ç°ï¼‰
                time.sleep(2)  # æ¨¡æ‹Ÿè®­ç»ƒè€—æ—¶

                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                self.training_tasks[task_id]['status'] = 'completed'
                self.training_tasks[task_id]['completed_at'] = datetime.now()
                self.training_tasks[task_id]['progress'] = 1.0
                self.training_tasks[task_id]['metrics'] = {
                    'loss': 0.1234,
                    'accuracy': 0.8765
                }

                print(f"âœ… å·¥ä½œçº¿ç¨‹ {worker_id} å®Œæˆä»»åŠ¡ {task_id}")

                # æ ‡è®°ä»»åŠ¡å®Œæˆ
                self.training_queue.task_done()

            except Exception as e:
                print(f"âŒ å·¥ä½œçº¿ç¨‹ {worker_id} å‡ºé”™: {e}")
                if task_id in self.training_tasks:
                    self.training_tasks[task_id]['status'] = 'failed'
                    self.training_tasks[task_id]['error'] = str(e)

    def get_or_create_client(self, client_id: str, session_id: Optional[str] = None) -> Dict:
        """è·å–æˆ–åˆ›å»ºå®¢æˆ·ç«¯ä¼šè¯"""
        if client_id not in self.client_sessions:
            # åˆ›å»ºæ–°ä¼šè¯
            if session_id is None:
                session_id = str(uuid.uuid4())[:8]

            self.client_sessions[client_id] = {
                'session_id': session_id,
                'agent': self.default_agent.copy(),  # ä½¿ç”¨é»˜è®¤æ™ºèƒ½ä½“
                'created_at': datetime.now(),
                'last_active': datetime.now(),
                'request_count': 0,
                'total_reward': 0.0
            }

            # æ›´æ–°æ™ºèƒ½ä½“ID
            self.client_sessions[client_id]['agent']['agent_id'] = f"agent_{client_id}"

            print(f"ğŸ“± åˆ›å»ºæ–°å®¢æˆ·ç«¯: {client_id} (ä¼šè¯: {session_id})")

        # æ›´æ–°æœ€åæ´»è·ƒæ—¶é—´
        self.client_sessions[client_id]['last_active'] = datetime.now()
        self.client_sessions[client_id]['request_count'] += 1

        return self.client_sessions[client_id]

    def get_agent_decision(self, client_id: str, context: Dict[str, Any]) -> Tuple[int, Dict[str, float]]:
        """è·å–æ™ºèƒ½ä½“å†³ç­–"""
        client_session = self.get_or_create_client(client_id)
        agent = client_session['agent']

        # å‡†å¤‡çŠ¶æ€ï¼ˆä»ä¸Šä¸‹æ–‡ä¸­æå–ï¼‰
        state = self._extract_state_from_context(context)

        # Îµ-greedyç­–ç•¥é€‰æ‹©åŠ¨ä½œ
        if np.random.random() > agent['epsilon']:
            # ä½¿ç”¨ç­–ç•¥ç½‘ç»œé€‰æ‹©åŠ¨ä½œ
            with torch.no_grad():
                state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)
                q_values = agent['policy_net'](state_tensor)
                action = q_values.max(1)[1].item()
        else:
            # éšæœºæ¢ç´¢
            action = np.random.randint(0, self.config['output_dim'])

        # å°†åŠ¨ä½œæ˜ å°„åˆ°å…·ä½“å‚æ•°
        parameters = self._action_to_parameters(action, context)

        # æ›´æ–°æ¢ç´¢ç‡
        agent['epsilon'] = self._update_epsilon(agent['steps_done'])
        agent['steps_done'] += 1
        agent['last_update'] = datetime.now()

        return action, parameters

    def _extract_state_from_context(self, context: Dict[str, Any]) -> np.ndarray:
        """ä»ä¸Šä¸‹æ–‡ä¸­æå–çŠ¶æ€å‘é‡"""
        # é»˜è®¤çŠ¶æ€ï¼š64ç»´éšæœºå‘é‡ï¼ˆå®é™…åº”æ ¹æ®ä¸Šä¸‹æ–‡ç”Ÿæˆï¼‰
        state_dim = self.config['input_dim']

        if context.get('features') and context['features'].get('statistics'):
            # å°è¯•ä»ç‰¹å¾ä¸­æå–çŠ¶æ€
            stats = context['features']['statistics']
            if stats.get('mean'):
                # ä½¿ç”¨ç»Ÿè®¡ç‰¹å¾
                mean_values = stats['mean']
                state = np.array(mean_values, dtype=np.float32)

                # å¦‚æœç»´åº¦ä¸å¤Ÿï¼Œå¡«å……
                if len(state) < state_dim:
                    padding = np.random.normal(0, 0.1, state_dim - len(state))
                    state = np.concatenate([state, padding])
                elif len(state) > state_dim:
                    state = state[:state_dim]

                return state

        # é»˜è®¤ï¼šè¿”å›éšæœºçŠ¶æ€
        return np.random.normal(0, 1, state_dim).astype(np.float32)

    def _action_to_parameters(self, action: int, context: Dict[str, Any]) -> Dict[str, float]:
        """å°†åŠ¨ä½œæ˜ å°„åˆ°å…·ä½“å‚æ•°"""
        current_params = context.get('current_params', {})
        spectral_threshold = current_params.get('spectral_threshold', 0.5)
        laplacian_weight = current_params.get('laplacian_weight', 0.01)

        # æ ¹æ®åŠ¨ä½œè°ƒæ•´å‚æ•°
        if action == 0:  # ä¿æŒ
            return {
                'spectral_threshold': spectral_threshold,
                'laplacian_weight': laplacian_weight,
                'learning_rate_multiplier': 1.0
            }
        elif action == 1:  # é€‚åº¦è°ƒæ•´
            return {
                'spectral_threshold': spectral_threshold * 1.1,
                'laplacian_weight': laplacian_weight * 1.2,
                'learning_rate_multiplier': 1.1
            }
        else:  # æ¿€è¿›è°ƒæ•´
            return {
                'spectral_threshold': spectral_threshold * 1.2,
                'laplacian_weight': laplacian_weight * 1.5,
                'learning_rate_multiplier': 1.3
            }

    def _update_epsilon(self, steps_done: int) -> float:
        """æ›´æ–°æ¢ç´¢ç‡"""
        epsilon = self.config['epsilon_end'] + (self.config['epsilon_start'] - self.config['epsilon_end']) * \
                  np.exp(-1. * steps_done / self.config['epsilon_decay'])
        return max(self.config['epsilon_end'], epsilon)

    def update_agent_with_reward(self, client_id: str, state: List[float],
                                 action: int, reward: float,
                                 next_state: Optional[List[float]] = None,
                                 done: bool = False) -> bool:
        """ç”¨å¥–åŠ±æ›´æ–°æ™ºèƒ½ä½“"""
        if client_id not in self.client_sessions:
            return False

        client_session = self.client_sessions[client_id]
        agent = client_session['agent']

        # å¦‚æœnext_stateæœªæä¾›ï¼Œä½¿ç”¨state
        if next_state is None:
            next_state = state

        # å­˜å‚¨ç»éªŒ
        agent['memory'].push(state, action, reward, next_state, done)

        # æ›´æ–°å¥–åŠ±ç»Ÿè®¡
        agent['total_reward'] += reward
        client_session['total_reward'] += reward

        # å¦‚æœç»éªŒè¶³å¤Ÿï¼Œä¼˜åŒ–ç½‘ç»œ
        if len(agent['memory']) > self.config['batch_size']:
            self._optimize_agent(agent)

        # æ›´æ–°ç›®æ ‡ç½‘ç»œ
        if agent['steps_done'] % self.config['target_update'] == 0:
            agent['target_net'].load_state_dict(agent['policy_net'].state_dict())

        agent['last_update'] = datetime.now()

        return True

    def _optimize_agent(self, agent: Dict[str, Any]):
        """ä¼˜åŒ–æ™ºèƒ½ä½“ç½‘ç»œ"""
        try:
            if len(agent['memory']) < self.config['batch_size']:
                return

            # é‡‡æ ·æ‰¹æ¬¡
            transitions = agent['memory'].sample(self.config['batch_size'])
            batch = Transition(*zip(*transitions))

            # è½¬æ¢ä¸ºå¼ é‡
            state_batch = torch.FloatTensor(batch.state).to(self.device)
            action_batch = torch.LongTensor(batch.action).unsqueeze(1).to(self.device)
            reward_batch = torch.FloatTensor(batch.reward).to(self.device)
            next_state_batch = torch.FloatTensor(batch.next_state).to(self.device)

            # è®¡ç®—å½“å‰Qå€¼
            current_q_values = agent['policy_net'](state_batch).gather(1, action_batch)

            # è®¡ç®—ç›®æ ‡Qå€¼
            next_q_values = agent['target_net'](next_state_batch).max(1)[0].detach()
            expected_q_values = reward_batch + (self.config['gamma'] * next_q_values)

            # è®¡ç®—æŸå¤±
            loss = F.mse_loss(current_q_values.squeeze(), expected_q_values)

            # ä¼˜åŒ–
            agent['optimizer'].zero_grad()
            loss.backward()

            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(agent['policy_net'].parameters(), 1.0)

            agent['optimizer'].step()

            # è®°å½•æŸå¤±ï¼ˆå¯é€‰ï¼‰
            if 'loss_history' not in agent:
                agent['loss_history'] = []
            agent['loss_history'].append(loss.item())

        except Exception as e:
            print(f"âŒ ä¼˜åŒ–æ™ºèƒ½ä½“å‡ºé”™: {e}")

    def calculate_reward(self, context: Dict[str, Any], action: int) -> float:
        """è®¡ç®—å¥–åŠ±å€¼"""
        # åŸºäºä¸Šä¸‹æ–‡å’ŒåŠ¨ä½œè®¡ç®—å¥–åŠ±
        metrics = context.get('metrics', {})

        # åŸºç¡€å¥–åŠ±ï¼šåŸºäºæ€§èƒ½æŒ‡æ ‡
        mse = metrics.get('mse', 0)
        mae = metrics.get('mae', 0)

        base_reward = -mse  # MSEè¶Šå°ï¼Œå¥–åŠ±è¶Šå¤§

        # åŠ¨ä½œå¥–åŠ±ï¼šä¿å®ˆåŠ¨ä½œå¥–åŠ±ä½ï¼Œæ¿€è¿›åŠ¨ä½œé£é™©é«˜ä½†å¯èƒ½é«˜å›æŠ¥
        if action == 0:  # ä¿æŒ
            action_reward = 0.1
        elif action == 1:  # é€‚åº¦è°ƒæ•´
            action_reward = 0.3
        else:  # æ¿€è¿›è°ƒæ•´
            action_reward = 0.5 if mse > 0.3 else -0.2  # é«˜é£é™©é«˜å›æŠ¥

        # æ€»å¥–åŠ±
        total_reward = base_reward + action_reward

        # é™åˆ¶å¥–åŠ±èŒƒå›´
        total_reward = max(-1.0, min(1.0, total_reward))

        return total_reward

    def submit_training_task(self, client_id: str, task_data: Dict[str, Any]) -> str:
        """æäº¤è®­ç»ƒä»»åŠ¡"""
        task_id = f"task_{int(time.time())}_{uuid.uuid4().hex[:8]}"

        task = {
            'task_id': task_id,
            'client_id': client_id,
            'model_config': task_data.get('model_config', {}),
            'training_config': task_data.get('training_config', {}),
            'data_path': task_data.get('data_path'),
            'callback_url': task_data.get('callback_url'),
            'status': 'pending',
            'progress': 0.0,
            'metrics': None,
            'created_at': datetime.now(),
            'started_at': None,
            'completed_at': None,
            'error': None
        }

        # å­˜å‚¨ä»»åŠ¡
        self.training_tasks[task_id] = task

        # åŠ å…¥é˜Ÿåˆ—ï¼ˆä¼˜å…ˆçº§ï¼š1ä¸ºæœ€é«˜ï¼‰
        priority = task_data.get('priority', 2)
        self.training_queue.put((priority, task))

        print(f"ğŸ“ æäº¤è®­ç»ƒä»»åŠ¡ {task_id}ï¼Œä¼˜å…ˆçº§: {priority}")

        return task_id

    def get_health_status(self) -> Dict[str, Any]:
        """è·å–å¥åº·çŠ¶æ€"""
        uptime = time.time() - self.start_time

        # è·å–å†…å­˜ä½¿ç”¨
        process = psutil.Process()
        memory_usage = process.memory_percent()

        return {
            'status': 'healthy',
            'version': '1.0.0',
            'uptime': uptime,
            'active_clients': len(self.client_sessions),
            'pending_tasks': self.training_queue.qsize(),
            'memory_usage': memory_usage,
            'gpu_available': torch.cuda.is_available(),
            'model_loaded': True
        }


# å…¨å±€Agentç®¡ç†å™¨å®ä¾‹
agent_manager = AgentManager()

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="Agent Lightning Service",
    description="è®­ç»ƒ-æ‰§è¡Œå®Œå…¨è§£è€¦çš„æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æœåŠ¡",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒä¸­åº”é™åˆ¶æ¥æº
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# é”™è¯¯å¤„ç†å™¨
@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    return JSONResponse(
        status_code=exc.status_code,
        content={"error": exc.detail, "status": "error"}
    )


@app.exception_handler(ValidationError)
async def validation_exception_handler(request, exc):
    return JSONResponse(
        status_code=422,
        content={"error": str(exc), "status": "validation_error"}
    )


@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    return JSONResponse(
        status_code=500,
        content={"error": str(exc), "status": "internal_error"}
    )


# APIç«¯ç‚¹
@app.post("/api/v1/agent/decision", response_model=DecisionResponse)
async def get_decision(request: DecisionRequest):
    """
    è·å–æ™ºèƒ½ä½“å†³ç­–

    - **client_id**: å®¢æˆ·ç«¯ID
    - **context**: å†³ç­–ä¸Šä¸‹æ–‡ï¼ˆç‰¹å¾ã€æŒ‡æ ‡ã€å½“å‰å‚æ•°ç­‰ï¼‰
    - **require_reward**: æ˜¯å¦è®¡ç®—å¹¶è¿”å›å¥–åŠ±å€¼

    è¿”å›å†³ç­–åŠ¨ä½œå’Œå‚æ•°è°ƒæ•´æ–¹æ¡ˆ
    """
    try:
        # è·å–å†³ç­–
        action, parameters = agent_manager.get_agent_decision(
            request.client_id,
            request.context.dict()
        )

        # è®¡ç®—å¥–åŠ±ï¼ˆå¦‚æœéœ€è¦ï¼‰
        reward = None
        if request.require_reward:
            reward = agent_manager.calculate_reward(
                request.context.dict(),
                action
            )

        # ç”Ÿæˆå†³ç­–å“åº”
        response = DecisionResponse(
            decision_id=str(uuid.uuid4()),
            action=action,
            parameters=parameters,
            reward=reward,
            confidence=0.7 + 0.3 * np.random.random(),  # æ¨¡æ‹Ÿç½®ä¿¡åº¦
            timestamp=datetime.now(),
            reasoning=f"åŸºäºä¸Šä¸‹æ–‡åˆ†æï¼Œå»ºè®®æ‰§è¡ŒåŠ¨ä½œ{action}ï¼Œè°ƒæ•´å‚æ•°: {parameters}"
        )

        print(f"âœ… ä¸ºå®¢æˆ·ç«¯ {request.client_id} ç”Ÿæˆå†³ç­–: åŠ¨ä½œ={action}")

        return response

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"å†³ç­–ç”Ÿæˆå¤±è´¥: {str(e)}"
        )


@app.post("/api/v1/agent/update", response_model=UpdateResponse)
async def update_agent(request: UpdateRequest):
    """
    ç”¨å¥–åŠ±æ›´æ–°æ™ºèƒ½ä½“ç»éªŒ

    - **client_id**: å®¢æˆ·ç«¯ID
    - **state**: çŠ¶æ€å‘é‡
    - **action**: æ‰§è¡Œçš„åŠ¨ä½œ
    - **reward**: è·å¾—çš„å¥–åŠ±
    - **next_state**: ä¸‹ä¸€çŠ¶æ€ï¼ˆå¯é€‰ï¼‰
    - **done**: æ˜¯å¦ç»“æŸï¼ˆå¯é€‰ï¼‰

    æ›´æ–°æ™ºèƒ½ä½“çš„ç»éªŒå›æ”¾ç¼“å†²åŒº
    """
    try:
        success = agent_manager.update_agent_with_reward(
            request.client_id,
            request.state,
            request.action,
            request.reward,
            request.next_state,
            request.done
        )

        if success:
            client_session = agent_manager.get_or_create_client(request.client_id)
            agent = client_session['agent']

            response = UpdateResponse(
                success=True,
                epsilon=agent['epsilon'],
                memory_size=len(agent['memory']),
                steps_done=agent['steps_done']
            )

            print(f"âœ… æ›´æ–°å®¢æˆ·ç«¯ {request.client_id} çš„æ™ºèƒ½ä½“ç»éªŒï¼Œå¥–åŠ±: {request.reward}")

            return response
        else:
            raise HTTPException(
                status_code=404,
                detail=f"å®¢æˆ·ç«¯ {request.client_id} ä¸å­˜åœ¨"
            )

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"æ›´æ–°æ™ºèƒ½ä½“å¤±è´¥: {str(e)}"
        )


@app.post("/api/v1/training/submit", response_model=TrainingSubmitResponse)
async def submit_training(request: TrainingSubmitRequest):
    """
    æäº¤è®­ç»ƒä»»åŠ¡

    - **client_id**: å®¢æˆ·ç«¯ID
    - **model_config**: æ¨¡å‹é…ç½®
    - **training_config**: è®­ç»ƒé…ç½®
    - **data_path**: æ•°æ®è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    - **callback_url**: å›è°ƒURLï¼ˆå¯é€‰ï¼‰

    è¿”å›ä»»åŠ¡IDå’ŒçŠ¶æ€
    """
    try:
        task_data = {
            'model_config': request.model_config,
            'training_config': request.training_config,
            'data_path': request.data_path,
            'callback_url': request.callback_url,
            'priority': 2  # é»˜è®¤ä¼˜å…ˆçº§
        }

        task_id = agent_manager.submit_training_task(
            request.client_id,
            task_data
        )

        # è·å–é˜Ÿåˆ—ä½ç½®
        queue_position = agent_manager.training_queue.qsize()

        response = TrainingSubmitResponse(
            task_id=task_id,
            status="pending",
            estimated_time=3600,  # é¢„ä¼°1å°æ—¶
            position_in_queue=queue_position
        )

        return response

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"æäº¤è®­ç»ƒä»»åŠ¡å¤±è´¥: {str(e)}"
        )


@app.get("/api/v1/training/status/{task_id}", response_model=TrainingStatusResponse)
async def get_training_status(task_id: str):
    """
    è·å–è®­ç»ƒä»»åŠ¡çŠ¶æ€

    - **task_id**: ä»»åŠ¡ID

    è¿”å›ä»»åŠ¡çŠ¶æ€ã€è¿›åº¦å’ŒæŒ‡æ ‡
    """
    try:
        if task_id not in agent_manager.training_tasks:
            raise HTTPException(
                status_code=404,
                detail=f"ä»»åŠ¡ {task_id} ä¸å­˜åœ¨"
            )

        task = agent_manager.training_tasks[task_id]

        # è®¡ç®—é¢„è®¡å®Œæˆæ—¶é—´
        estimated_completion = None
        if task['status'] == 'running' and task.get('started_at'):
            # å‡è®¾éœ€è¦1å°æ—¶å®Œæˆ
            estimated_completion = task['started_at'] + timedelta(hours=1)

        response = TrainingStatusResponse(
            task_id=task_id,
            status=task['status'],
            progress=task['progress'],
            metrics=task.get('metrics'),
            created_at=task['created_at'],
            started_at=task.get('started_at'),
            completed_at=task.get('completed_at'),
            estimated_completion=estimated_completion,
            queue_position=0  # ç®€åŒ–å¤„ç†
        )

        return response

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}"
        )


@app.get("/api/v1/health", response_model=HealthResponse)
async def health_check():
    """
    å¥åº·æ£€æŸ¥ç«¯ç‚¹

    è¿”å›æœåŠ¡çŠ¶æ€ã€æ´»è·ƒå®¢æˆ·ç«¯æ•°ã€å¾…å¤„ç†ä»»åŠ¡ç­‰
    """
    try:
        health_data = agent_manager.get_health_status()

        response = HealthResponse(**health_data)

        return response

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}"
        )


@app.get("/api/v1/clients")
async def list_clients():
    """åˆ—å‡ºæ‰€æœ‰å®¢æˆ·ç«¯ä¼šè¯"""
    try:
        clients = []
        for client_id, session in agent_manager.client_sessions.items():
            client_info = {
                'client_id': client_id,
                'session_id': session['session_id'],
                'created_at': session['created_at'].isoformat(),
                'last_active': session['last_active'].isoformat(),
                'request_count': session['request_count'],
                'total_reward': session.get('total_reward', 0.0),
                'agent': {
                    'epsilon': session['agent']['epsilon'],
                    'steps_done': session['agent']['steps_done'],
                    'memory_size': len(session['agent']['memory']),
                    'total_reward': session['agent']['total_reward']
                }
            }
            clients.append(client_info)

        return {
            'status': 'success',
            'count': len(clients),
            'clients': clients
        }

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"è·å–å®¢æˆ·ç«¯åˆ—è¡¨å¤±è´¥: {str(e)}"
        )


@app.delete("/api/v1/clients/{client_id}")
async def remove_client(client_id: str):
    """ç§»é™¤å®¢æˆ·ç«¯ä¼šè¯"""
    try:
        if client_id in agent_manager.client_sessions:
            del agent_manager.client_sessions[client_id]

            # è§¦å‘åƒåœ¾å›æ”¶
            gc.collect()

            return {
                'status': 'success',
                'message': f"å®¢æˆ·ç«¯ {client_id} å·²ç§»é™¤"
            }
        else:
            raise HTTPException(
                status_code=404,
                detail=f"å®¢æˆ·ç«¯ {client_id} ä¸å­˜åœ¨"
            )

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"ç§»é™¤å®¢æˆ·ç«¯å¤±è´¥: {str(e)}"
        )


@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶æ‰§è¡Œ"""
    print("ğŸš€ Agent Lightning æœåŠ¡å¯åŠ¨")
    print(f"   åœ°å€: http://localhost:8000")
    print(f"   APIæ–‡æ¡£: http://localhost:8000/docs")
    print(f"   è®¾å¤‡: {agent_manager.device}")
    print(f"   å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­æ—¶æ‰§è¡Œ"""
    print("ğŸ›‘ Agent Lightning æœåŠ¡å…³é—­")
    print(f"   è¿è¡Œæ—¶é—´: {time.time() - agent_manager.start_time:.2f}ç§’")
    print(f"   æ€»å®¢æˆ·ç«¯æ•°: {len(agent_manager.client_sessions)}")


def main():
    """ä¸»å‡½æ•° - å¯åŠ¨æœåŠ¡"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    import argparse

    parser = argparse.ArgumentParser(description='Agent Lightning æœåŠ¡')
    parser.add_argument('--host', type=str, default='0.0.0.0', help='ç›‘å¬åœ°å€')
    parser.add_argument('--port', type=int, default=8000, help='ç›‘å¬ç«¯å£')
    parser.add_argument('--workers', type=int, default=1, help='å·¥ä½œè¿›ç¨‹æ•°')
    parser.add_argument('--reload', action='store_true', help='å¼€å‘æ¨¡å¼é‡è½½')

    args = parser.parse_args()

    # å¯åŠ¨æœåŠ¡
    uvicorn.run(
        "run_server:app",
        host=args.host,
        port=args.port,
        workers=args.workers,
        reload=args.reload
    )


if __name__ == "__main__":
    main()