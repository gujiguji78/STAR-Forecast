# main.py - å®Œæ•´çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ é—­ç¯
import sys
import json
from pathlib import Path
import numpy as np
import pandas as pd
from typing import Dict, List, Any

# å¯¼å…¥AutoGenå¤šæ™ºèƒ½ä½“ç³»ç»Ÿ
from agents.autogen_system import AutoGenDebateSystem, DebateConfig
from agents.memory_bank import MemoryBank
from agents.debate_system import DebateOrchestrator

# å¯¼å…¥Agent Lightningå¼ºåŒ–å­¦ä¹ 
from training.lightning_client import LightningTrainer
from models.istr import ISTRPredictor
from models.ensemble import EnsemblePredictor

# å¯¼å…¥æ•°æ®å¤„ç†
from data.dataloader import TimeSeriesDataLoader
from data.processor import DataProcessor


class STARForecastSystem:
    """STAR-Forecast: æ™ºèƒ½ä½“å¼ºåŒ–é¢„æµ‹ç³»ç»Ÿ"""

    def __init__(self, config_path: str = None):
        # 1. åˆå§‹åŒ–é…ç½®
        if config_path:
            with open(config_path, 'r') as f:
                self.config = json.load(f)
        else:
            self.config = self._default_config()

        # 2. åˆå§‹åŒ–è®°å¿†é“¶è¡Œ
        self.memory_bank = MemoryBank(
            persistence_path="results/memory_store.json",
            max_memory_items=1000
        )

        # 3. åˆå§‹åŒ–å¤šæ™ºèƒ½ä½“è¾©è®ºç³»ç»Ÿ
        debate_config = DebateConfig(
            agent_count=3,  # 3ä¸ªä¸“å®¶æ™ºèƒ½ä½“
            debate_rounds=2,
            temperature=0.7,
            use_memory=True
        )
        self.debate_system = AutoGenDebateSystem(
            config=debate_config,
            memory_bank=self.memory_bank
        )

        # 4. åˆå§‹åŒ–æ·±åº¦å­¦ä¹ é¢„æµ‹å™¨
        self.predictor = ISTRPredictor.load_from_checkpoint(
            "results/train_ETTh1_96to24_20260101_230210/checkpoint.ckpt"
        )

        # 5. åˆå§‹åŒ–Agent Lightningå¼ºåŒ–å­¦ä¹ å™¨
        self.lightning_trainer = LightningTrainer(
            model=self.predictor,
            memory_bank=self.memory_bank,
            learning_rate=1e-4,
            batch_size=32
        )

        # 6. åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨
        self.data_processor = DataProcessor()

    def _default_config(self) -> Dict:
        """é»˜è®¤é…ç½®"""
        return {
            "prediction_horizon": 24,
            "lookback_window": 96,
            "debate_enabled": True,
            "reinforcement_enabled": True,
            "ensemble_method": "weighted_average"
        }

    def forecast_with_debate(self, historical_data: np.ndarray) -> Dict:
        """
        å¤šæ™ºèƒ½ä½“è¾©è®ºé¢„æµ‹æµç¨‹
        """
        print("ğŸš€ å¼€å§‹å¤šæ™ºèƒ½ä½“è¾©è®ºé¢„æµ‹...")

        # æ­¥éª¤1: åŸºç¡€æ·±åº¦å­¦ä¹ é¢„æµ‹
        base_prediction = self.predictor.predict(historical_data)

        if not self.config["debate_enabled"]:
            return {"prediction": base_prediction, "debate_log": None}

        # æ­¥éª¤2: å¯åŠ¨å¤šæ™ºèƒ½ä½“è¾©è®º
        debate_context = {
            "historical_data": historical_data.tolist(),
            "base_prediction": base_prediction.tolist(),
            "confidence_scores": self.predictor.get_confidence_scores(historical_data)
        }

        debate_result = self.debate_system.start_debate(
            topic="æ—¶é—´åºåˆ—é¢„æµ‹ä¼˜åŒ–",
            context=debate_context,
            question="å¦‚ä½•æ”¹è¿›å½“å‰é¢„æµ‹ç»“æœï¼Ÿ"
        )

        # æ­¥éª¤3: è§£æè¾©è®ºç»“æœå¹¶ä¿®æ­£é¢„æµ‹
        refined_prediction = self._apply_debate_insights(
            base_prediction,
            debate_result
        )

        # æ­¥éª¤4: å­˜å‚¨åˆ°è®°å¿†é“¶è¡Œ
        self.memory_bank.store_experience({
            "timestamp": pd.Timestamp.now(),
            "historical_data": historical_data,
            "base_prediction": base_prediction,
            "debate_result": debate_result,
            "refined_prediction": refined_prediction
        })

        return {
            "base_prediction": base_prediction,
            "refined_prediction": refined_prediction,
            "debate_log": debate_result.debate_log,
            "confidence": self._calculate_confidence(refined_prediction)
        }

    def _apply_debate_insights(self, base_pred: np.ndarray, debate_result) -> np.ndarray:
        """åº”ç”¨æ™ºèƒ½ä½“è¾©è®ºçš„è§è§£"""
        insights = debate_result.get_consensus_insights()

        # æ ¹æ®è¾©è®ºç»“æœè°ƒæ•´é¢„æµ‹
        if "adjust_trend" in insights:
            trend_adjustment = insights["adjust_trend"]
            base_pred = base_pred * (1 + trend_adjustment)

        if "smooth_variance" in insights and insights["smooth_variance"]:
            # åº”ç”¨å¹³æ»‘
            from scipy.ndimage import gaussian_filter1d
            base_pred = gaussian_filter1d(base_pred, sigma=1)

        return base_pred

    def reinforcement_training_loop(self, validation_data: Dict):
        """
        Agent Lightningå¼ºåŒ–è®­ç»ƒé—­ç¯
        """
        print("âš¡ å¯åŠ¨Agent Lightningå¼ºåŒ–è®­ç»ƒ...")

        # æ­¥éª¤1: åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°å½“å‰è¡¨ç°
        current_performance = self._evaluate_on_validation(validation_data)

        # æ­¥éª¤2: ä»è®°å¿†é“¶è¡Œè·å–é«˜è´¨é‡ç»éªŒ
        valuable_experiences = self.memory_bank.retrieve_relevant_experiences(
            query="high_confidence_predictions",
            top_k=50
        )

        # æ­¥éª¤3: æ‰§è¡Œå¼ºåŒ–å­¦ä¹ 
        if valuable_experiences and self.config["reinforcement_enabled"]:
            improvement = self.lightning_trainer.reinforce(
                experiences=valuable_experiences,
                target_metric="mse",  # ç›®æ ‡æ˜¯æœ€å°åŒ–å‡æ–¹è¯¯å·®
                n_epochs=10
            )

            print(f"ğŸ“ˆ å¼ºåŒ–å­¦ä¹ æå‡: {improvement:.4f}")

            # æ­¥éª¤4: è¯„ä¼°æå‡æ•ˆæœ
            new_performance = self._evaluate_on_validation(validation_data)

            return {
                "old_performance": current_performance,
                "new_performance": new_performance,
                "improvement": new_performance["mse"] - current_performance["mse"],
                "training_samples": len(valuable_experiences)
            }

        return {"status": "no_training_performed"}

    def _evaluate_on_validation(self, data: Dict) -> Dict:
        """åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹"""
        predictions = []
        truths = []

        for batch in data["loader"]:
            pred = self.predictor.predict(batch["x"])
            predictions.append(pred)
            truths.append(batch["y"])

        predictions = np.concatenate(predictions)
        truths = np.concatenate(truths)

        # è®¡ç®—æŒ‡æ ‡
        mse = np.mean((predictions - truths) ** 2)
        mae = np.mean(np.abs(predictions - truths))

        return {"mse": mse, "mae": mae}

    def _calculate_confidence(self, prediction: np.ndarray) -> float:
        """è®¡ç®—é¢„æµ‹ç½®ä¿¡åº¦"""
        # ä½¿ç”¨é¢„æµ‹çš„æ–¹å·®ä½œä¸ºç½®ä¿¡åº¦æŒ‡æ ‡
        variance = np.var(prediction)
        confidence = 1.0 / (1.0 + variance)
        return float(confidence)

    def run_full_pipeline(self, train_data, val_data, test_data):
        """
        è¿è¡Œå®Œæ•´é¢„æµ‹ç®¡é“
        """
        results = []

        print("=" * 50)
        print("ğŸ”® STAR-Forecast æ™ºèƒ½é¢„æµ‹ç³»ç»Ÿå¯åŠ¨")
        print("=" * 50)

        # é˜¶æ®µ1: å¤šæ™ºèƒ½ä½“è¾©è®ºé¢„æµ‹
        print("\nğŸ“Š é˜¶æ®µ1: å¤šæ™ºèƒ½ä½“è¾©è®ºé¢„æµ‹")
        for i, test_sample in enumerate(test_data[:10]):  # æµ‹è¯•å‰10ä¸ªæ ·æœ¬
            result = self.forecast_with_debate(test_sample)
            results.append(result)
            print(f"æ ·æœ¬ {i + 1}: ç½®ä¿¡åº¦ {result['confidence']:.3f}")

        # é˜¶æ®µ2: Agent Lightningå¼ºåŒ–å­¦ä¹ 
        print("\nâš¡ é˜¶æ®µ2: Agent Lightningå¼ºåŒ–å­¦ä¹ ")
        training_result = self.reinforcement_training_loop(val_data)
        print(f"è®­ç»ƒç»“æœ: {training_result}")

        # é˜¶æ®µ3: é›†æˆé¢„æµ‹
        print("\nğŸ¤ é˜¶æ®µ3: æ™ºèƒ½ä½“é›†æˆé¢„æµ‹")
        ensemble_result = self._ensemble_predictions(results)

        # é˜¶æ®µ4: ç”ŸæˆæŠ¥å‘Š
        print("\nğŸ“ˆ é˜¶æ®µ4: ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š")
        report = self._generate_report(results, ensemble_result, training_result)

        return report

    def _ensemble_predictions(self, predictions_list: List[Dict]) -> Dict:
        """é›†æˆå¤šä¸ªæ™ºèƒ½ä½“çš„é¢„æµ‹"""
        ensemble_predictor = EnsemblePredictor(
            methods=[self.config["ensemble_method"]],
            weights=[0.4, 0.3, 0.3]  # å¯è°ƒæ•´æƒé‡
        )

        all_predictions = [r["refined_prediction"] for r in predictions_list]
        ensemble_pred = ensemble_predictor.ensemble(all_predictions)

        return {
            "ensemble_prediction": ensemble_pred,
            "variance": np.var(all_predictions, axis=0),
            "agreement_score": self._calculate_agreement(all_predictions)
        }

    def _calculate_agreement(self, predictions: List[np.ndarray]) -> float:
        """è®¡ç®—æ™ºèƒ½ä½“é—´çš„ä¸€è‡´æ€§"""
        if len(predictions) < 2:
            return 1.0

        # è®¡ç®—ä¸¤ä¸¤ä¹‹é—´çš„ç›¸å…³ç³»æ•°
        corrs = []
        for i in range(len(predictions)):
            for j in range(i + 1, len(predictions)):
                corr = np.corrcoef(predictions[i].flatten(), predictions[j].flatten())[0, 1]
                corrs.append(corr)

        return float(np.mean(corrs))

    def _generate_report(self, results, ensemble_result, training_result) -> Dict:
        """ç”Ÿæˆå®Œæ•´æŠ¥å‘Š"""
        confidences = [r["confidence"] for r in results]

        return {
            "timestamp": pd.Timestamp.now().isoformat(),
            "total_samples": len(results),
            "average_confidence": np.mean(confidences),
            "ensemble_prediction": ensemble_result["ensemble_prediction"].tolist(),
            "agent_agreement": ensemble_result["agreement_score"],
            "reinforcement_improvement": training_result.get("improvement", 0),
            "memory_bank_size": len(self.memory_bank),
            "config": self.config
        }


# å®¢æˆ·ç«¯ä½¿ç”¨ç¤ºä¾‹
def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    import argparse

    parser = argparse.ArgumentParser(description='STAR-Forecast æ™ºèƒ½é¢„æµ‹ç³»ç»Ÿ')
    parser.add_argument('--config', type=str, default='configs/default_config.json',
                        help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--mode', type=str, default='full',
                        choices=['debate', 'reinforce', 'full'],
                        help='è¿è¡Œæ¨¡å¼')

    args = parser.parse_args()

    # 1. åˆå§‹åŒ–ç³»ç»Ÿ
    system = STARForecastSystem(config_path=args.config)

    # 2. åŠ è½½æ•°æ®
    print("ğŸ“‚ åŠ è½½æ•°æ®...")
    data_loader = TimeSeriesDataLoader(
        data_path="data/raw",
        lookback=system.config["lookback_window"],
        horizon=system.config["prediction_horizon"]
    )

    train_data, val_data, test_data = data_loader.load_split_data(
        split_ratio=[0.7, 0.2, 0.1]
    )

    # 3. æ ¹æ®æ¨¡å¼è¿è¡Œ
    if args.mode == 'debate':
        # ä»…è¿è¡Œå¤šæ™ºèƒ½ä½“è¾©è®º
        test_sample = test_data[0]
        result = system.forecast_with_debate(test_sample)
        print("è¾©è®ºé¢„æµ‹ç»“æœ:", result)

    elif args.mode == 'reinforce':
        # ä»…è¿è¡Œå¼ºåŒ–å­¦ä¹ 
        result = system.reinforcement_training_loop(val_data)
        print("å¼ºåŒ–å­¦ä¹ ç»“æœ:", result)

    else:  # full
        # è¿è¡Œå®Œæ•´ç®¡é“
        report = system.run_full_pipeline(train_data, val_data, test_data)

        # ä¿å­˜ç»“æœ
        output_dir = Path("results") / f"run_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}"
        output_dir.mkdir(parents=True, exist_ok=True)

        with open(output_dir / "forecast_report.json", 'w') as f:
            json.dump(report, f, indent=2)

        print(f"âœ… å®Œæˆï¼ç»“æœä¿å­˜è‡³: {output_dir}")
        print(f"ğŸ“Š å¹³å‡ç½®ä¿¡åº¦: {report['average_confidence']:.3f}")
        print(f"ğŸ¤ æ™ºèƒ½ä½“ä¸€è‡´æ€§: {report['agent_agreement']:.3f}")

        # å¯è§†åŒ–ç»“æœï¼ˆå¯é€‰ï¼‰
        system._visualize_results(report, output_dir)


# å¿«é€Ÿæµ‹è¯•è„šæœ¬
if __name__ == "__main__":
    # ç®€å•æµ‹è¯•å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ
    print("ğŸ§ª æµ‹è¯•å¤šæ™ºèƒ½ä½“è¾©è®ºç³»ç»Ÿ...")

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_historical = np.random.randn(96, 7)  # 96æ—¶é—´æ­¥ï¼Œ7ä¸ªç‰¹å¾

    # åˆå§‹åŒ–ç®€åŒ–ç‰ˆç³»ç»Ÿ
    from agents.autogen_system import AutoGenDebateSystem
    from agents.memory_bank import MemoryBank

    memory = MemoryBank()
    debate_system = AutoGenDebateSystem(
        agent_count=2,
        debate_rounds=1,
        memory_bank=memory
    )

    # è¿è¡Œä¸€æ¬¡è¾©è®º
    context = {
        "data_description": "æµ‹è¯•æ—¶é—´åºåˆ—æ•°æ®",
        "current_prediction": [1.2, 1.3, 1.4]
    }

    result = debate_system.start_debate(
        topic="æµ‹è¯•é¢„æµ‹è¾©è®º",
        context=context,
        question="è¿™ä¸ªé¢„æµ‹åˆç†å—ï¼Ÿ"
    )

    print(f"è¾©è®ºå®Œæˆï¼å…±è¯†: {result.consensus}")
    print(f"å»ºè®®: {result.recommendations}")

    # å¦‚æœéœ€è¦è¿è¡Œå®Œæ•´ç³»ç»Ÿ
    # main()