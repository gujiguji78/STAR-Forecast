"""
å®éªŒç®¡ç†å™¨ - ç»Ÿä¸€çš„å®éªŒè·Ÿè¸ªã€ç®¡ç†å’Œåˆ†æç³»ç»Ÿ
æ”¯æŒå®éªŒé…ç½®ã€ç‰ˆæœ¬æ§åˆ¶ã€ç»“æœæ¯”è¾ƒå’ŒçŸ¥è¯†åº“æ„å»º
"""
import json
import yaml
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, field, asdict
from datetime import datetime
from pathlib import Path
import logging
import hashlib
import pickle
import shutil
from enum import Enum
import uuid
import sqlite3
from contextlib import contextmanager
import itertools
import warnings

warnings.filterwarnings('ignore')

# å¯¼å…¥é¡¹ç›®æ¨¡å—
import sys

sys.path.append('..')
from training.trainer import STARForecastTrainer
from experiments.ablation_study import AblationStudyManager, AblationComparison
from experiments.baseline_comparison import BaselineComparison, BaselineModel


class ExperimentStatus(Enum):
    """å®éªŒçŠ¶æ€"""
    CREATED = "created"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


class ExperimentType(Enum):
    """å®éªŒç±»å‹"""
    FULL_TRAINING = "full_training"  # å®Œæ•´è®­ç»ƒ
    ABLATION_STUDY = "ablation_study"  # æ¶ˆèå®éªŒ
    BASELINE_COMPARISON = "baseline_comparison"  # åŸºçº¿æ¯”è¾ƒ
    HYPERPARAMETER_TUNING = "hyperparameter_tuning"  # è¶…å‚æ•°è°ƒä¼˜
    TRANSFER_LEARNING = "transfer_learning"  # è¿ç§»å­¦ä¹ 
    ROBUSTNESS_TEST = "robustness_test"  # é²æ£’æ€§æµ‹è¯•


@dataclass
class ExperimentMetadata:
    """å®éªŒå…ƒæ•°æ®"""
    experiment_id: str
    name: str
    description: str
    experiment_type: ExperimentType
    status: ExperimentStatus
    config: Dict[str, Any]
    created_by: str = "system"
    created_at: datetime = field(default_factory=datetime.now)
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    duration_seconds: Optional[float] = None
    git_commit: Optional[str] = None
    tags: List[str] = field(default_factory=list)
    parent_experiment: Optional[str] = None  # çˆ¶å®éªŒID
    dependencies: List[str] = field(default_factory=list)  # ä¾èµ–çš„å®éªŒ

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'experiment_id': self.experiment_id,
            'name': self.name,
            'description': self.description,
            'experiment_type': self.experiment_type.value,
            'status': self.status.value,
            'config': self.config,
            'created_by': self.created_by,
            'created_at': self.created_at.isoformat(),
            'started_at': self.started_at.isoformat() if self.started_at else None,
            'completed_at': self.completed_at.isoformat() if self.completed_at else None,
            'duration_seconds': self.duration_seconds,
            'git_commit': self.git_commit,
            'tags': self.tags,
            'parent_experiment': self.parent_experiment,
            'dependencies': self.dependencies
        }


@dataclass
class ExperimentResult:
    """å®éªŒç»“æœ"""
    experiment_id: str
    metrics: Dict[str, Any]
    artifacts: Dict[str, str]  # è·¯å¾„ -> æè¿°
    logs: Dict[str, Any]
    models: Dict[str, str]  # æ¨¡å‹åç§° -> æ¨¡å‹è·¯å¾„
    visualizations: List[str]  # å¯è§†åŒ–æ–‡ä»¶è·¯å¾„
    created_at: datetime = field(default_factory=datetime.now)

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'experiment_id': self.experiment_id,
            'metrics': self.metrics,
            'artifacts': self.artifacts,
            'logs': self.logs,
            'models': self.models,
            'visualizations': self.visualizations,
            'created_at': self.created_at.isoformat()
        }


@dataclass
class ExperimentComparison:
    """å®éªŒå¯¹æ¯”"""
    comparison_id: str
    experiment_ids: List[str]
    comparison_metrics: Dict[str, Dict[str, Any]]  # metric -> experiment_id -> value
    ranking: Dict[str, List[str]]  # metric -> æ’åºåçš„experiment_idåˆ—è¡¨
    insights: List[str]
    created_at: datetime = field(default_factory=datetime.now)

    def to_dataframe(self) -> pd.DataFrame:
        """è½¬æ¢ä¸ºDataFrame"""
        rows = []

        for metric, experiment_values in self.comparison_metrics.items():
            for exp_id, value in experiment_values.items():
                rows.append({
                    'experiment_id': exp_id,
                    'metric': metric,
                    'value': value
                })

        return pd.DataFrame(rows)


class KnowledgeBaseEntry:
    """çŸ¥è¯†åº“æ¡ç›®"""

    def __init__(self,
                 knowledge_id: str,
                 title: str,
                 content: str,
                 experiment_ids: List[str],
                 evidence: Dict[str, Any],
                 confidence: float = 0.5,
                 tags: List[str] = None):
        self.knowledge_id = knowledge_id
        self.title = title
        self.content = content
        self.experiment_ids = experiment_ids
        self.evidence = evidence
        self.confidence = confidence
        self.tags = tags or []
        self.created_at = datetime.now()
        self.updated_at = datetime.now()
        self.citation_count = 0

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'knowledge_id': self.knowledge_id,
            'title': self.title,
            'content': self.content,
            'experiment_ids': self.experiment_ids,
            'evidence': self.evidence,
            'confidence': self.confidence,
            'tags': self.tags,
            'created_at': self.created_at.isoformat(),
            'updated_at': self.updated_at.isoformat(),
            'citation_count': self.citation_count
        }


class ExperimentDatabase:
    """å®éªŒæ•°æ®åº“ï¼ˆSQLiteï¼‰"""

    def __init__(self, db_path: str = "./experiments/experiments.db"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(exist_ok=True)
        self._init_database()

    @contextmanager
    def _get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        try:
            yield conn
        finally:
            conn.close()

    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        with self._get_connection() as conn:
            # å®éªŒå…ƒæ•°æ®è¡¨
            conn.execute("""
                         CREATE TABLE IF NOT EXISTS experiments
                         (
                             experiment_id
                             TEXT
                             PRIMARY
                             KEY,
                             name
                             TEXT
                             NOT
                             NULL,
                             description
                             TEXT,
                             experiment_type
                             TEXT
                             NOT
                             NULL,
                             status
                             TEXT
                             NOT
                             NULL,
                             config
                             TEXT
                             NOT
                             NULL,
                             created_by
                             TEXT
                             DEFAULT
                             'system',
                             created_at
                             DATETIME
                             NOT
                             NULL,
                             started_at
                             DATETIME,
                             completed_at
                             DATETIME,
                             duration_seconds
                             REAL,
                             git_commit
                             TEXT,
                             tags
                             TEXT,
                             parent_experiment
                             TEXT,
                             dependencies
                             TEXT
                         )
                         """)

            # å®éªŒç»“æœè¡¨
            conn.execute("""
                         CREATE TABLE IF NOT EXISTS experiment_results
                         (
                             result_id
                             TEXT
                             PRIMARY
                             KEY,
                             experiment_id
                             TEXT
                             NOT
                             NULL,
                             metrics
                             TEXT
                             NOT
                             NULL,
                             artifacts
                             TEXT
                             NOT
                             NULL,
                             logs
                             TEXT
                             NOT
                             NULL,
                             models
                             TEXT
                             NOT
                             NULL,
                             visualizations
                             TEXT
                             NOT
                             NULL,
                             created_at
                             DATETIME
                             NOT
                             NULL,
                             FOREIGN
                             KEY
                         (
                             experiment_id
                         ) REFERENCES experiments
                         (
                             experiment_id
                         )
                             )
                         """)

            # çŸ¥è¯†åº“è¡¨
            conn.execute("""
                         CREATE TABLE IF NOT EXISTS knowledge_base
                         (
                             knowledge_id
                             TEXT
                             PRIMARY
                             KEY,
                             title
                             TEXT
                             NOT
                             NULL,
                             content
                             TEXT
                             NOT
                             NULL,
                             experiment_ids
                             TEXT
                             NOT
                             NULL,
                             evidence
                             TEXT
                             NOT
                             NULL,
                             confidence
                             REAL
                             DEFAULT
                             0.5,
                             tags
                             TEXT,
                             created_at
                             DATETIME
                             NOT
                             NULL,
                             updated_at
                             DATETIME
                             NOT
                             NULL,
                             citation_count
                             INTEGER
                             DEFAULT
                             0
                         )
                         """)

            # åˆ›å»ºç´¢å¼•
            conn.execute("CREATE INDEX IF NOT EXISTS idx_exp_type ON experiments (experiment_type)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_exp_status ON experiments (status)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_exp_created ON experiments (created_at)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_knowledge_tags ON knowledge_base (tags)")

            conn.commit()

    def save_experiment(self, metadata: ExperimentMetadata):
        """ä¿å­˜å®éªŒå…ƒæ•°æ®"""
        with self._get_connection() as conn:
            conn.execute("""
                INSERT OR REPLACE INTO experiments 
                (experiment_id, name, description, experiment_type, status, 
                 config, created_by, created_at, started_at, completed_at,
                 duration_seconds, git_commit, tags, parent_experiment, dependencies)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                metadata.experiment_id,
                metadata.name,
                metadata.description,
                metadata.experiment_type.value,
                metadata.status.value,
                json.dumps(metadata.config, ensure_ascii=False),
                metadata.created_by,
                metadata.created_at.isoformat(),
                metadata.started_at.isoformat() if metadata.started_at else None,
                metadata.completed_at.isoformat() if metadata.completed_at else None,
                metadata.duration_seconds,
                metadata.git_commit,
                json.dumps(metadata.tags, ensure_ascii=False),
                metadata.parent_experiment,
                json.dumps(metadata.dependencies, ensure_ascii=False)
            ))

            conn.commit()

    def save_experiment_result(self, result: ExperimentResult):
        """ä¿å­˜å®éªŒç»“æœ"""
        result_id = hashlib.md5(
            f"{result.experiment_id}{datetime.now().isoformat()}".encode()
        ).hexdigest()[:16]

        with self._get_connection() as conn:
            conn.execute("""
                         INSERT INTO experiment_results
                         (result_id, experiment_id, metrics, artifacts, logs, models, visualizations, created_at)
                         VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                         """, (
                             result_id,
                             result.experiment_id,
                             json.dumps(result.metrics, ensure_ascii=False),
                             json.dumps(result.artifacts, ensure_ascii=False),
                             json.dumps(result.logs, ensure_ascii=False),
                             json.dumps(result.models, ensure_ascii=False),
                             json.dumps(result.visualizations, ensure_ascii=False),
                             result.created_at.isoformat()
                         ))

            conn.commit()

    def save_knowledge(self, knowledge: KnowledgeBaseEntry):
        """ä¿å­˜çŸ¥è¯†åº“æ¡ç›®"""
        with self._get_connection() as conn:
            conn.execute("""
                INSERT OR REPLACE INTO knowledge_base 
                (knowledge_id, title, content, experiment_ids, evidence, 
                 confidence, tags, created_at, updated_at, citation_count)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                knowledge.knowledge_id,
                knowledge.title,
                knowledge.content,
                json.dumps(knowledge.experiment_ids, ensure_ascii=False),
                json.dumps(knowledge.evidence, ensure_ascii=False),
                knowledge.confidence,
                json.dumps(knowledge.tags, ensure_ascii=False),
                knowledge.created_at.isoformat(),
                knowledge.updated_at.isoformat(),
                knowledge.citation_count
            ))

            conn.commit()

    def get_experiment(self, experiment_id: str) -> Optional[ExperimentMetadata]:
        """è·å–å®éªŒ"""
        with self._get_connection() as conn:
            cursor = conn.execute(
                "SELECT * FROM experiments WHERE experiment_id = ?",
                (experiment_id,)
            )
            row = cursor.fetchone()

            if row is None:
                return None

            # è§£ææ•°æ®
            metadata = ExperimentMetadata(
                experiment_id=row['experiment_id'],
                name=row['name'],
                description=row['description'],
                experiment_type=ExperimentType(row['experiment_type']),
                status=ExperimentStatus(row['status']),
                config=json.loads(row['config']),
                created_by=row['created_by'],
                created_at=datetime.fromisoformat(row['created_at']),
                started_at=datetime.fromisoformat(row['started_at']) if row['started_at'] else None,
                completed_at=datetime.fromisoformat(row['completed_at']) if row['completed_at'] else None,
                duration_seconds=row['duration_seconds'],
                git_commit=row['git_commit'],
                tags=json.loads(row['tags']) if row['tags'] else [],
                parent_experiment=row['parent_experiment'],
                dependencies=json.loads(row['dependencies']) if row['dependencies'] else []
            )

            return metadata

    def get_experiment_result(self, experiment_id: str) -> Optional[ExperimentResult]:
        """è·å–å®éªŒç»“æœ"""
        with self._get_connection() as conn:
            cursor = conn.execute(
                "SELECT * FROM experiment_results WHERE experiment_id = ? ORDER BY created_at DESC LIMIT 1",
                (experiment_id,)
            )
            row = cursor.fetchone()

            if row is None:
                return None

            # è§£ææ•°æ®
            result = ExperimentResult(
                experiment_id=row['experiment_id'],
                metrics=json.loads(row['metrics']),
                artifacts=json.loads(row['artifacts']),
                logs=json.loads(row['logs']),
                models=json.loads(row['models']),
                visualizations=json.loads(row['visualizations']),
                created_at=datetime.fromisoformat(row['created_at'])
            )

            return result

    def search_experiments(self,
                           experiment_type: Optional[ExperimentType] = None,
                           status: Optional[ExperimentStatus] = None,
                           tags: Optional[List[str]] = None,
                           start_date: Optional[datetime] = None,
                           end_date: Optional[datetime] = None,
                           limit: int = 100) -> List[ExperimentMetadata]:
        """æœç´¢å®éªŒ"""
        conditions = []
        params = []

        if experiment_type:
            conditions.append("experiment_type = ?")
            params.append(experiment_type.value)

        if status:
            conditions.append("status = ?")
            params.append(status.value)

        if start_date:
            conditions.append("created_at >= ?")
            params.append(start_date.isoformat())

        if end_date:
            conditions.append("created_at <= ?")
            params.append(end_date.isoformat())

        if tags:
            # ç®€å•çš„æ ‡ç­¾æœç´¢ï¼ˆå®é™…åº”ä½¿ç”¨å…¨æ–‡æœç´¢ï¼‰
            tag_conditions = []
            for tag in tags:
                tag_conditions.append("tags LIKE ?")
                params.append(f'%{tag}%')

            if tag_conditions:
                conditions.append(f"({' OR '.join(tag_conditions)})")

        where_clause = " AND ".join(conditions) if conditions else "1=1"
        sql = f"""
            SELECT * FROM experiments 
            WHERE {where_clause}
            ORDER BY created_at DESC
            LIMIT ?
        """
        params.append(limit)

        with self._get_connection() as conn:
            cursor = conn.execute(sql, params)
            rows = cursor.fetchall()

            experiments = []
            for row in rows:
                metadata = ExperimentMetadata(
                    experiment_id=row['experiment_id'],
                    name=row['name'],
                    description=row['description'],
                    experiment_type=ExperimentType(row['experiment_type']),
                    status=ExperimentStatus(row['status']),
                    config=json.loads(row['config']),
                    created_by=row['created_by'],
                    created_at=datetime.fromisoformat(row['created_at']),
                    started_at=datetime.fromisoformat(row['started_at']) if row['started_at'] else None,
                    completed_at=datetime.fromisoformat(row['completed_at']) if row['completed_at'] else None,
                    duration_seconds=row['duration_seconds'],
                    git_commit=row['git_commit'],
                    tags=json.loads(row['tags']) if row['tags'] else [],
                    parent_experiment=row['parent_experiment'],
                    dependencies=json.loads(row['dependencies']) if row['dependencies'] else []
                )
                experiments.append(metadata)

            return experiments

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        with self._get_connection() as conn:
            stats = {}

            # å®éªŒç»Ÿè®¡
            cursor = conn.execute("SELECT COUNT(*) as total FROM experiments")
            stats['total_experiments'] = cursor.fetchone()['total']

            cursor = conn.execute("SELECT experiment_type, COUNT(*) as count FROM experiments GROUP BY experiment_type")
            stats['by_type'] = {row['experiment_type']: row['count'] for row in cursor.fetchall()}

            cursor = conn.execute("SELECT status, COUNT(*) as count FROM experiments GROUP BY status")
            stats['by_status'] = {row['status']: row['count'] for row in cursor.fetchall()}

            # çŸ¥è¯†åº“ç»Ÿè®¡
            cursor = conn.execute("SELECT COUNT(*) as total FROM knowledge_base")
            stats['total_knowledge'] = cursor.fetchone()['total']

            return stats


class ExperimentManager:
    """
    å®éªŒç®¡ç†å™¨

    åŠŸèƒ½ï¼š
    1. ç»Ÿä¸€çš„å®éªŒç”Ÿå‘½å‘¨æœŸç®¡ç†
    2. å®éªŒç‰ˆæœ¬æ§åˆ¶å’Œå¤ç°
    3. å®éªŒç»“æœè·Ÿè¸ªå’Œåˆ†æ
    4. çŸ¥è¯†åº“æ„å»ºå’Œæ£€ç´¢
    5. å®éªŒå¯¹æ¯”å’Œæ´å¯Ÿç”Ÿæˆ
    """

    def __init__(self,
                 base_config_path: str = "./config.yaml",
                 experiments_root: str = "./experiments"):

        self.base_config_path = Path(base_config_path)
        self.experiments_root = Path(experiments_root)

        # åˆ›å»ºç›®å½•ç»“æ„
        self.experiments_root.mkdir(parents=True, exist_ok=True)
        (self.experiments_root / "configs").mkdir(exist_ok=True)
        (self.experiments_root / "results").mkdir(exist_ok=True)
        (self.experiments_root / "models").mkdir(exist_ok=True)
        (self.experiments_root / "logs").mkdir(exist_ok=True)
        (self.experiments_root / "visualizations").mkdir(exist_ok=True)
        (self.experiments_root / "reports").mkdir(exist_ok=True)

        # åˆå§‹åŒ–ç»„ä»¶
        self.db = ExperimentDatabase(self.experiments_root / "experiments.db")
        self.logger = logging.getLogger(__name__)

        # å®éªŒæ³¨å†Œè¡¨
        self.active_experiments: Dict[str, Any] = {}

        # åŠ è½½åŸºç¡€é…ç½®
        self.base_config = self._load_config(base_config_path)

        self.logger.info("ğŸ§ª å®éªŒç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®"""
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        return config

    def _get_git_commit(self) -> Optional[str]:
        """è·å–å½“å‰Gitæäº¤"""
        try:
            import subprocess
            result = subprocess.run(
                ['git', 'rev-parse', 'HEAD'],
                capture_output=True,
                text=True,
                cwd=Path.cwd()
            )
            if result.returncode == 0:
                return result.stdout.strip()[:8]
        except:
            pass
        return None

    def create_experiment(self,
                          name: str,
                          description: str,
                          experiment_type: ExperimentType,
                          config: Dict[str, Any] = None,
                          tags: List[str] = None,
                          parent_experiment: str = None,
                          dependencies: List[str] = None) -> ExperimentMetadata:
        """åˆ›å»ºæ–°å®éªŒ"""
        # ç”Ÿæˆå®éªŒID
        experiment_id = f"{experiment_type.value}_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}"

        # åˆå¹¶é…ç½®
        if config is None:
            config = self.base_config.copy()
        else:
            # æ·±æ‹·è´åŸºç¡€é…ç½®å¹¶æ›´æ–°
            import copy
            merged_config = copy.deepcopy(self.base_config)

            def update_dict(d, u):
                for k, v in u.items():
                    if isinstance(v, dict):
                        d[k] = update_dict(d.get(k, {}), v)
                    else:
                        d[k] = v
                return d

            config = update_dict(merged_config, config)

        # åˆ›å»ºå®éªŒå…ƒæ•°æ®
        metadata = ExperimentMetadata(
            experiment_id=experiment_id,
            name=name,
            description=description,
            experiment_type=experiment_type,
            status=ExperimentStatus.CREATED,
            config=config,
            tags=tags or [],
            parent_experiment=parent_experiment,
            dependencies=dependencies or [],
            git_commit=self._get_git_commit()
        )

        # ä¿å­˜åˆ°æ•°æ®åº“
        self.db.save_experiment(metadata)

        # ä¿å­˜é…ç½®æ–‡ä»¶
        config_path = self.experiments_root / "configs" / f"{experiment_id}.yaml"
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)

        self.logger.info(f"ğŸ“ åˆ›å»ºå®éªŒ: {experiment_id}")
        self.logger.info(f"   åç§°: {name}")
        self.logger.info(f"   ç±»å‹: {experiment_type.value}")

        return metadata

    def run_full_training(self,
                          experiment_id: str,
                          data_path: str = "./data/ETTh1.csv",
                          save_model: bool = True) -> ExperimentResult:
        """è¿è¡Œå®Œæ•´è®­ç»ƒå®éªŒ"""
        # è·å–å®éªŒå…ƒæ•°æ®
        metadata = self.db.get_experiment(experiment_id)
        if not metadata:
            raise ValueError(f"å®éªŒä¸å­˜åœ¨: {experiment_id}")

        # æ›´æ–°çŠ¶æ€ä¸ºè¿è¡Œä¸­
        metadata.status = ExperimentStatus.RUNNING
        metadata.started_at = datetime.now()
        self.db.save_experiment(metadata)

        self.logger.info(f"ğŸš€ å¼€å§‹è¿è¡Œå®éªŒ: {experiment_id}")

        try:
            # åˆ›å»ºè®­ç»ƒå™¨
            trainer = STARForecastTrainer(metadata.config)
            trainer.build_models()
            trainer.build_optimizer()
            trainer.initialize_agents()

            # è®­ç»ƒæ¨¡å‹
            test_metrics = trainer.train(data_path)

            # æ›´æ–°å®éªŒçŠ¶æ€
            metadata.status = ExperimentStatus.COMPLETED
            metadata.completed_at = datetime.now()
            metadata.duration_seconds = (metadata.completed_at - metadata.started_at).total_seconds()
            self.db.save_experiment(metadata)

            # ä¿å­˜æ¨¡å‹
            models = {}
            if save_model:
                model_path = self.experiments_root / "models" / f"{experiment_id}_model.pth"
                trainer._save_checkpoint(trainer.current_epoch, is_best=True)
                models['best_model'] = str(model_path)

            # æ”¶é›†æ—¥å¿—å’Œå¯è§†åŒ–
            logs = {
                'training_history': getattr(trainer, 'training_history', {}),
                'agent_decisions': getattr(trainer.agent_client, 'stats', {}) if hasattr(trainer,
                                                                                         'agent_client') else {},
                'autogen_conversations': len(getattr(trainer.autogen_system, 'conversation_history', {}))
                if hasattr(trainer, 'autogen_system') else 0
            }

            # ç”Ÿæˆå¯è§†åŒ–
            visualizations = self._generate_training_visualizations(trainer, experiment_id)

            # ä¿å­˜ç»“æœ
            result = ExperimentResult(
                experiment_id=experiment_id,
                metrics=test_metrics,
                artifacts={
                    'config': str(self.experiments_root / "configs" / f"{experiment_id}.yaml"),
                    'logs': str(self.experiments_root / "logs" / f"{experiment_id}.log")
                },
                logs=logs,
                models=models,
                visualizations=visualizations
            )

            self.db.save_experiment_result(result)

            # ç”ŸæˆæŠ¥å‘Š
            self._generate_experiment_report(metadata, result)

            # æå–çŸ¥è¯†
            self._extract_knowledge_from_experiment(metadata, result)

            self.logger.info(f"âœ… å®éªŒå®Œæˆ: {experiment_id}")
            self.logger.info(f"   ç»“æœ: {test_metrics}")

            return result

        except Exception as e:
            # æ›´æ–°ä¸ºå¤±è´¥çŠ¶æ€
            metadata.status = ExperimentStatus.FAILED
            metadata.completed_at = datetime.now()
            self.db.save_experiment(metadata)

            self.logger.error(f"âŒ å®éªŒå¤±è´¥: {experiment_id}")
            self.logger.error(f"   é”™è¯¯: {e}")

            import traceback
            traceback.print_exc()

            raise

    def run_ablation_study(self,
                           experiment_id: str,
                           variants: List[str] = None,
                           data_path: str = "./data/ETTh1.csv") -> ExperimentResult:
        """è¿è¡Œæ¶ˆèå®éªŒ"""
        # è·å–å®éªŒå…ƒæ•°æ®
        metadata = self.db.get_experiment(experiment_id)
        if not metadata:
            raise ValueError(f"å®éªŒä¸å­˜åœ¨: {experiment_id}")

        # æ›´æ–°çŠ¶æ€
        metadata.status = ExperimentStatus.RUNNING
        metadata.started_at = datetime.now()
        self.db.save_experiment(metadata)

        self.logger.info(f"ğŸ”¬ å¼€å§‹æ¶ˆèå®éªŒ: {experiment_id}")

        try:
            # åˆ›å»ºæ¶ˆèå®éªŒç®¡ç†å™¨
            ablation_manager = AblationStudyManager(self.base_config_path)

            # è½¬æ¢å˜ä½“å‚æ•°
            from experiments.ablation_study import AblationVariant
            ablation_variants = None
            if variants:
                ablation_variants = [AblationVariant(v) for v in variants]

            # è¿è¡Œæ¶ˆèå®éªŒ
            comparison = ablation_manager.run_ablation_experiment(
                variants=ablation_variants,
                data_path=data_path,
                experiment_name=experiment_id
            )

            # æ›´æ–°å®éªŒçŠ¶æ€
            metadata.status = ExperimentStatus.COMPLETED
            metadata.completed_at = datetime.now()
            metadata.duration_seconds = (metadata.completed_at - metadata.started_at).total_seconds()
            self.db.save_experiment(metadata)

            # å‡†å¤‡ç»“æœ
            metrics = {
                'ablation_summary': comparison.summary_stats,
                'statistical_tests': comparison.statistical_tests
            }

            # æ”¶é›†å¯è§†åŒ–
            vis_dir = Path("./experiments/ablation_results/visualizations")
            visualizations = []
            if vis_dir.exists():
                for vis_file in vis_dir.glob(f"{experiment_id}*.png"):
                    visualizations.append(str(vis_file))

            # ä¿å­˜ç»“æœ
            result = ExperimentResult(
                experiment_id=experiment_id,
                metrics=metrics,
                artifacts={
                    'comparison_json': str(Path("./experiments/ablation_results") / f"{experiment_id}.json"),
                    'comparison_csv': str(Path("./experiments/ablation_results") / f"{experiment_id}.csv"),
                    'comparison_pickle': str(Path("./experiments/ablation_results") / f"{experiment_id}.pkl")
                },
                logs={'ablation_comparison': comparison.to_dict()},
                models={},
                visualizations=visualizations
            )

            self.db.save_experiment_result(result)

            # æå–çŸ¥è¯†
            self._extract_knowledge_from_ablation(comparison, experiment_id)

            self.logger.info(f"âœ… æ¶ˆèå®éªŒå®Œæˆ: {experiment_id}")

            return result

        except Exception as e:
            metadata.status = ExperimentStatus.FAILED
            metadata.completed_at = datetime.now()
            self.db.save_experiment(metadata)

            self.logger.error(f"âŒ æ¶ˆèå®éªŒå¤±è´¥: {experiment_id}")
            self.logger.error(f"   é”™è¯¯: {e}")

            raise

    def run_baseline_comparison(self,
                                experiment_id: str,
                                baselines: List[str] = None,
                                data_path: str = "./data/ETTh1.csv") -> ExperimentResult:
        """è¿è¡ŒåŸºçº¿æ¯”è¾ƒå®éªŒ"""
        # è·å–å®éªŒå…ƒæ•°æ®
        metadata = self.db.get_experiment(experiment_id)
        if not metadata:
            raise ValueError(f"å®éªŒä¸å­˜åœ¨: {experiment_id}")

        # æ›´æ–°çŠ¶æ€
        metadata.status = ExperimentStatus.RUNNING
        metadata.started_at = datetime.now()
        self.db.save_experiment(metadata)

        self.logger.info(f"ğŸ“Š å¼€å§‹åŸºçº¿æ¯”è¾ƒ: {experiment_id}")

        try:
            # åˆ›å»ºåŸºçº¿æ¯”è¾ƒç®¡ç†å™¨
            from experiments.baseline_comparison import BaselineComparisonManager
            baseline_manager = BaselineComparisonManager(self.base_config_path)

            # è¿è¡ŒåŸºçº¿æ¯”è¾ƒ
            comparison = baseline_manager.run_baseline_comparison(
                baselines=baselines,
                data_path=data_path,
                experiment_name=experiment_id
            )

            # æ›´æ–°å®éªŒçŠ¶æ€
            metadata.status = ExperimentStatus.COMPLETED
            metadata.completed_at = datetime.now()
            metadata.duration_seconds = (metadata.completed_at - metadata.started_at).total_seconds()
            self.db.save_experiment(metadata)

            # å‡†å¤‡ç»“æœ
            metrics = {
                'baseline_performance': comparison.performance_metrics,
                'statistical_comparison': comparison.statistical_comparison
            }

            # æ”¶é›†å¯è§†åŒ–
            vis_dir = Path("./experiments/baseline_results/visualizations")
            visualizations = []
            if vis_dir.exists():
                for vis_file in vis_dir.glob(f"{experiment_id}*.png"):
                    visualizations.append(str(vis_file))

            # ä¿å­˜ç»“æœ
            result = ExperimentResult(
                experiment_id=experiment_id,
                metrics=metrics,
                artifacts={
                    'comparison_json': str(Path("./experiments/baseline_results") / f"{experiment_id}.json"),
                    'comparison_csv': str(Path("./experiments/baseline_results") / f"{experiment_id}.csv")
                },
                logs={'baseline_comparison': comparison.to_dict()},
                models={},
                visualizations=visualizations
            )

            self.db.save_experiment_result(result)

            self.logger.info(f"âœ… åŸºçº¿æ¯”è¾ƒå®Œæˆ: {experiment_id}")

            return result

        except Exception as e:
            metadata.status = ExperimentStatus.FAILED
            metadata.completed_at = datetime.now()
            self.db.save_experiment(metadata)

            self.logger.error(f"âŒ åŸºçº¿æ¯”è¾ƒå¤±è´¥: {experiment_id}")
            self.logger.error(f"   é”™è¯¯: {e}")

            raise

    def _generate_training_visualizations(self, trainer, experiment_id: str) -> List[str]:
        """ç”Ÿæˆè®­ç»ƒå¯è§†åŒ–"""
        try:
            import matplotlib.pyplot as plt
            import seaborn as sns

            vis_dir = self.experiments_root / "visualizations" / experiment_id
            vis_dir.mkdir(parents=True, exist_ok=True)

            visualizations = []

            # 1. è®­ç»ƒæŸå¤±æ›²çº¿
            if hasattr(trainer, 'training_history') and trainer.training_history:
                fig, axes = plt.subplots(2, 2, figsize=(12, 10))

                # è®­ç»ƒæŸå¤±
                if 'train_loss' in trainer.training_history:
                    ax = axes[0, 0]
                    ax.plot(trainer.training_history['train_loss'], label='Train Loss')
                    if 'val_loss' in trainer.training_history:
                        ax.plot(trainer.training_history['val_loss'], label='Val Loss')
                    ax.set_title('Training and Validation Loss')
                    ax.set_xlabel('Epoch')
                    ax.set_ylabel('Loss')
                    ax.legend()
                    ax.grid(True, alpha=0.3)

                # è®­ç»ƒå¥–åŠ±ï¼ˆå¦‚æœæœ‰ï¼‰
                if 'train_reward' in trainer.training_history:
                    ax = axes[0, 1]
                    ax.plot(trainer.training_history['train_reward'])
                    ax.set_title('Training Reward')
                    ax.set_xlabel('Epoch')
                    ax.set_ylabel('Reward')
                    ax.grid(True, alpha=0.3)

                # éªŒè¯æŒ‡æ ‡
                if 'val_mse' in trainer.training_history:
                    ax = axes[1, 0]
                    ax.plot(trainer.training_history['val_mse'], label='MSE')
                    if 'val_mae' in trainer.training_history:
                        ax.plot(trainer.training_history['val_mae'], label='MAE')
                    ax.set_title('Validation Metrics')
                    ax.set_xlabel('Epoch')
                    ax.set_ylabel('Metric Value')
                    ax.legend()
                    ax.grid(True, alpha=0.3)

                # å­¦ä¹ ç‡
                if hasattr(trainer, 'scheduler') and trainer.scheduler:
                    ax = axes[1, 1]
                    lr_history = []
                    for epoch in range(trainer.current_epoch):
                        lr_history.append(trainer.optimizer.param_groups[0]['lr'])
                        trainer.scheduler.step()

                    ax.plot(lr_history)
                    ax.set_title('Learning Rate Schedule')
                    ax.set_xlabel('Epoch')
                    ax.set_ylabel('Learning Rate')
                    ax.grid(True, alpha=0.3)

                plt.tight_layout()
                vis_path = vis_dir / "training_history.png"
                plt.savefig(vis_path, dpi=300, bbox_inches='tight')
                plt.close()
                visualizations.append(str(vis_path))

            return visualizations

        except Exception as e:
            self.logger.warning(f"å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
            return []

    def _generate_experiment_report(self,
                                    metadata: ExperimentMetadata,
                                    result: ExperimentResult):
        """ç”Ÿæˆå®éªŒæŠ¥å‘Š"""
        try:
            report_dir = self.experiments_root / "reports" / metadata.experiment_id
            report_dir.mkdir(parents=True, exist_ok=True)

            # ç”ŸæˆMarkdownæŠ¥å‘Š
            report_path = report_dir / "report.md"

            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(f"# å®éªŒæŠ¥å‘Š: {metadata.name}\n\n")
                f.write(f"**å®éªŒID**: {metadata.experiment_id}\n\n")
                f.write(f"**åˆ›å»ºæ—¶é—´**: {metadata.created_at}\n\n")
                f.write(f"**å®Œæˆæ—¶é—´**: {metadata.completed_at}\n\n")
                f.write(f"**æŒç»­æ—¶é—´**: {metadata.duration_seconds:.1f} ç§’\n\n")
                f.write(f"**å®éªŒç±»å‹**: {metadata.experiment_type.value}\n\n")
                f.write(f"**æè¿°**: {metadata.description}\n\n")

                # æ ‡ç­¾
                if metadata.tags:
                    f.write(f"**æ ‡ç­¾**: {', '.join(metadata.tags)}\n\n")

                # å®éªŒç»“æœ
                f.write("## å®éªŒç»“æœ\n\n")

                for metric_name, metric_value in result.metrics.items():
                    if isinstance(metric_value, dict):
                        f.write(f"### {metric_name}\n\n")
                        for k, v in metric_value.items():
                            if isinstance(v, (int, float)):
                                f.write(f"- {k}: {v:.6f}\n")
                            else:
                                f.write(f"- {k}: {v}\n")
                        f.write("\n")
                    elif isinstance(metric_value, (int, float)):
                        f.write(f"- **{metric_name}**: {metric_value:.6f}\n")
                    else:
                        f.write(f"- **{metric_name}**: {metric_value}\n")

                # é…ç½®æ‘˜è¦
                f.write("\n## é…ç½®æ‘˜è¦\n\n")

                # æå–å…³é”®é…ç½®
                key_configs = [
                    ('data', ['seq_len', 'pred_len']),
                    ('training', ['epochs', 'learning_rate', 'batch_size']),
                    ('istr', ['hidden_dim', 'trainable_ratio']),
                    ('autogen', ['check_interval', 'max_rounds']),
                    ('agent_lightning', ['lr', 'gamma'])
                ]

                for section, keys in key_configs:
                    if section in metadata.config:
                        f.write(f"### {section}\n\n")
                        for key in keys:
                            if key in metadata.config[section]:
                                value = metadata.config[section][key]
                                f.write(f"- {key}: {value}\n")
                        f.write("\n")

                # å¯è§†åŒ–é“¾æ¥
                if result.visualizations:
                    f.write("## å¯è§†åŒ–\n\n")
                    for vis_path in result.visualizations:
                        vis_name = Path(vis_path).name
                        f.write(f"![{vis_name}]({vis_path})\n\n")

                # æ€»ç»“
                f.write("## æ€»ç»“\n\n")
                f.write("å®éªŒå·²æˆåŠŸå®Œæˆã€‚\n\n")

            # ç”ŸæˆHTMLæŠ¥å‘Š
            self._generate_html_report(report_path)

            self.logger.info(f"ğŸ“„ å®éªŒæŠ¥å‘Šä¿å­˜åˆ°: {report_path}")

        except Exception as e:
            self.logger.warning(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")

    def _generate_html_report(self, markdown_path: Path):
        """ç”ŸæˆHTMLæŠ¥å‘Š"""
        try:
            import markdown

            with open(markdown_path, 'r', encoding='utf-8') as f:
                md_content = f.read()

            html_content = markdown.markdown(md_content, extensions=['tables', 'fenced_code'])

            # æ·»åŠ HTMLæ¨¡æ¿
            html_template = f"""
            <!DOCTYPE html>
            <html>
            <head>
                <meta charset="utf-8">
                <title>å®éªŒæŠ¥å‘Š</title>
                <style>
                    body {{ font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }}
                    h1, h2, h3 {{ color: #333; }}
                    code {{ background: #f4f4f4; padding: 2px 6px; }}
                    pre {{ background: #f4f4f4; padding: 10px; overflow: auto; }}
                    img {{ max-width: 100%; height: auto; }}
                    table {{ border-collapse: collapse; width: 100%; }}
                    th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                    th {{ background-color: #f2f2f2; }}
                </style>
            </head>
            <body>
                {html_content}
            </body>
            </html>
            """

            html_path = markdown_path.with_suffix('.html')
            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(html_template)

        except Exception as e:
            self.logger.warning(f"HTMLæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")

    def _extract_knowledge_from_experiment(self,
                                           metadata: ExperimentMetadata,
                                           result: ExperimentResult):
        """ä»å®éªŒä¸­æå–çŸ¥è¯†"""
        try:
            # æå–å…³é”®å‘ç°
            knowledge_id = f"knowledge_{metadata.experiment_id}_{uuid.uuid4().hex[:8]}"

            # åˆ†æç»“æœ
            insights = []

            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨è¿‡æ‹Ÿåˆ
            if ('train_loss' in result.logs.get('training_history', {}) and
                    'val_loss' in result.logs.get('training_history', {})):
                train_loss = result.logs['training_history']['train_loss'][-1] if result.logs['training_history'][
                    'train_loss'] else 0
                val_loss = result.logs['training_history']['val_loss'][-1] if result.logs['training_history'][
                    'val_loss'] else 0

                if val_loss > train_loss * 1.2:  # éªŒè¯æŸå¤±æ¯”è®­ç»ƒæŸå¤±é«˜20%
                    insights.append("å‘ç°è¿‡æ‹Ÿåˆè¿¹è±¡ï¼šéªŒè¯æŸå¤±æ˜¾è‘—é«˜äºè®­ç»ƒæŸå¤±")
                elif train_loss > val_loss * 1.2:
                    insights.append("å‘ç°æ¬ æ‹Ÿåˆè¿¹è±¡ï¼šè®­ç»ƒæŸå¤±æ˜¾è‘—é«˜äºéªŒè¯æŸå¤±")

            # æ£€æŸ¥è®­ç»ƒç¨³å®šæ€§
            if 'train_loss' in result.logs.get('training_history', {}):
                losses = result.logs['training_history']['train_loss']
                if len(losses) > 10:
                    final_loss = losses[-1]
                    initial_loss = losses[0]
                    improvement = (initial_loss - final_loss) / initial_loss

                    if improvement > 0.5:
                        insights.append(f"è®­ç»ƒæ•ˆæœæ˜¾è‘—ï¼šæŸå¤±é™ä½äº†{improvement:.1%}")

            # æ£€æŸ¥æ™ºèƒ½ä½“äº¤äº’
            if 'agent_decisions' in result.logs:
                decisions = result.logs['agent_decisions']
                if isinstance(decisions, dict) and 'total_requests' in decisions:
                    if decisions['total_requests'] > 0:
                        success_rate = decisions.get('successful_requests', 0) / decisions['total_requests']
                        if success_rate < 0.5:
                            insights.append("æ™ºèƒ½ä½“ç³»ç»Ÿäº¤äº’æˆåŠŸç‡è¾ƒä½")

            # åˆ›å»ºçŸ¥è¯†æ¡ç›®
            if insights:
                knowledge = KnowledgeBaseEntry(
                    knowledge_id=knowledge_id,
                    title=f"å®éªŒå‘ç°: {metadata.name}",
                    content="\n".join(insights),
                    experiment_ids=[metadata.experiment_id],
                    evidence={
                        'metrics': result.metrics,
                        'config_summary': {
                            'learning_rate': metadata.config.get('training', {}).get('learning_rate'),
                            'batch_size': metadata.config.get('data', {}).get('batch_size'),
                            'epochs': metadata.config.get('training', {}).get('epochs')
                        }
                    },
                    confidence=0.7,
                    tags=metadata.tags + ['experiment_finding']
                )

                self.db.save_knowledge(knowledge)
                self.logger.info(f"ğŸ§  æå–çŸ¥è¯†: {knowledge_id}")

        except Exception as e:
            self.logger.warning(f"çŸ¥è¯†æå–å¤±è´¥: {e}")

    def _extract_knowledge_from_ablation(self,
                                         comparison: AblationComparison,
                                         experiment_id: str):
        """ä»æ¶ˆèå®éªŒä¸­æå–çŸ¥è¯†"""
        try:
            # åˆ†ææœ€ä½³å’Œæœ€å·®å˜ä½“
            best_variant = None
            best_mse = float('inf')
            worst_variant = None
            worst_mse = 0

            for variant, stats in comparison.summary_stats.items():
                mse = stats['mean']
                if mse < best_mse:
                    best_mse = mse
                    best_variant = variant
                if mse > worst_mse:
                    worst_mse = mse
                    worst_variant = variant

            # åˆ›å»ºçŸ¥è¯†æ¡ç›®
            if best_variant and worst_variant:
                knowledge_id = f"knowledge_ablation_{experiment_id}_{uuid.uuid4().hex[:8]}"

                content = f"""
æ¶ˆèå®éªŒå‘ç°ï¼š
1. æœ€ä½³æ€§èƒ½å˜ä½“ï¼š{best_variant} (MSE: {best_mse:.6f})
2. æœ€å·®æ€§èƒ½å˜ä½“ï¼š{worst_variant} (MSE: {worst_mse:.6f})
3. æ€§èƒ½å·®å¼‚ï¼š{worst_mse / best_mse:.1%}

å…³é”®æ´å¯Ÿï¼š
- {self._get_ablation_insight(best_variant, worst_variant)}
"""

                knowledge = KnowledgeBaseEntry(
                    knowledge_id=knowledge_id,
                    title=f"æ¶ˆèå®éªŒå‘ç°: {experiment_id}",
                    content=content,
                    experiment_ids=[experiment_id],
                    evidence={
                        'best_variant': best_variant,
                        'best_mse': best_mse,
                        'worst_variant': worst_variant,
                        'worst_mse': worst_mse,
                        'statistical_tests': comparison.statistical_tests
                    },
                    confidence=0.8,
                    tags=['ablation_study', 'performance_analysis']
                )

                self.db.save_knowledge(knowledge)
                self.logger.info(f"ğŸ§  æå–æ¶ˆèçŸ¥è¯†: {knowledge_id}")

        except Exception as e:
            self.logger.warning(f"æ¶ˆèçŸ¥è¯†æå–å¤±è´¥: {e}")

    def _get_ablation_insight(self, best_variant: str, worst_variant: str) -> str:
        """è·å–æ¶ˆèå®éªŒæ´å¯Ÿ"""
        insights = {
            ('full', 'no_autogen'): "AutoGenå¤šæ™ºèƒ½ä½“ç³»ç»Ÿå¯¹æ€§èƒ½æå‡æœ‰æ˜¾è‘—è´¡çŒ®",
            ('full', 'no_agent_lightning'): "Agent Lightningå¼ºåŒ–å­¦ä¹ æœºåˆ¶æœ‰æ•ˆæå‡äº†æ¨¡å‹é€‚åº”æ€§",
            ('full', 'no_istr'): "ISTRç½‘ç»œï¼ˆTCN+æ‹‰æ™®æ‹‰æ–¯ï¼‰æ˜¯æ€§èƒ½æå‡çš„å…³é”®",
            ('full', 'no_laplacian'): "æ‹‰æ™®æ‹‰æ–¯æ­£åˆ™åŒ–æœ‰æ•ˆé˜²æ­¢äº†è¿‡æ‹Ÿåˆ",
            ('full', 'no_spectral_gate'): "è°±é—¨æ§æœºåˆ¶å¢å¼ºäº†ç‰¹å¾æå–èƒ½åŠ›",
            ('full', 'frozen_istr'): "ISTRç½‘ç»œçš„è‡ªé€‚åº”å‚æ•°è°ƒæ•´è‡³å…³é‡è¦",
            ('full', 'single_agent'): "å¤šæ™ºèƒ½ä½“ååŒæ¯”å•æ™ºèƒ½ä½“æ›´æœ‰æ•ˆ",
            ('full', 'no_semantic_reward'): "è¯­ä¹‰å¥–åŠ±æœºåˆ¶æé«˜äº†å¼ºåŒ–å­¦ä¹ æ•ˆæœ",
            ('full', 'simple_baseline'): "å®Œæ•´STAR-Forecastæ¡†æ¶æ˜¾è‘—ä¼˜äºç®€å•åŸºçº¿"
        }

        return insights.get((best_variant, worst_variant),
                            f"{best_variant}æ¯”{worst_variant}è¡¨ç°æ›´å¥½")

    def compare_experiments(self, experiment_ids: List[str]) -> ExperimentComparison:
        """æ¯”è¾ƒå¤šä¸ªå®éªŒ"""
        comparison_id = f"comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        comparison_metrics = {}
        ranking = {}

        for exp_id in experiment_ids:
            result = self.db.get_experiment_result(exp_id)
            if result and result.metrics:
                # æå–æ•°å€¼æŒ‡æ ‡
                for metric_name, metric_value in result.metrics.items():
                    if isinstance(metric_value, (int, float)):
                        if metric_name not in comparison_metrics:
                            comparison_metrics[metric_name] = {}
                        comparison_metrics[metric_name][exp_id] = metric_value

        # ç”Ÿæˆæ’å
        for metric_name, experiment_values in comparison_metrics.items():
            # æ’åºï¼ˆè¶Šå°è¶Šå¥½å¯¹äºMSEç­‰æŸå¤±æŒ‡æ ‡ï¼‰
            if any('loss' in metric_name.lower() or 'mse' in metric_name.lower() or 'mae' in metric_name.lower()
                   for keyword in ['loss', 'mse', 'mae', 'error']):
                sorted_experiments = sorted(experiment_values.items(), key=lambda x: x[1])
            else:  # è¶Šå¤§è¶Šå¥½å¯¹äºå‡†ç¡®ç‡ç­‰æŒ‡æ ‡
                sorted_experiments = sorted(experiment_values.items(), key=lambda x: x[1], reverse=True)

            ranking[metric_name] = [exp_id for exp_id, _ in sorted_experiments]

        # ç”Ÿæˆæ´å¯Ÿ
        insights = self._generate_comparison_insights(comparison_metrics, ranking)

        comparison = ExperimentComparison(
            comparison_id=comparison_id,
            experiment_ids=experiment_ids,
            comparison_metrics=comparison_metrics,
            ranking=ranking,
            insights=insights
        )

        return comparison

    def _generate_comparison_insights(self,
                                      comparison_metrics: Dict[str, Dict[str, float]],
                                      ranking: Dict[str, List[str]]) -> List[str]:
        """ç”Ÿæˆæ¯”è¾ƒæ´å¯Ÿ"""
        insights = []

        if not comparison_metrics:
            return insights

        # æ‰¾å‡ºæœ€ä½³å®éªŒ
        primary_metric = next(iter(comparison_metrics))
        if primary_metric in ranking and ranking[primary_metric]:
            best_experiment = ranking[primary_metric][0]
            insights.append(f"æœ€ä½³å®éªŒ: {best_experiment} (åœ¨{primary_metric}ä¸Šè¡¨ç°æœ€å¥½)")

        # åˆ†ææ€§èƒ½å·®å¼‚
        for metric_name, experiment_values in comparison_metrics.items():
            if len(experiment_values) >= 2:
                values = list(experiment_values.values())
                min_val, max_val = min(values), max(values)

                if min_val > 0:
                    ratio = max_val / min_val
                    if ratio > 1.5:
                        insights.append(f"åœ¨{metric_name}ä¸Šï¼Œæœ€ä½³å’Œæœ€å·®å®éªŒæ€§èƒ½å·®å¼‚æ˜¾è‘— ({ratio:.1f}å€)")

        return insights

    def search_knowledge(self,
                         query: str,
                         tags: List[str] = None,
                         min_confidence: float = 0.0,
                         limit: int = 10) -> List[KnowledgeBaseEntry]:
        """æœç´¢çŸ¥è¯†åº“"""
        # è¿™é‡Œå®ç°ç®€å•çš„å…³é”®è¯æœç´¢
        # å®é™…é¡¹ç›®åº”ä½¿ç”¨å‘é‡æœç´¢æˆ–å…¨æ–‡æœç´¢

        with self.db._get_connection() as conn:
            conditions = ["(title LIKE ? OR content LIKE ?)"]
            params = [f'%{query}%', f'%{query}%']

            if tags:
                tag_conditions = []
                for tag in tags:
                    tag_conditions.append("tags LIKE ?")
                    params.append(f'%{tag}%')

                if tag_conditions:
                    conditions.append(f"({' OR '.join(tag_conditions)})")

            if min_confidence > 0:
                conditions.append("confidence >= ?")
                params.append(min_confidence)

            where_clause = " AND ".join(conditions)
            sql = f"""
                SELECT * FROM knowledge_base 
                WHERE {where_clause}
                ORDER BY citation_count DESC, confidence DESC
                LIMIT ?
            """
            params.append(limit)

            cursor = conn.execute(sql, params)
            rows = cursor.fetchall()

            knowledge_entries = []
            for row in rows:
                entry = KnowledgeBaseEntry(
                    knowledge_id=row['knowledge_id'],
                    title=row['title'],
                    content=row['content'],
                    experiment_ids=json.loads(row['experiment_ids']),
                    evidence=json.loads(row['evidence']),
                    confidence=row['confidence'],
                    tags=json.loads(row['tags']) if row['tags'] else []
                )
                entry.created_at = datetime.fromisoformat(row['created_at'])
                entry.updated_at = datetime.fromisoformat(row['updated_at'])
                entry.citation_count = row['citation_count']

                knowledge_entries.append(entry)

            return knowledge_entries

    def get_experiment_statistics(self) -> Dict[str, Any]:
        """è·å–å®éªŒç»Ÿè®¡"""
        return self.db.get_statistics()

    def export_experiment(self, experiment_id: str, export_path: str):
        """å¯¼å‡ºå®éªŒ"""
        metadata = self.db.get_experiment(experiment_id)
        if not metadata:
            raise ValueError(f"å®éªŒä¸å­˜åœ¨: {experiment_id}")

        result = self.db.get_experiment_result(experiment_id)

        # åˆ›å»ºå¯¼å‡ºç›®å½•
        export_dir = Path(export_path) / experiment_id
        export_dir.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜å…ƒæ•°æ®
        with open(export_dir / "metadata.json", 'w', encoding='utf-8') as f:
            json.dump(metadata.to_dict(), f, indent=2, ensure_ascii=False)

        # ä¿å­˜ç»“æœ
        if result:
            with open(export_dir / "result.json", 'w', encoding='utf-8') as f:
                json.dump(result.to_dict(), f, indent=2, ensure_ascii=False)

        # å¤åˆ¶é…ç½®æ–‡ä»¶
        config_src = self.experiments_root / "configs" / f"{experiment_id}.yaml"
        if config_src.exists():
            shutil.copy(config_src, export_dir / "config.yaml")

        # å¤åˆ¶æ¨¡å‹æ–‡ä»¶
        if result and result.models:
            for model_name, model_path in result.models.items():
                if Path(model_path).exists():
                    shutil.copy(model_path, export_dir / f"{model_name}.pth")

        self.logger.info(f"ğŸ“¤ å®éªŒå¯¼å‡ºåˆ°: {export_dir}")

    def import_experiment(self, import_path: str) -> str:
        """å¯¼å…¥å®éªŒ"""
        import_dir = Path(import_path)

        # è¯»å–å…ƒæ•°æ®
        metadata_path = import_dir / "metadata.json"
        if not metadata_path.exists():
            raise ValueError(f"å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {metadata_path}")

        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata_dict = json.load(f)

        # åˆ›å»ºæ–°å®éªŒID
        new_experiment_id = f"{metadata_dict['experiment_type']}_imported_{uuid.uuid4().hex[:8]}"

        # æ›´æ–°å…ƒæ•°æ®
        metadata_dict['experiment_id'] = new_experiment_id
        metadata_dict['created_at'] = datetime.now().isoformat()

        # ä¿å­˜åˆ°æ•°æ®åº“
        metadata = ExperimentMetadata(**metadata_dict)
        self.db.save_experiment(metadata)

        # ä¿å­˜é…ç½®æ–‡ä»¶
        config_src = import_dir / "config.yaml"
        if config_src.exists():
            config_dst = self.experiments_root / "configs" / f"{new_experiment_id}.yaml"
            shutil.copy(config_src, config_dst)

        # è¯»å–ç»“æœ
        result_path = import_dir / "result.json"
        if result_path.exists():
            with open(result_path, 'r', encoding='utf-8') as f:
                result_dict = json.load(f)

            result_dict['experiment_id'] = new_experiment_id
            result_dict['created_at'] = datetime.now().isoformat()

            result = ExperimentResult(**result_dict)
            self.db.save_experiment_result(result)

        self.logger.info(f"ğŸ“¥ å®éªŒå¯¼å…¥å®Œæˆ: {new_experiment_id}")

        return new_experiment_id


# Webç•Œé¢ç±»
class ExperimentDashboard:
    """å®éªŒä»ªè¡¨æ¿ï¼ˆWebç•Œé¢ï¼‰"""

    def __init__(self, experiment_manager: ExperimentManager, port: int = 8080):
        self.manager = experiment_manager
        self.port = port

    def run(self):
        """è¿è¡ŒWebä»ªè¡¨æ¿"""
        try:
            from flask import Flask, render_template, jsonify, request
            import plotly
            import plotly.graph_objs as go
            import json

            app = Flask(__name__)

            @app.route('/')
            def index():
                """é¦–é¡µ"""
                stats = self.manager.get_experiment_statistics()
                recent_experiments = self.manager.db.search_experiments(limit=10)

                return render_template('index.html',
                                       stats=stats,
                                       experiments=recent_experiments)

            @app.route('/api/experiments')
            def get_experiments():
                """è·å–å®éªŒåˆ—è¡¨"""
                experiments = self.manager.db.search_experiments(limit=100)
                return jsonify([exp.to_dict() for exp in experiments])

            @app.route('/api/experiment/<experiment_id>')
            def get_experiment(experiment_id):
                """è·å–å®éªŒè¯¦æƒ…"""
                metadata = self.manager.db.get_experiment(experiment_id)
                result = self.manager.db.get_experiment_result(experiment_id)

                if not metadata:
                    return jsonify({'error': 'Experiment not found'}), 404

                response = {
                    'metadata': metadata.to_dict(),
                    'result': result.to_dict() if result else None
                }

                return jsonify(response)

            @app.route('/api/knowledge')
            def get_knowledge():
                """è·å–çŸ¥è¯†åº“"""
                query = request.args.get('query', '')
                tags = request.args.getlist('tags')

                knowledge = self.manager.search_knowledge(query, tags)
                return jsonify([k.to_dict() for k in knowledge])

            @app.route('/api/statistics')
            def get_statistics():
                """è·å–ç»Ÿè®¡ä¿¡æ¯"""
                stats = self.manager.get_experiment_statistics()
                return jsonify(stats)

            self.logger.info(f"ğŸŒ å®éªŒä»ªè¡¨æ¿å¯åŠ¨: http://localhost:{self.port}")
            app.run(host='0.0.0.0', port=self.port, debug=False)

        except ImportError:
            self.logger.error("éœ€è¦å®‰è£…Flaskå’Œplotlyæ¥è¿è¡Œä»ªè¡¨æ¿")
            self.logger.error("å®‰è£…å‘½ä»¤: pip install flask plotly")


# ä½¿ç”¨ç¤ºä¾‹
def main():
    """å®éªŒç®¡ç†å™¨ä½¿ç”¨ç¤ºä¾‹"""
    import argparse

    parser = argparse.ArgumentParser(description="å®éªŒç®¡ç†å™¨")
    parser.add_argument("--action", type=str, required=True,
                        choices=['create', 'run', 'compare', 'search', 'export', 'import', 'dashboard'],
                        help="è¦æ‰§è¡Œçš„æ“ä½œ")
    parser.add_argument("--type", type=str,
                        choices=['full_training', 'ablation_study', 'baseline_comparison'],
                        help="å®éªŒç±»å‹")
    parser.add_argument("--name", type=str, help="å®éªŒåç§°")
    parser.add_argument("--description", type=str, help="å®éªŒæè¿°")
    parser.add_argument("--experiment_id", type=str, help="å®éªŒID")
    parser.add_argument("--data", type=str, default="./data/ETTh1.csv",
                        help="æ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--tags", type=str, nargs='+', help="å®éªŒæ ‡ç­¾")

    args = parser.parse_args()

    # åˆ›å»ºå®éªŒç®¡ç†å™¨
    manager = ExperimentManager()

    if args.action == 'create':
        if not args.type or not args.name:
            print("éœ€è¦æŒ‡å®šå®éªŒç±»å‹å’Œåç§°")
            return

        experiment_type = ExperimentType(args.type)

        metadata = manager.create_experiment(
            name=args.name,
            description=args.description or f"{args.type} experiment",
            experiment_type=experiment_type,
            tags=args.tags
        )

        print(f"âœ… å®éªŒåˆ›å»ºæˆåŠŸ: {metadata.experiment_id}")
        print(f"   åç§°: {metadata.name}")
        print(f"   ç±»å‹: {metadata.experiment_type.value}")

    elif args.action == 'run':
        if not args.experiment_id:
            print("éœ€è¦æŒ‡å®šå®éªŒID")
            return

        metadata = manager.db.get_experiment(args.experiment_id)
        if not metadata:
            print(f"å®éªŒä¸å­˜åœ¨: {args.experiment_id}")
            return

        if metadata.experiment_type == ExperimentType.FULL_TRAINING:
            result = manager.run_full_training(args.experiment_id, args.data)
        elif metadata.experiment_type == ExperimentType.ABLATION_STUDY:
            result = manager.run_ablation_study(args.experiment_id, data_path=args.data)
        elif metadata.experiment_type == ExperimentType.BASELINE_COMPARISON:
            result = manager.run_baseline_comparison(args.experiment_id, data_path=args.data)
        else:
            print(f"ä¸æ”¯æŒçš„å®éªŒç±»å‹: {metadata.experiment_type}")
            return

        print(f"âœ… å®éªŒå®Œæˆ: {args.experiment_id}")
        print(f"   ç»“æœ: {result.metrics}")

    elif args.action == 'compare':
        if not args.experiment_id:
            print("éœ€è¦æŒ‡å®šå®éªŒIDï¼ˆå¤šä¸ªç”¨é€—å·åˆ†éš”ï¼‰")
            return

        experiment_ids = args.experiment_id.split(',')
        comparison = manager.compare_experiments(experiment_ids)

        print(f"ğŸ“Š å®éªŒæ¯”è¾ƒç»“æœ:")
        for insight in comparison.insights:
            print(f"   {insight}")

    elif args.action == 'search':
        knowledge = manager.search_knowledge(args.description or '', args.tags)

        print(f"ğŸ§  æ‰¾åˆ° {len(knowledge)} æ¡çŸ¥è¯†:")
        for k in knowledge:
            print(f"   [{k.confidence:.1%}] {k.title}")
            print(f"      {k.content[:100]}...")
            print()

    elif args.action == 'dashboard':
        dashboard = ExperimentDashboard(manager)
        dashboard.run()

    else:
        print(f"æœªçŸ¥æ“ä½œ: {args.action}")


if __name__ == "__main__":
    main()