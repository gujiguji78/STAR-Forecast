"""
STAR-Forecast å¯è§†åŒ–æ¨¡å—
çœŸå®æœ‰æ•ˆçš„å¯è§†åŒ–å·¥å…·ï¼Œæ”¯æŒè®­ç»ƒæ›²çº¿ã€é¢„æµ‹ç»“æœã€ç‰¹å¾åˆ†æç­‰
æ— æ¨¡æ‹Ÿæˆåˆ†ï¼Œå®Œå…¨å¯ç”¨
"""
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Union
import torch
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings

warnings.filterwarnings('ignore')

# è®¾ç½®matplotlibæ ·å¼
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆå¦‚æœéœ€è¦ï¼‰
try:
    plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
except:
    pass


class TrainingVisualizer:
    """è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–"""

    def __init__(self, save_dir: str = "./visualizations"):
        """
        åˆå§‹åŒ–å¯è§†åŒ–å™¨

        Args:
            save_dir: å¯è§†åŒ–ç»“æœä¿å­˜ç›®å½•
        """
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)

    def plot_training_curves(self,
                             train_losses: List[float],
                             val_losses: List[float],
                             train_metrics: Optional[Dict[str, List[float]]] = None,
                             val_metrics: Optional[Dict[str, List[float]]] = None,
                             title: str = "è®­ç»ƒè¿‡ç¨‹æ›²çº¿",
                             save_name: Optional[str] = None):
        """
        ç»˜åˆ¶è®­ç»ƒæ›²çº¿

        Args:
            train_losses: è®­ç»ƒæŸå¤±åˆ—è¡¨
            val_losses: éªŒè¯æŸå¤±åˆ—è¡¨
            train_metrics: è®­ç»ƒæŒ‡æ ‡å­—å…¸
            val_metrics: éªŒè¯æŒ‡æ ‡å­—å…¸
            title: å›¾è¡¨æ ‡é¢˜
            save_name: ä¿å­˜æ–‡ä»¶å
        """
        epochs = range(1, len(train_losses) + 1)

        # ç¡®å®šå­å›¾æ•°é‡
        n_plots = 1  # æŸå¤±æ›²çº¿
        if train_metrics:
            n_plots += len(train_metrics)

        fig, axes = plt.subplots(n_plots, 1, figsize=(12, 4 * n_plots))
        if n_plots == 1:
            axes = [axes]

        # ç»˜åˆ¶æŸå¤±æ›²çº¿
        ax = axes[0]
        ax.plot(epochs, train_losses, 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2, alpha=0.8)
        ax.plot(epochs, val_losses, 'r-', label='éªŒè¯æŸå¤±', linewidth=2, alpha=0.8)

        # æ ‡è®°æœ€ä½³ç‚¹
        best_epoch = np.argmin(val_losses) + 1
        best_loss = min(val_losses)
        ax.scatter(best_epoch, best_loss, color='red', s=100,
                   zorder=5, label=f'æœ€ä½³éªŒè¯æŸå¤±: {best_loss:.4f}')
        ax.axvline(x=best_epoch, color='red', linestyle='--', alpha=0.5)

        ax.set_xlabel('Epoch')
        ax.set_ylabel('æŸå¤±')
        ax.set_title('è®­ç»ƒå’ŒéªŒè¯æŸå¤±')
        ax.legend()
        ax.grid(True, alpha=0.3)

        # ç»˜åˆ¶æŒ‡æ ‡æ›²çº¿
        if train_metrics and n_plots > 1:
            for idx, (metric_name, train_values) in enumerate(train_metrics.items(), 1):
                if idx >= n_plots:
                    break

                ax = axes[idx]
                ax.plot(epochs, train_values, 'g-', label=f'è®­ç»ƒ{metric_name.upper()}',
                        linewidth=2, alpha=0.8)

                if val_metrics and metric_name in val_metrics:
                    val_values = val_metrics[metric_name]
                    ax.plot(epochs, val_values, 'orange', label=f'éªŒè¯{metric_name.upper()}',
                            linewidth=2, alpha=0.8)

                    # æ ‡è®°æœ€ä½³ç‚¹
                    if metric_name in ['mse', 'loss']:  # è¶Šå°è¶Šå¥½
                        best_idx = np.argmin(val_values)
                        best_val = val_values[best_idx]
                    else:  # è¶Šå¤§è¶Šå¥½
                        best_idx = np.argmax(val_values)
                        best_val = val_values[best_idx]

                    ax.scatter(best_idx + 1, best_val, color='orange', s=80,
                               zorder=5, label=f'æœ€ä½³: {best_val:.4f}')

                ax.set_xlabel('Epoch')
                ax.set_ylabel(metric_name.upper())
                ax.set_title(f'{metric_name.upper()} æ›²çº¿')
                ax.legend()
                ax.grid(True, alpha=0.3)

        plt.suptitle(title, fontsize=16, fontweight='bold')
        plt.tight_layout()

        # ä¿å­˜å›¾ç‰‡
        if save_name:
            save_path = self.save_dir / f"{save_name}_training_curves.png"
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š è®­ç»ƒæ›²çº¿å·²ä¿å­˜åˆ°: {save_path}")

        plt.show()

    def plot_prediction_vs_actual(self,
                                  predictions: np.ndarray,
                                  actuals: np.ndarray,
                                  sample_indices: Optional[List[int]] = None,
                                  seq_len: int = 96,
                                  pred_len: int = 24,
                                  title: str = "é¢„æµ‹ vs å®é™…å€¼",
                                  save_name: Optional[str] = None):
        """
        ç»˜åˆ¶é¢„æµ‹å€¼ä¸å®é™…å€¼å¯¹æ¯”

        Args:
            predictions: é¢„æµ‹å€¼æ•°ç»„ [n_samples, pred_len]
            actuals: å®é™…å€¼æ•°ç»„ [n_samples, pred_len]
            sample_indices: è¦ç»˜åˆ¶çš„æ ·æœ¬ç´¢å¼•åˆ—è¡¨
            seq_len: è¾“å…¥åºåˆ—é•¿åº¦
            pred_len: é¢„æµ‹é•¿åº¦
            title: å›¾è¡¨æ ‡é¢˜
            save_name: ä¿å­˜æ–‡ä»¶å
        """
        if sample_indices is None:
            # éšæœºé€‰æ‹©3ä¸ªæ ·æœ¬
            n_samples = min(3, len(predictions))
            sample_indices = np.random.choice(len(predictions), n_samples, replace=False)

        n_samples = len(sample_indices)
        fig, axes = plt.subplots(n_samples, 1, figsize=(14, 4 * n_samples))

        if n_samples == 1:
            axes = [axes]

        for idx, sample_idx in enumerate(sample_indices):
            ax = axes[idx]

            # å®é™…å€¼
            actual = actuals[sample_idx]

            # é¢„æµ‹å€¼
            pred = predictions[sample_idx]

            # æ—¶é—´è½´
            time_axis = np.arange(pred_len)

            # ç»˜åˆ¶
            ax.plot(time_axis, actual, 'b-', label='å®é™…å€¼', linewidth=2, alpha=0.8, marker='o')
            ax.plot(time_axis, pred, 'r-', label='é¢„æµ‹å€¼', linewidth=2, alpha=0.8, marker='s')

            # å¡«å……è¯¯å·®åŒºåŸŸ
            ax.fill_between(time_axis, actual, pred,
                            where=(pred >= actual),
                            color='red', alpha=0.2, label='æ­£è¯¯å·®')
            ax.fill_between(time_axis, actual, pred,
                            where=(pred < actual),
                            color='blue', alpha=0.2, label='è´Ÿè¯¯å·®')

            # è®¡ç®—è¯¯å·®
            mse = np.mean((pred - actual) ** 2)
            mae = np.mean(np.abs(pred - actual))

            ax.set_xlabel('æ—¶é—´æ­¥')
            ax.set_ylabel('å€¼')
            ax.set_title(f'æ ·æœ¬ {sample_idx}: MSE={mse:.4f}, MAE={mae:.4f}')
            ax.legend()
            ax.grid(True, alpha=0.3)

            # æ·»åŠ è¯¯å·®æ¡å½¢å›¾
            errors = np.abs(pred - actual)
            ax_twin = ax.twinx()
            ax_twin.bar(time_axis, errors, alpha=0.3, color='gray', width=0.4, label='ç»å¯¹è¯¯å·®')
            ax_twin.set_ylabel('ç»å¯¹è¯¯å·®')
            ax_twin.legend(loc='upper right')

        plt.suptitle(title, fontsize=16, fontweight='bold')
        plt.tight_layout()

        # ä¿å­˜å›¾ç‰‡
        if save_name:
            save_path = self.save_dir / f"{save_name}_predictions.png"
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“ˆ é¢„æµ‹å¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {save_path}")

        plt.show()

    def plot_error_distribution(self,
                                predictions: np.ndarray,
                                actuals: np.ndarray,
                                title: str = "é¢„æµ‹è¯¯å·®åˆ†å¸ƒ",
                                save_name: Optional[str] = None):
        """
        ç»˜åˆ¶é¢„æµ‹è¯¯å·®åˆ†å¸ƒ

        Args:
            predictions: é¢„æµ‹å€¼
            actuals: å®é™…å€¼
            title: å›¾è¡¨æ ‡é¢˜
            save_name: ä¿å­˜æ–‡ä»¶å
        """
        errors = predictions - actuals
        abs_errors = np.abs(errors)

        fig, axes = plt.subplots(2, 2, figsize=(14, 10))

        # 1. è¯¯å·®ç›´æ–¹å›¾
        ax = axes[0, 0]
        ax.hist(errors.flatten(), bins=50, alpha=0.7, color='blue', edgecolor='black')
        ax.axvline(x=0, color='red', linestyle='--', linewidth=2)
        ax.set_xlabel('é¢„æµ‹è¯¯å·® (é¢„æµ‹å€¼ - å®é™…å€¼)')
        ax.set_ylabel('é¢‘æ¬¡')
        ax.set_title('é¢„æµ‹è¯¯å·®åˆ†å¸ƒ')
        ax.grid(True, alpha=0.3)

        # 2. ç»å¯¹è¯¯å·®åˆ†å¸ƒ
        ax = axes[0, 1]
        ax.hist(abs_errors.flatten(), bins=50, alpha=0.7, color='green', edgecolor='black')
        ax.set_xlabel('ç»å¯¹è¯¯å·®')
        ax.set_ylabel('é¢‘æ¬¡')
        ax.set_title('ç»å¯¹è¯¯å·®åˆ†å¸ƒ')
        ax.grid(True, alpha=0.3)

        # 3. è¯¯å·®ç®±çº¿å›¾ï¼ˆæŒ‰æ—¶é—´æ­¥ï¼‰
        ax = axes[1, 0]
        if len(predictions.shape) > 1:
            time_step_errors = [errors[:, i] for i in range(predictions.shape[1])]
            ax.boxplot(time_step_errors)
            ax.set_xlabel('é¢„æµ‹æ—¶é—´æ­¥')
            ax.set_ylabel('é¢„æµ‹è¯¯å·®')
            ax.set_title('å„æ—¶é—´æ­¥é¢„æµ‹è¯¯å·®åˆ†å¸ƒ')
            ax.axhline(y=0, color='red', linestyle='--', alpha=0.5)
            ax.grid(True, alpha=0.3)

        # 4. è¯¯å·®QQå›¾ï¼ˆæ£€æŸ¥æ­£æ€æ€§ï¼‰
        ax = axes[1, 1]
        from scipy import stats
        stats.probplot(errors.flatten(), dist="norm", plot=ax)
        ax.set_title('è¯¯å·®QQå›¾ï¼ˆæ£€éªŒæ­£æ€æ€§ï¼‰')
        ax.grid(True, alpha=0.3)

        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        mean_error = np.mean(errors)
        std_error = np.std(errors)
        mae = np.mean(abs_errors)
        mse = np.mean(errors ** 2)

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬
        stats_text = f"""
        è¯¯å·®ç»Ÿè®¡:
        å‡å€¼: {mean_error:.4f}
        æ ‡å‡†å·®: {std_error:.4f}
        MAE: {mae:.4f}
        MSE: {mse:.4f}
        RMSE: {np.sqrt(mse):.4f}
        """

        fig.text(0.02, 0.02, stats_text, fontsize=10,
                 verticalalignment='bottom',
                 bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

        plt.suptitle(title, fontsize=16, fontweight='bold')
        plt.tight_layout()

        # ä¿å­˜å›¾ç‰‡
        if save_name:
            save_path = self.save_dir / f"{save_name}_error_distribution.png"
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š è¯¯å·®åˆ†å¸ƒå›¾å·²ä¿å­˜åˆ°: {save_path}")

        plt.show()

    def plot_feature_importance(self,
                                model,
                                feature_names: List[str],
                                sample_data: torch.Tensor,
                                title: str = "ç‰¹å¾é‡è¦æ€§åˆ†æ",
                                save_name: Optional[str] = None):
        """
        ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§åˆ†æ

        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹
            feature_names: ç‰¹å¾åç§°åˆ—è¡¨
            sample_data: æ ·æœ¬æ•°æ® [batch, seq_len, n_features]
            title: å›¾è¡¨æ ‡é¢˜
            save_name: ä¿å­˜æ–‡ä»¶å
        """
        model.eval()

        # ä½¿ç”¨æ¢¯åº¦ä¿¡æ¯ä¼°è®¡ç‰¹å¾é‡è¦æ€§
        sample_data.requires_grad = True

        # å‰å‘ä¼ æ’­
        features = model(sample_data)
        output = features.mean()  # ç®€åŒ–

        # åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦
        output.backward()

        # è·å–æ¢¯åº¦
        gradients = sample_data.grad.abs().mean(dim=(0, 1)).cpu().numpy()  # [n_features]

        # å½’ä¸€åŒ–
        gradients = gradients / (gradients.sum() + 1e-8)

        # ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§
        fig, axes = plt.subplots(1, 2, figsize=(14, 6))

        # 1. æ¡å½¢å›¾
        ax = axes[0]
        y_pos = np.arange(len(feature_names))
        ax.barh(y_pos, gradients, align='center', alpha=0.7, color='steelblue')
        ax.set_yticks(y_pos)
        ax.set_yticklabels(feature_names)
        ax.set_xlabel('ç‰¹å¾é‡è¦æ€§ï¼ˆæ¢¯åº¦ç»å¯¹å€¼ï¼‰')
        ax.set_title('åŸºäºæ¢¯åº¦çš„ç‰¹å¾é‡è¦æ€§')
        ax.grid(True, alpha=0.3, axis='x')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, v in enumerate(gradients):
            ax.text(v + 0.001, i, f'{v:.3f}', va='center')

        # 2. é¥¼å›¾
        ax = axes[1]
        # åªæ˜¾ç¤ºé‡è¦æ€§å¤§äºé˜ˆå€¼
        threshold = 0.05
        mask = gradients > threshold
        if mask.sum() > 0:
            important_features = np.array(feature_names)[mask]
            important_values = gradients[mask]

            # æ·»åŠ "å…¶ä»–"ç±»åˆ«
            other_value = gradients[~mask].sum()
            if other_value > 0:
                important_features = np.append(important_features, 'å…¶ä»–')
                important_values = np.append(important_values, other_value)

            wedges, texts, autotexts = ax.pie(important_values,
                                              labels=important_features,
                                              autopct='%1.1f%%',
                                              startangle=90,
                                              colors=plt.cm.Set3(np.linspace(0, 1, len(important_features))))
            ax.axis('equal')
            ax.set_title('ç‰¹å¾é‡è¦æ€§åˆ†å¸ƒ')

        plt.suptitle(title, fontsize=16, fontweight='bold')
        plt.tight_layout()

        # ä¿å­˜å›¾ç‰‡
        if save_name:
            save_path = self.save_dir / f"{save_name}_feature_importance.png"
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ” ç‰¹å¾é‡è¦æ€§å›¾å·²ä¿å­˜åˆ°: {save_path}")

        plt.show()

        return gradients


class InteractiveVisualizer:
    """äº¤äº’å¼å¯è§†åŒ–ï¼ˆä½¿ç”¨Plotlyï¼‰"""

    def __init__(self):
        """åˆå§‹åŒ–äº¤äº’å¼å¯è§†åŒ–å™¨"""
        self.figures = {}

    def create_interactive_training_curve(self,
                                          train_losses: List[float],
                                          val_losses: List[float],
                                          train_metrics: Optional[Dict] = None,
                                          title: str = "äº¤äº’å¼è®­ç»ƒæ›²çº¿"):
        """
        åˆ›å»ºäº¤äº’å¼è®­ç»ƒæ›²çº¿

        Args:
            train_losses: è®­ç»ƒæŸå¤±
            val_losses: éªŒè¯æŸå¤±
            train_metrics: è®­ç»ƒæŒ‡æ ‡
            title: å›¾è¡¨æ ‡é¢˜

        Returns:
            plotly.graph_objects.Figure: äº¤äº’å¼å›¾è¡¨
        """
        epochs = list(range(1, len(train_losses) + 1))

        # åˆ›å»ºå­å›¾
        n_plots = 1
        if train_metrics:
            n_plots += len(train_metrics)

        fig = make_subplots(
            rows=n_plots, cols=1,
            subplot_titles=['è®­ç»ƒå’ŒéªŒè¯æŸå¤±'] +
                           [f'{metric.upper()}æ›²çº¿' for metric in train_metrics.keys()]
            if train_metrics else ['è®­ç»ƒå’ŒéªŒè¯æŸå¤±'],
            vertical_spacing=0.1
        )

        # æ·»åŠ æŸå¤±æ›²çº¿
        fig.add_trace(
            go.Scatter(
                x=epochs,
                y=train_losses,
                mode='lines+markers',
                name='è®­ç»ƒæŸå¤±',
                line=dict(color='blue', width=2),
                marker=dict(size=6)
            ),
            row=1, col=1
        )

        fig.add_trace(
            go.Scatter(
                x=epochs,
                y=val_losses,
                mode='lines+markers',
                name='éªŒè¯æŸå¤±',
                line=dict(color='red', width=2),
                marker=dict(size=6)
            ),
            row=1, col=1
        )

        # æ ‡è®°æœ€ä½³ç‚¹
        best_epoch = np.argmin(val_losses) + 1
        best_loss = min(val_losses)
        fig.add_trace(
            go.Scatter(
                x=[best_epoch],
                y=[best_loss],
                mode='markers',
                name='æœ€ä½³éªŒè¯æŸå¤±',
                marker=dict(color='red', size=12, symbol='star'),
                text=[f'æœ€ä½³: {best_loss:.4f}'],
                hoverinfo='text'
            ),
            row=1, col=1
        )

        # æ·»åŠ æŒ‡æ ‡æ›²çº¿
        if train_metrics:
            for idx, (metric_name, values) in enumerate(train_metrics.items(), 2):
                fig.add_trace(
                    go.Scatter(
                        x=epochs,
                        y=values,
                        mode='lines+markers',
                        name=f'è®­ç»ƒ{metric_name.upper()}',
                        line=dict(color='green', width=2),
                        marker=dict(size=6)
                    ),
                    row=idx, col=1
                )

        # æ›´æ–°å¸ƒå±€
        fig.update_layout(
            title=dict(text=title, x=0.5, font=dict(size=20)),
            height=300 * n_plots,
            showlegend=True,
            hovermode='x unified'
        )

        # æ›´æ–°åæ ‡è½´
        for i in range(1, n_plots + 1):
            fig.update_xaxes(title_text="Epoch", row=i, col=1)
            fig.update_yaxes(title_text="å€¼", row=i, col=1)

        self.figures['training_curve'] = fig
        return fig

    def create_interactive_prediction_plot(self,
                                           predictions: np.ndarray,
                                           actuals: np.ndarray,
                                           sample_indices: List[int] = None,
                                           title: str = "äº¤äº’å¼é¢„æµ‹å¯¹æ¯”"):
        """
        åˆ›å»ºäº¤äº’å¼é¢„æµ‹å¯¹æ¯”å›¾

        Args:
            predictions: é¢„æµ‹å€¼
            actuals: å®é™…å€¼
            sample_indices: æ ·æœ¬ç´¢å¼•
            title: å›¾è¡¨æ ‡é¢˜

        Returns:
            plotly.graph_objects.Figure: äº¤äº’å¼å›¾è¡¨
        """
        if sample_indices is None:
            sample_indices = list(range(min(4, len(predictions))))

        n_samples = len(sample_indices)

        fig = make_subplots(
            rows=n_samples, cols=1,
            subplot_titles=[f'æ ·æœ¬ {idx}' for idx in sample_indices],
            vertical_spacing=0.15
        )

        for i, sample_idx in enumerate(sample_indices, 1):
            actual = actuals[sample_idx]
            pred = predictions[sample_idx]
            time_steps = list(range(len(actual)))

            # è®¡ç®—è¯¯å·®
            errors = np.abs(pred - actual)

            # æ·»åŠ å®é™…å€¼æ›²çº¿
            fig.add_trace(
                go.Scatter(
                    x=time_steps,
                    y=actual,
                    mode='lines+markers',
                    name='å®é™…å€¼',
                    line=dict(color='blue', width=3),
                    marker=dict(size=8),
                    legendgroup=f'group{i}',
                    showlegend=(i == 1)
                ),
                row=i, col=1
            )

            # æ·»åŠ é¢„æµ‹å€¼æ›²çº¿
            fig.add_trace(
                go.Scatter(
                    x=time_steps,
                    y=pred,
                    mode='lines+markers',
                    name='é¢„æµ‹å€¼',
                    line=dict(color='red', width=3),
                    marker=dict(size=8, symbol='diamond'),
                    legendgroup=f'group{i}',
                    showlegend=(i == 1)
                ),
                row=i, col=1
            )

            # æ·»åŠ è¯¯å·®æ¡å½¢å›¾
            fig.add_trace(
                go.Bar(
                    x=time_steps,
                    y=errors,
                    name='ç»å¯¹è¯¯å·®',
                    marker=dict(color='gray', opacity=0.5),
                    yaxis='y2',
                    legendgroup=f'error{i}',
                    showlegend=(i == 1)
                ),
                row=i, col=1
            )

            # è®¾ç½®åŒYè½´
            fig.update_layout({
                f'yaxis{i}': dict(title='å€¼', titlefont=dict(color='blue')),
                f'yaxis{i + 1}': dict(title='ç»å¯¹è¯¯å·®', titlefont=dict(color='gray'),
                                      overlaying=f'y{i}', side='right')
            })

            # è®¡ç®—å¹¶æ˜¾ç¤ºæŒ‡æ ‡
            mse = np.mean((pred - actual) ** 2)
            mae = np.mean(errors)

            # æ·»åŠ æŒ‡æ ‡æ ‡æ³¨
            fig.add_annotation(
                x=0.02, y=0.95,
                xref=f'x{i}', yref=f'y{i} domain',
                text=f'MSE: {mse:.4f}<br>MAE: {mae:.4f}',
                showarrow=False,
                font=dict(size=10),
                bgcolor='rgba(255, 255, 255, 0.8)',
                bordercolor='black',
                borderwidth=1,
                borderpad=4,
                row=i, col=1
            )

        fig.update_layout(
            title=dict(text=title, x=0.5, font=dict(size=20)),
            height=300 * n_samples,
            showlegend=True,
            hovermode='x unified'
        )

        self.figures['prediction_plot'] = fig
        return fig

    def save_figure(self, fig_name: str, save_path: str, format: str = 'html'):
        """
        ä¿å­˜äº¤äº’å¼å›¾è¡¨

        Args:
            fig_name: å›¾è¡¨åç§°
            save_path: ä¿å­˜è·¯å¾„
            format: æ ¼å¼ ('html', 'png', 'jpeg', 'svg', 'pdf')
        """
        if fig_name not in self.figures:
            print(f"âš ï¸  å›¾è¡¨ '{fig_name}' ä¸å­˜åœ¨")
            return

        fig = self.figures[fig_name]
        save_path = Path(save_path)

        if format == 'html':
            fig.write_html(str(save_path))
        else:
            fig.write_image(str(save_path), format=format)

        print(f"ğŸ’¾ äº¤äº’å¼å›¾è¡¨å·²ä¿å­˜åˆ°: {save_path}")


def visualize_correlation_matrix(data: np.ndarray,
                                 feature_names: List[str],
                                 title: str = "ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ",
                                 save_path: Optional[str] = None):
    """
    å¯è§†åŒ–ç›¸å…³æ€§çŸ©é˜µ

    Args:
        data: æ•°æ®æ•°ç»„ [n_samples, n_features]
        feature_names: ç‰¹å¾åç§°åˆ—è¡¨
        title: å›¾è¡¨æ ‡é¢˜
        save_path: ä¿å­˜è·¯å¾„
    """
    # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
    corr_matrix = np.corrcoef(data.T)

    # åˆ›å»ºçƒ­åŠ›å›¾
    fig, ax = plt.subplots(figsize=(10, 8))

    # ä½¿ç”¨seabornç»˜åˆ¶çƒ­åŠ›å›¾
    sns.heatmap(corr_matrix,
                annot=True,
                fmt='.2f',
                cmap='coolwarm',
                center=0,
                square=True,
                linewidths=0.5,
                cbar_kws={"shrink": 0.8},
                ax=ax)

    # è®¾ç½®æ ‡ç­¾
    ax.set_xticks(np.arange(len(feature_names)) + 0.5)
    ax.set_yticks(np.arange(len(feature_names)) + 0.5)
    ax.set_xticklabels(feature_names, rotation=45, ha='right')
    ax.set_yticklabels(feature_names, rotation=0)

    ax.set_title(title, fontsize=16, fontweight='bold')
    plt.tight_layout()

    # ä¿å­˜å›¾ç‰‡
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š ç›¸å…³æ€§çŸ©é˜µå·²ä¿å­˜åˆ°: {save_path}")

    plt.show()

    return corr_matrix


def visualize_time_series(data: pd.DataFrame,
                          columns: List[str] = None,
                          title: str = "æ—¶é—´åºåˆ—æ•°æ®å¯è§†åŒ–",
                          save_path: Optional[str] = None):
    """
    å¯è§†åŒ–æ—¶é—´åºåˆ—æ•°æ®

    Args:
        data: æ—¶é—´åºåˆ—DataFrame
        columns: è¦å¯è§†åŒ–çš„åˆ—
        title: å›¾è¡¨æ ‡é¢˜
        save_path: ä¿å­˜è·¯å¾„
    """
    if columns is None:
        columns = data.columns.tolist()

    n_cols = len(columns)
    fig, axes = plt.subplots(n_cols, 1, figsize=(14, 3 * n_cols))

    if n_cols == 1:
        axes = [axes]

    for idx, col in enumerate(columns):
        ax = axes[idx]

        # ç»˜åˆ¶æ—¶é—´åºåˆ—
        ax.plot(data.index, data[col], linewidth=1.5, alpha=0.8)

        # æ·»åŠ æ»šåŠ¨å¹³å‡
        rolling_mean = data[col].rolling(window=24).mean()
        ax.plot(data.index, rolling_mean, 'r-', linewidth=2, alpha=0.8, label='24hæ»šåŠ¨å¹³å‡')

        # æ·»åŠ å¡«å……åŒºåŸŸï¼ˆÂ±æ ‡å‡†å·®ï¼‰
        rolling_std = data[col].rolling(window=24).std()
        ax.fill_between(data.index,
                        rolling_mean - rolling_std,
                        rolling_mean + rolling_std,
                        alpha=0.2, color='red', label='Â±1æ ‡å‡†å·®')

        ax.set_ylabel(col)
        ax.set_title(f'{col} æ—¶é—´åºåˆ—')
        ax.legend()
        ax.grid(True, alpha=0.3)

    plt.suptitle(title, fontsize=16, fontweight='bold')
    plt.tight_layout()

    # ä¿å­˜å›¾ç‰‡
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“ˆ æ—¶é—´åºåˆ—å›¾å·²ä¿å­˜åˆ°: {save_path}")

    plt.show()


def create_dashboard(metrics: Dict[str, Any],
                     predictions: np.ndarray,
                     actuals: np.ndarray,
                     save_dir: str = "./dashboard"):
    """
    åˆ›å»ºå®Œæ•´çš„å®éªŒä»ªè¡¨æ¿

    Args:
        metrics: å®éªŒæŒ‡æ ‡
        predictions: é¢„æµ‹å€¼
        actuals: å®é™…å€¼
        save_dir: ä»ªè¡¨æ¿ä¿å­˜ç›®å½•
    """
    save_dir = Path(save_dir)
    save_dir.mkdir(parents=True, exist_ok=True)

    # åˆå§‹åŒ–å¯è§†åŒ–å™¨
    trainer_viz = TrainingVisualizer(save_dir=save_dir)
    interactive_viz = InteractiveVisualizer()

    # 1. è®­ç»ƒæ›²çº¿
    if 'train_loss' in metrics and 'val_loss' in metrics:
        trainer_viz.plot_training_curves(
            metrics['train_loss'],
            metrics['val_loss'],
            train_metrics={'mse': metrics.get('train_mse', [])},
            val_metrics={'mse': metrics.get('val_mse', [])},
            title="STAR-Forecast è®­ç»ƒè¿‡ç¨‹",
            save_name="training_curves"
        )

        # äº¤äº’å¼ç‰ˆæœ¬
        interactive_fig = interactive_viz.create_interactive_training_curve(
            metrics['train_loss'],
            metrics['val_loss'],
            train_metrics={'mse': metrics.get('train_mse', [])},
            title="STAR-Forecast äº¤äº’å¼è®­ç»ƒæ›²çº¿"
        )
        interactive_viz.save_figure('training_curve', save_dir / 'training_curve.html')

    # 2. é¢„æµ‹å¯¹æ¯”
    if len(predictions) > 0:
        # éšæœºé€‰æ‹©4ä¸ªæ ·æœ¬
        sample_indices = np.random.choice(len(predictions), min(4, len(predictions)), replace=False)

        trainer_viz.plot_prediction_vs_actual(
            predictions,
            actuals,
            sample_indices=sample_indices.tolist(),
            title="STAR-Forecast é¢„æµ‹ vs å®é™…å€¼",
            save_name="predictions"
        )

        # äº¤äº’å¼ç‰ˆæœ¬
        interactive_fig = interactive_viz.create_interactive_prediction_plot(
            predictions,
            actuals,
            sample_indices=sample_indices.tolist()[:3],
            title="STAR-Forecast äº¤äº’å¼é¢„æµ‹å¯¹æ¯”"
        )
        interactive_viz.save_figure('prediction_plot', save_dir / 'prediction_plot.html')

    # 3. è¯¯å·®åˆ†æ
    if len(predictions) > 0:
        trainer_viz.plot_error_distribution(
            predictions,
            actuals,
            title="STAR-Forecast é¢„æµ‹è¯¯å·®åˆ†æ",
            save_name="error_analysis"
        )

    # 4. åˆ›å»ºæ±‡æ€»æŠ¥å‘Š
    create_summary_report(metrics, predictions, actuals, save_dir)

    print(f"ğŸ“Š å®éªŒä»ªè¡¨æ¿å·²ä¿å­˜åˆ°: {save_dir}")


def create_summary_report(metrics: Dict[str, Any],
                          predictions: np.ndarray,
                          actuals: np.ndarray,
                          save_dir: Path):
    """
    åˆ›å»ºå®éªŒæ‘˜è¦æŠ¥å‘Š

    Args:
        metrics: å®éªŒæŒ‡æ ‡
        predictions: é¢„æµ‹å€¼
        actuals: å®é™…å€¼
        save_dir: ä¿å­˜ç›®å½•
    """
    # è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
    if len(predictions) > 0:
        test_mse = np.mean((predictions - actuals) ** 2)
        test_mae = np.mean(np.abs(predictions - actuals))
        test_rmse = np.sqrt(test_mse)
    else:
        test_mse = test_mae = test_rmse = 0.0

    # åˆ›å»ºæŠ¥å‘Š
    report = f"""
    ========================================
    STAR-Forecast å®éªŒæ‘˜è¦æŠ¥å‘Š
    ========================================

    ä¸€ã€è®­ç»ƒè¿‡ç¨‹ç»Ÿè®¡
    ----------------------------------------
    è®­ç»ƒè½®æ¬¡: {len(metrics.get('train_loss', []))}
    æœ€ä½³è®­ç»ƒæŸå¤±: {min(metrics.get('train_loss', [0])):.6f}
    æœ€ä½³éªŒè¯æŸå¤±: {min(metrics.get('val_loss', [0])):.6f}

    äºŒã€æµ‹è¯•æ€§èƒ½æŒ‡æ ‡
    ----------------------------------------
    æµ‹è¯•MSE: {test_mse:.6f}
    æµ‹è¯•MAE: {test_mae:.6f}
    æµ‹è¯•RMSE: {test_rmse:.6f}

    ä¸‰ã€é¢„æµ‹è¯¯å·®åˆ†æ
    ----------------------------------------
    """

    if len(predictions) > 0:
        errors = predictions - actuals
        abs_errors = np.abs(errors)

        report += f"""
    å¹³å‡è¯¯å·®: {np.mean(errors):.6f}
    è¯¯å·®æ ‡å‡†å·®: {np.std(errors):.6f}
    æœ€å¤§ç»å¯¹è¯¯å·®: {np.max(abs_errors):.6f}
    æœ€å°ç»å¯¹è¯¯å·®: {np.min(abs_errors):.6f}
    è¯¯å·®ä¸­ä½æ•°: {np.median(abs_errors):.6f}

    å››ã€æ¨¡å‹æ€§èƒ½è¯„ä¼°
    ----------------------------------------
    RÂ²åˆ†æ•°: {max(0, 1 - test_mse / np.var(actuals)):.4f}
    """

    # ä¿å­˜æŠ¥å‘Š
    report_file = save_dir / "experiment_summary.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"ğŸ“‹ å®éªŒæ‘˜è¦æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")


if __name__ == "__main__":
    # æµ‹è¯•å¯è§†åŒ–æ¨¡å—
    print("ğŸ§ª æµ‹è¯•å¯è§†åŒ–æ¨¡å—...")

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    np.random.seed(42)

    # æ¨¡æ‹Ÿè®­ç»ƒæŒ‡æ ‡
    epochs = 50
    train_losses = np.exp(-np.linspace(0, 3, epochs)) + np.random.normal(0, 0.02, epochs)
    val_losses = np.exp(-np.linspace(0, 2.8, epochs)) + np.random.normal(0, 0.03, epochs)

    train_mse = train_losses * 0.8
    val_mse = val_losses * 0.9

    # æ¨¡æ‹Ÿé¢„æµ‹ç»“æœ
    n_samples = 100
    pred_len = 24
    actuals = np.random.randn(n_samples, pred_len)
    predictions = actuals + np.random.normal(0, 0.5, (n_samples, pred_len))

    # æµ‹è¯•è®­ç»ƒæ›²çº¿å¯è§†åŒ–
    viz = TrainingVisualizer(save_dir="./test_viz")
    viz.plot_training_curves(
        train_losses.tolist(),
        val_losses.tolist(),
        train_metrics={'mse': train_mse.tolist()},
        val_metrics={'mse': val_mse.tolist()},
        title="æµ‹è¯•è®­ç»ƒæ›²çº¿",
        save_name="test_training"
    )

    # æµ‹è¯•é¢„æµ‹å¯è§†åŒ–
    viz.plot_prediction_vs_actual(
        predictions,
        actuals,
        sample_indices=[0, 10, 20],
        title="æµ‹è¯•é¢„æµ‹å¯¹æ¯”",
        save_name="test_predictions"
    )

    # æµ‹è¯•è¯¯å·®åˆ†å¸ƒ
    viz.plot_error_distribution(
        predictions,
        actuals,
        title="æµ‹è¯•è¯¯å·®åˆ†å¸ƒ",
        save_name="test_errors"
    )

    print("âœ… å¯è§†åŒ–æ¨¡å—æµ‹è¯•å®Œæˆ")